The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `1`
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/scratch/users/yeevelyn/stable-lora/env/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:507: SyntaxWarning: invalid escape sequence '\.'
  layer_index = re.match(f".*.{pattern}\.(\d+)\.*", key)
/scratch/users/yeevelyn/stable-lora/env/lib/python3.12/site-packages/peft/tuners/lora/model.py:154: SyntaxWarning: invalid escape sequence '\.'
  target_name_key = next(filter(lambda key: re.match(f".*\.{key}$", current_key), pattern_keys), current_key)
/scratch/users/yeevelyn/stable-lora/env/lib/python3.12/site-packages/peft/tuners/loha/model.py:106: SyntaxWarning: invalid escape sequence '\.'
  target_name_key = next(filter(lambda key: re.match(f"(.*\.)?{key}$", current_key), pattern_keys), target_name)
/scratch/users/yeevelyn/stable-lora/env/lib/python3.12/site-packages/peft/tuners/lokr/model.py:107: SyntaxWarning: invalid escape sequence '\.'
  target_name_key = next(filter(lambda key: re.match(f"(.*\.)?{key}$", current_key), pattern_keys), target_name)
/scratch/users/yeevelyn/stable-lora/env/lib/python3.12/site-packages/peft/tuners/oft/model.py:99: SyntaxWarning: invalid escape sequence '\.'
  target_name_key = next(filter(lambda key: re.match(f"(.*\.)?{key}$", current_key), pattern_keys), target_name)
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
02/23/2025 15:42:38 - INFO - __main__ - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

{'dynamic_thresholding_ratio', 'timestep_spacing', 'prediction_type', 'rescale_betas_zero_snr', 'clip_sample_range', 'thresholding', 'variance_type', 'sample_max_value'} was not found in config. Values will be initialized to default values.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
{'use_linear_projection', 'mid_block_type', 'upcast_attention', 'resnet_skip_time_act', 'conv_in_kernel', 'class_embeddings_concat', 'dual_cross_attention', 'encoder_hid_dim_type', 'timestep_post_act', 'reverse_transformer_layers_per_block', 'addition_embed_type_num_heads', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'class_embed_type', 'transformer_layers_per_block', 'only_cross_attention', 'time_embedding_dim', 'num_attention_heads', 'addition_embed_type', 'addition_time_embed_dim', 'projection_class_embeddings_input_dim', 'mid_block_only_cross_attention', 'resnet_out_scale_factor', 'time_embedding_type', 'num_class_embeds', 'cross_attention_norm', 'encoder_hid_dim', 'time_embedding_act_fn', 'conv_out_kernel', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing UNet2DConditionModel.

All the weights of UNet2DConditionModel were initialized from the model checkpoint at runwayml/stable-diffusion-v1-5.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.
02/23/2025 15:43:20 - INFO - __main__ - ***** Running training *****
02/23/2025 15:43:20 - INFO - __main__ -   Num examples = 34
02/23/2025 15:43:20 - INFO - __main__ -   Num Epochs = 1445
02/23/2025 15:43:20 - INFO - __main__ -   Instantaneous batch size per device = 1
02/23/2025 15:43:20 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
02/23/2025 15:43:20 - INFO - __main__ -   Gradient Accumulation steps = 4
02/23/2025 15:43:20 - INFO - __main__ -   Total optimization steps = 13000
02/23/2025 15:43:20 - INFO - accelerate.accelerator - Loading states from train/checkpoint-12000
02/23/2025 15:43:25 - INFO - accelerate.checkpointing - All model weights loaded successfully
02/23/2025 15:43:25 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
02/23/2025 15:43:25 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
02/23/2025 15:43:25 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully
02/23/2025 15:43:25 - INFO - accelerate.checkpointing - All random states loaded successfully
02/23/2025 15:43:25 - INFO - accelerate.accelerator - Loading in 0 custom states
Resuming from checkpoint checkpoint-12000
Steps:  92%|█████████▏| 12000/13000 [00:00<?, ?it/s]Steps:  92%|█████████▏| 12000/13000 [00:04<?, ?it/s, lr=9.55e-6, step_loss=0.509]Steps:  92%|█████████▏| 12000/13000 [00:04<?, ?it/s, lr=9.55e-6, step_loss=0.0213]Steps:  92%|█████████▏| 12000/13000 [00:05<?, ?it/s, lr=9.55e-6, step_loss=0.0927]Steps:  92%|█████████▏| 12001/13000 [00:05<1:31:54,  5.52s/it, lr=9.55e-6, step_loss=0.0927]Steps:  92%|█████████▏| 12001/13000 [00:05<1:31:54,  5.52s/it, lr=1.45e-6, step_loss=0.189] Steps:  92%|█████████▏| 12001/13000 [00:05<1:31:54,  5.52s/it, lr=1.45e-6, step_loss=0.0153]Steps:  92%|█████████▏| 12001/13000 [00:06<1:31:54,  5.52s/it, lr=1.45e-6, step_loss=0.412] Steps:  92%|█████████▏| 12001/13000 [00:06<1:31:54,  5.52s/it, lr=1.45e-6, step_loss=0.195]Steps:  92%|█████████▏| 12002/13000 [00:06<51:34,  3.10s/it, lr=1.45e-6, step_loss=0.195]  Steps:  92%|█████████▏| 12002/13000 [00:06<51:34,  3.10s/it, lr=1.45e-6, step_loss=0.0708]Steps:  92%|█████████▏| 12002/13000 [00:07<51:34,  3.10s/it, lr=1.45e-6, step_loss=0.0123]Steps:  92%|█████████▏| 12002/13000 [00:07<51:34,  3.10s/it, lr=1.45e-6, step_loss=0.0874]Steps:  92%|█████████▏| 12002/13000 [00:08<51:34,  3.10s/it, lr=1.45e-6, step_loss=0.0357]Steps:  92%|█████████▏| 12003/13000 [00:08<39:10,  2.36s/it, lr=1.45e-6, step_loss=0.0357]Steps:  92%|█████████▏| 12003/13000 [00:08<39:10,  2.36s/it, lr=1.44e-6, step_loss=0.0811]Steps:  92%|█████████▏| 12003/13000 [00:08<39:10,  2.36s/it, lr=1.44e-6, step_loss=0.0217]Steps:  92%|█████████▏| 12003/13000 [00:09<39:10,  2.36s/it, lr=1.44e-6, step_loss=0.0038]Steps:  92%|█████████▏| 12003/13000 [00:09<39:10,  2.36s/it, lr=1.44e-6, step_loss=0.228] Steps:  92%|█████████▏| 12004/13000 [00:09<33:40,  2.03s/it, lr=1.44e-6, step_loss=0.228]Steps:  92%|█████████▏| 12004/13000 [00:09<33:40,  2.03s/it, lr=1.44e-6, step_loss=0.0597]Steps:  92%|█████████▏| 12004/13000 [00:10<33:40,  2.03s/it, lr=1.44e-6, step_loss=0.0743]Steps:  92%|█████████▏| 12004/13000 [00:10<33:40,  2.03s/it, lr=1.44e-6, step_loss=0.0169]Steps:  92%|█████████▏| 12004/13000 [00:11<33:40,  2.03s/it, lr=1.44e-6, step_loss=0.0911]Steps:  92%|█████████▏| 12005/13000 [00:11<29:52,  1.80s/it, lr=1.44e-6, step_loss=0.0911]Steps:  92%|█████████▏| 12005/13000 [00:11<29:52,  1.80s/it, lr=1.44e-6, step_loss=0.0159]Steps:  92%|█████████▏| 12005/13000 [00:11<29:52,  1.80s/it, lr=1.44e-6, step_loss=0.141] Steps:  92%|█████████▏| 12005/13000 [00:12<29:52,  1.80s/it, lr=1.44e-6, step_loss=0.104]Steps:  92%|█████████▏| 12005/13000 [00:12<29:52,  1.80s/it, lr=1.44e-6, step_loss=0.0192]Steps:  92%|█████████▏| 12006/13000 [00:12<27:41,  1.67s/it, lr=1.44e-6, step_loss=0.0192]Steps:  92%|█████████▏| 12006/13000 [00:12<27:41,  1.67s/it, lr=1.44e-6, step_loss=0.0063]Steps:  92%|█████████▏| 12006/13000 [00:13<27:41,  1.67s/it, lr=1.44e-6, step_loss=0.00494]Steps:  92%|█████████▏| 12006/13000 [00:13<27:41,  1.67s/it, lr=1.44e-6, step_loss=0.0076] Steps:  92%|█████████▏| 12006/13000 [00:13<27:41,  1.67s/it, lr=1.44e-6, step_loss=0.599] Steps:  92%|█████████▏| 12007/13000 [00:14<26:31,  1.60s/it, lr=1.44e-6, step_loss=0.599]Steps:  92%|█████████▏| 12007/13000 [00:14<26:31,  1.60s/it, lr=1.43e-6, step_loss=0.134]Steps:  92%|█████████▏| 12007/13000 [00:14<26:31,  1.60s/it, lr=1.43e-6, step_loss=0.00865]Steps:  92%|█████████▏| 12007/13000 [00:14<26:31,  1.60s/it, lr=1.43e-6, step_loss=0.00503]Steps:  92%|█████████▏| 12007/13000 [00:15<26:31,  1.60s/it, lr=1.43e-6, step_loss=0.11]   Steps:  92%|█████████▏| 12008/13000 [00:15<25:50,  1.56s/it, lr=1.43e-6, step_loss=0.11]Steps:  92%|█████████▏| 12008/13000 [00:15<25:50,  1.56s/it, lr=1.43e-6, step_loss=0.0364]Steps:  92%|█████████▏| 12008/13000 [00:16<25:50,  1.56s/it, lr=1.43e-6, step_loss=0.012] Steps:  92%|█████████▏| 12009/13000 [00:16<21:19,  1.29s/it, lr=1.43e-6, step_loss=0.012]Steps:  92%|█████████▏| 12009/13000 [00:16<21:19,  1.29s/it, lr=1.43e-6, step_loss=0.165]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.43it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.12it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:10<00:00,  2.07s/it][ALoading pipeline components...: 100%|██████████| 7/7 [00:10<00:00,  1.53s/it]
02/23/2025 15:43:52 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  92%|█████████▏| 12009/13000 [00:46<21:19,  1.29s/it, lr=1.43e-6, step_loss=0.0633]Steps:  92%|█████████▏| 12009/13000 [00:46<21:19,  1.29s/it, lr=1.43e-6, step_loss=0.0376]Steps:  92%|█████████▏| 12009/13000 [00:46<21:19,  1.29s/it, lr=1.43e-6, step_loss=0.0801]Steps:  92%|█████████▏| 12010/13000 [00:47<2:51:47, 10.41s/it, lr=1.43e-6, step_loss=0.0801]Steps:  92%|█████████▏| 12010/13000 [00:47<2:51:47, 10.41s/it, lr=1.42e-6, step_loss=0.00503]Steps:  92%|█████████▏| 12010/13000 [00:47<2:51:47, 10.41s/it, lr=1.42e-6, step_loss=0.261]  Steps:  92%|█████████▏| 12010/13000 [00:47<2:51:47, 10.41s/it, lr=1.42e-6, step_loss=0.11] Steps:  92%|█████████▏| 12010/13000 [00:48<2:51:47, 10.41s/it, lr=1.42e-6, step_loss=0.108]Steps:  92%|█████████▏| 12011/13000 [00:48<2:06:13,  7.66s/it, lr=1.42e-6, step_loss=0.108]Steps:  92%|█████████▏| 12011/13000 [00:48<2:06:13,  7.66s/it, lr=1.42e-6, step_loss=0.327]Steps:  92%|█████████▏| 12011/13000 [00:49<2:06:13,  7.66s/it, lr=1.42e-6, step_loss=0.0656]Steps:  92%|█████████▏| 12011/13000 [00:49<2:06:13,  7.66s/it, lr=1.42e-6, step_loss=0.0484]Steps:  92%|█████████▏| 12011/13000 [00:49<2:06:13,  7.66s/it, lr=1.42e-6, step_loss=0.0869]Steps:  92%|█████████▏| 12012/13000 [00:50<1:35:05,  5.77s/it, lr=1.42e-6, step_loss=0.0869]Steps:  92%|█████████▏| 12012/13000 [00:50<1:35:05,  5.77s/it, lr=1.42e-6, step_loss=0.195] Steps:  92%|█████████▏| 12012/13000 [00:50<1:35:05,  5.77s/it, lr=1.42e-6, step_loss=0.392]Steps:  92%|█████████▏| 12012/13000 [00:50<1:35:05,  5.77s/it, lr=1.42e-6, step_loss=0.147]Steps:  92%|█████████▏| 12012/13000 [00:51<1:35:05,  5.77s/it, lr=1.42e-6, step_loss=0.0255]Steps:  92%|█████████▏| 12013/13000 [00:51<1:13:15,  4.45s/it, lr=1.42e-6, step_loss=0.0255]Steps:  92%|█████████▏| 12013/13000 [00:51<1:13:15,  4.45s/it, lr=1.42e-6, step_loss=0.0676]Steps:  92%|█████████▏| 12013/13000 [00:51<1:13:15,  4.45s/it, lr=1.42e-6, step_loss=0.0734]Steps:  92%|█████████▏| 12013/13000 [00:52<1:13:15,  4.45s/it, lr=1.42e-6, step_loss=0.0887]Steps:  92%|█████████▏| 12013/13000 [00:52<1:13:15,  4.45s/it, lr=1.42e-6, step_loss=0.00345]Steps:  92%|█████████▏| 12014/13000 [00:52<58:28,  3.56s/it, lr=1.42e-6, step_loss=0.00345]  Steps:  92%|█████████▏| 12014/13000 [00:53<58:28,  3.56s/it, lr=1.41e-6, step_loss=0.161]  Steps:  92%|█████████▏| 12014/13000 [00:53<58:28,  3.56s/it, lr=1.41e-6, step_loss=0.399]Steps:  92%|█████████▏| 12014/13000 [00:53<58:28,  3.56s/it, lr=1.41e-6, step_loss=0.0134]Steps:  92%|█████████▏| 12014/13000 [00:54<58:28,  3.56s/it, lr=1.41e-6, step_loss=0.18]  Steps:  92%|█████████▏| 12015/13000 [00:54<48:00,  2.92s/it, lr=1.41e-6, step_loss=0.18]Steps:  92%|█████████▏| 12015/13000 [00:54<48:00,  2.92s/it, lr=1.41e-6, step_loss=0.532]Steps:  92%|█████████▏| 12015/13000 [00:54<48:00,  2.92s/it, lr=1.41e-6, step_loss=0.0232]Steps:  92%|█████████▏| 12015/13000 [00:55<48:00,  2.92s/it, lr=1.41e-6, step_loss=0.0777]Steps:  92%|█████████▏| 12015/13000 [00:55<48:00,  2.92s/it, lr=1.41e-6, step_loss=0.00779]Steps:  92%|█████████▏| 12016/13000 [00:55<40:57,  2.50s/it, lr=1.41e-6, step_loss=0.00779]Steps:  92%|█████████▏| 12016/13000 [00:56<40:57,  2.50s/it, lr=1.41e-6, step_loss=0.0063] Steps:  92%|█████████▏| 12016/13000 [00:56<40:57,  2.50s/it, lr=1.41e-6, step_loss=0.00579]Steps:  92%|█████████▏| 12016/13000 [00:56<40:57,  2.50s/it, lr=1.41e-6, step_loss=0.00664]Steps:  92%|█████████▏| 12016/13000 [00:57<40:57,  2.50s/it, lr=1.41e-6, step_loss=0.14]   Steps:  92%|█████████▏| 12017/13000 [00:57<35:42,  2.18s/it, lr=1.41e-6, step_loss=0.14]Steps:  92%|█████████▏| 12017/13000 [00:57<35:42,  2.18s/it, lr=1.4e-6, step_loss=0.00748]Steps:  92%|█████████▏| 12017/13000 [00:57<35:42,  2.18s/it, lr=1.4e-6, step_loss=0.191]  Steps:  92%|█████████▏| 12018/13000 [00:58<28:25,  1.74s/it, lr=1.4e-6, step_loss=0.191]Steps:  92%|█████████▏| 12018/13000 [00:58<28:25,  1.74s/it, lr=1.4e-6, step_loss=0.155]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.47it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.32it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.11it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.63it/s]
02/23/2025 15:44:24 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  92%|█████████▏| 12018/13000 [01:12<28:25,  1.74s/it, lr=1.4e-6, step_loss=0.0521]Steps:  92%|█████████▏| 12018/13000 [01:13<28:25,  1.74s/it, lr=1.4e-6, step_loss=0.162] Steps:  92%|█████████▏| 12018/13000 [01:13<28:25,  1.74s/it, lr=1.4e-6, step_loss=0.0296]Steps:  92%|█████████▏| 12019/13000 [01:13<1:36:56,  5.93s/it, lr=1.4e-6, step_loss=0.0296]Steps:  92%|█████████▏| 12019/13000 [01:13<1:36:56,  5.93s/it, lr=1.4e-6, step_loss=0.117] Steps:  92%|█████████▏| 12019/13000 [01:14<1:36:56,  5.93s/it, lr=1.4e-6, step_loss=0.116]Steps:  92%|█████████▏| 12019/13000 [01:14<1:36:56,  5.93s/it, lr=1.4e-6, step_loss=0.0352]Steps:  92%|█████████▏| 12019/13000 [01:14<1:36:56,  5.93s/it, lr=1.4e-6, step_loss=0.0342]Steps:  92%|█████████▏| 12020/13000 [01:15<1:14:53,  4.59s/it, lr=1.4e-6, step_loss=0.0342]Steps:  92%|█████████▏| 12020/13000 [01:15<1:14:53,  4.59s/it, lr=1.4e-6, step_loss=0.381] Steps:  92%|█████████▏| 12020/13000 [01:15<1:14:53,  4.59s/it, lr=1.4e-6, step_loss=0.0913]Steps:  92%|█████████▏| 12020/13000 [01:16<1:14:53,  4.59s/it, lr=1.4e-6, step_loss=0.00452]Steps:  92%|█████████▏| 12020/13000 [01:16<1:14:53,  4.59s/it, lr=1.4e-6, step_loss=0.286]  Steps:  92%|█████████▏| 12021/13000 [01:16<59:32,  3.65s/it, lr=1.4e-6, step_loss=0.286]  Steps:  92%|█████████▏| 12021/13000 [01:16<59:32,  3.65s/it, lr=1.39e-6, step_loss=0.111]Steps:  92%|█████████▏| 12021/13000 [01:17<59:32,  3.65s/it, lr=1.39e-6, step_loss=0.115]Steps:  92%|█████████▏| 12021/13000 [01:17<59:32,  3.65s/it, lr=1.39e-6, step_loss=0.594]Steps:  92%|█████████▏| 12021/13000 [01:17<59:32,  3.65s/it, lr=1.39e-6, step_loss=0.127]Steps:  92%|█████████▏| 12022/13000 [01:18<48:45,  2.99s/it, lr=1.39e-6, step_loss=0.127]Steps:  92%|█████████▏| 12022/13000 [01:18<48:45,  2.99s/it, lr=1.39e-6, step_loss=0.00852]Steps:  92%|█████████▏| 12022/13000 [01:18<48:45,  2.99s/it, lr=1.39e-6, step_loss=0.0583] Steps:  92%|█████████▏| 12022/13000 [01:18<48:45,  2.99s/it, lr=1.39e-6, step_loss=0.258] Steps:  92%|█████████▏| 12022/13000 [01:19<48:45,  2.99s/it, lr=1.39e-6, step_loss=0.00342]Steps:  92%|█████████▏| 12023/13000 [01:19<41:13,  2.53s/it, lr=1.39e-6, step_loss=0.00342]Steps:  92%|█████████▏| 12023/13000 [01:19<41:13,  2.53s/it, lr=1.39e-6, step_loss=0.00496]Steps:  92%|█████████▏| 12023/13000 [01:20<41:13,  2.53s/it, lr=1.39e-6, step_loss=0.121]  Steps:  92%|█████████▏| 12023/13000 [01:20<41:13,  2.53s/it, lr=1.39e-6, step_loss=0.0763]Steps:  92%|█████████▏| 12023/13000 [01:20<41:13,  2.53s/it, lr=1.39e-6, step_loss=0.0484]Steps:  92%|█████████▏| 12024/13000 [01:21<35:58,  2.21s/it, lr=1.39e-6, step_loss=0.0484]Steps:  92%|█████████▏| 12024/13000 [01:21<35:58,  2.21s/it, lr=1.38e-6, step_loss=0.0871]Steps:  92%|█████████▏| 12024/13000 [01:21<35:58,  2.21s/it, lr=1.38e-6, step_loss=0.00349]Steps:  92%|█████████▏| 12024/13000 [01:21<35:58,  2.21s/it, lr=1.38e-6, step_loss=0.0145] Steps:  92%|█████████▏| 12024/13000 [01:22<35:58,  2.21s/it, lr=1.38e-6, step_loss=0.0837]Steps:  92%|█████████▎| 12025/13000 [01:22<32:12,  1.98s/it, lr=1.38e-6, step_loss=0.0837]Steps:  92%|█████████▎| 12025/13000 [01:22<32:12,  1.98s/it, lr=1.38e-6, step_loss=0.103] Steps:  92%|█████████▎| 12025/13000 [01:22<32:12,  1.98s/it, lr=1.38e-6, step_loss=0.0213]Steps:  92%|█████████▎| 12025/13000 [01:23<32:12,  1.98s/it, lr=1.38e-6, step_loss=0.0763]Steps:  92%|█████████▎| 12025/13000 [01:23<32:12,  1.98s/it, lr=1.38e-6, step_loss=0.00651]Steps:  93%|█████████▎| 12026/13000 [01:23<29:25,  1.81s/it, lr=1.38e-6, step_loss=0.00651]Steps:  93%|█████████▎| 12026/13000 [01:24<29:25,  1.81s/it, lr=1.38e-6, step_loss=0.0294] Steps:  93%|█████████▎| 12026/13000 [01:24<29:25,  1.81s/it, lr=1.38e-6, step_loss=0.215] Steps:  93%|█████████▎| 12027/13000 [01:24<24:02,  1.48s/it, lr=1.38e-6, step_loss=0.215]Steps:  93%|█████████▎| 12027/13000 [01:24<24:02,  1.48s/it, lr=1.38e-6, step_loss=0.0277]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.35it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.50it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.51it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.02it/s]
02/23/2025 15:44:51 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  93%|█████████▎| 12027/13000 [01:39<24:02,  1.48s/it, lr=1.38e-6, step_loss=0.134] Steps:  93%|█████████▎| 12027/13000 [01:39<24:02,  1.48s/it, lr=1.38e-6, step_loss=0.306]Steps:  93%|█████████▎| 12027/13000 [01:40<24:02,  1.48s/it, lr=1.38e-6, step_loss=0.0886]Steps:  93%|█████████▎| 12028/13000 [01:40<1:33:38,  5.78s/it, lr=1.38e-6, step_loss=0.0886]Steps:  93%|█████████▎| 12028/13000 [01:40<1:33:38,  5.78s/it, lr=1.37e-6, step_loss=0.00581]Steps:  93%|█████████▎| 12028/13000 [01:40<1:33:38,  5.78s/it, lr=1.37e-6, step_loss=0.0166] Steps:  93%|█████████▎| 12028/13000 [01:41<1:33:38,  5.78s/it, lr=1.37e-6, step_loss=0.0162]Steps:  93%|█████████▎| 12028/13000 [01:41<1:33:38,  5.78s/it, lr=1.37e-6, step_loss=0.0348]Steps:  93%|█████████▎| 12029/13000 [01:41<1:12:35,  4.49s/it, lr=1.37e-6, step_loss=0.0348]Steps:  93%|█████████▎| 12029/13000 [01:43<1:12:35,  4.49s/it, lr=1.37e-6, step_loss=0.0182]Steps:  93%|█████████▎| 12029/13000 [01:44<1:12:35,  4.49s/it, lr=1.37e-6, step_loss=0.098] Steps:  93%|█████████▎| 12029/13000 [01:44<1:12:35,  4.49s/it, lr=1.37e-6, step_loss=0.201]Steps:  93%|█████████▎| 12029/13000 [01:44<1:12:35,  4.49s/it, lr=1.37e-6, step_loss=0.024]Steps:  93%|█████████▎| 12030/13000 [01:45<1:06:26,  4.11s/it, lr=1.37e-6, step_loss=0.024]Steps:  93%|█████████▎| 12030/13000 [01:45<1:06:26,  4.11s/it, lr=1.37e-6, step_loss=0.102]Steps:  93%|█████████▎| 12030/13000 [01:45<1:06:26,  4.11s/it, lr=1.37e-6, step_loss=0.0104]Steps:  93%|█████████▎| 12030/13000 [01:45<1:06:26,  4.11s/it, lr=1.37e-6, step_loss=0.0177]Steps:  93%|█████████▎| 12030/13000 [01:46<1:06:26,  4.11s/it, lr=1.37e-6, step_loss=0.0553]Steps:  93%|█████████▎| 12031/13000 [01:46<53:19,  3.30s/it, lr=1.37e-6, step_loss=0.0553]  Steps:  93%|█████████▎| 12031/13000 [01:46<53:19,  3.30s/it, lr=1.36e-6, step_loss=0.142] Steps:  93%|█████████▎| 12031/13000 [01:47<53:19,  3.30s/it, lr=1.36e-6, step_loss=0.329]Steps:  93%|█████████▎| 12031/13000 [01:47<53:19,  3.30s/it, lr=1.36e-6, step_loss=0.00431]Steps:  93%|█████████▎| 12031/13000 [01:47<53:19,  3.30s/it, lr=1.36e-6, step_loss=0.0129] Steps:  93%|█████████▎| 12032/13000 [01:48<44:14,  2.74s/it, lr=1.36e-6, step_loss=0.0129]Steps:  93%|█████████▎| 12032/13000 [01:48<44:14,  2.74s/it, lr=1.36e-6, step_loss=0.124] Steps:  93%|█████████▎| 12032/13000 [01:48<44:14,  2.74s/it, lr=1.36e-6, step_loss=0.0144]Steps:  93%|█████████▎| 12032/13000 [01:48<44:14,  2.74s/it, lr=1.36e-6, step_loss=0.507] Steps:  93%|█████████▎| 12032/13000 [01:49<44:14,  2.74s/it, lr=1.36e-6, step_loss=0.218]Steps:  93%|█████████▎| 12033/13000 [01:49<37:53,  2.35s/it, lr=1.36e-6, step_loss=0.218]Steps:  93%|█████████▎| 12033/13000 [01:49<37:53,  2.35s/it, lr=1.36e-6, step_loss=0.00299]Steps:  93%|█████████▎| 12033/13000 [01:49<37:53,  2.35s/it, lr=1.36e-6, step_loss=0.291]  Steps:  93%|█████████▎| 12033/13000 [01:50<37:53,  2.35s/it, lr=1.36e-6, step_loss=0.0232]Steps:  93%|█████████▎| 12033/13000 [01:50<37:53,  2.35s/it, lr=1.36e-6, step_loss=0.0719]Steps:  93%|█████████▎| 12034/13000 [01:50<33:26,  2.08s/it, lr=1.36e-6, step_loss=0.0719]Steps:  93%|█████████▎| 12034/13000 [01:50<33:26,  2.08s/it, lr=1.36e-6, step_loss=0.076] Steps:  93%|█████████▎| 12034/13000 [01:51<33:26,  2.08s/it, lr=1.36e-6, step_loss=0.00493]Steps:  93%|█████████▎| 12034/13000 [01:51<33:26,  2.08s/it, lr=1.36e-6, step_loss=0.0586] Steps:  93%|█████████▎| 12034/13000 [01:52<33:26,  2.08s/it, lr=1.36e-6, step_loss=0.0455]Steps:  93%|█████████▎| 12035/13000 [01:52<30:24,  1.89s/it, lr=1.36e-6, step_loss=0.0455]Steps:  93%|█████████▎| 12035/13000 [01:52<30:24,  1.89s/it, lr=1.35e-6, step_loss=0.0318]Steps:  93%|█████████▎| 12035/13000 [01:52<30:24,  1.89s/it, lr=1.35e-6, step_loss=0.0772]Steps:  93%|█████████▎| 12036/13000 [01:53<24:38,  1.53s/it, lr=1.35e-6, step_loss=0.0772]Steps:  93%|█████████▎| 12036/13000 [01:53<24:38,  1.53s/it, lr=1.35e-6, step_loss=0.0989]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.38it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.53it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.89it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.47it/s]
02/23/2025 15:45:19 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  93%|█████████▎| 12036/13000 [02:07<24:38,  1.53s/it, lr=1.35e-6, step_loss=0.281] Steps:  93%|█████████▎| 12036/13000 [02:07<24:38,  1.53s/it, lr=1.35e-6, step_loss=0.0297]Steps:  93%|█████████▎| 12036/13000 [02:08<24:38,  1.53s/it, lr=1.35e-6, step_loss=0.0687]Steps:  93%|█████████▎| 12037/13000 [02:08<1:31:57,  5.73s/it, lr=1.35e-6, step_loss=0.0687]Steps:  93%|█████████▎| 12037/13000 [02:08<1:31:57,  5.73s/it, lr=1.35e-6, step_loss=0.0046]Steps:  93%|█████████▎| 12037/13000 [02:09<1:31:57,  5.73s/it, lr=1.35e-6, step_loss=0.0306]Steps:  93%|█████████▎| 12037/13000 [02:09<1:31:57,  5.73s/it, lr=1.35e-6, step_loss=0.185] Steps:  93%|█████████▎| 12037/13000 [02:09<1:31:57,  5.73s/it, lr=1.35e-6, step_loss=0.16] Steps:  93%|█████████▎| 12038/13000 [02:10<1:11:21,  4.45s/it, lr=1.35e-6, step_loss=0.16]Steps:  93%|█████████▎| 12038/13000 [02:10<1:11:21,  4.45s/it, lr=1.35e-6, step_loss=0.183]Steps:  93%|█████████▎| 12038/13000 [02:10<1:11:21,  4.45s/it, lr=1.35e-6, step_loss=0.0447]Steps:  93%|█████████▎| 12038/13000 [02:10<1:11:21,  4.45s/it, lr=1.35e-6, step_loss=0.0208]Steps:  93%|█████████▎| 12038/13000 [02:11<1:11:21,  4.45s/it, lr=1.35e-6, step_loss=0.036] Steps:  93%|█████████▎| 12039/13000 [02:11<56:57,  3.56s/it, lr=1.35e-6, step_loss=0.036]  Steps:  93%|█████████▎| 12039/13000 [02:11<56:57,  3.56s/it, lr=1.34e-6, step_loss=0.19] Steps:  93%|█████████▎| 12039/13000 [02:11<56:57,  3.56s/it, lr=1.34e-6, step_loss=0.191]Steps:  93%|█████████▎| 12039/13000 [02:12<56:57,  3.56s/it, lr=1.34e-6, step_loss=0.00359]Steps:  93%|█████████▎| 12039/13000 [02:12<56:57,  3.56s/it, lr=1.34e-6, step_loss=0.179]  Steps:  93%|█████████▎| 12040/13000 [02:12<46:37,  2.91s/it, lr=1.34e-6, step_loss=0.179]Steps:  93%|█████████▎| 12040/13000 [02:12<46:37,  2.91s/it, lr=1.34e-6, step_loss=0.403]Steps:  93%|█████████▎| 12040/13000 [02:13<46:37,  2.91s/it, lr=1.34e-6, step_loss=0.0795]Steps:  93%|█████████▎| 12040/13000 [02:13<46:37,  2.91s/it, lr=1.34e-6, step_loss=0.196] Steps:  93%|█████████▎| 12040/13000 [02:14<46:37,  2.91s/it, lr=1.34e-6, step_loss=0.262]Steps:  93%|█████████▎| 12041/13000 [02:14<39:29,  2.47s/it, lr=1.34e-6, step_loss=0.262]Steps:  93%|█████████▎| 12041/13000 [02:14<39:29,  2.47s/it, lr=1.34e-6, step_loss=0.0784]Steps:  93%|█████████▎| 12041/13000 [02:14<39:29,  2.47s/it, lr=1.34e-6, step_loss=0.0639]Steps:  93%|█████████▎| 12041/13000 [02:15<39:29,  2.47s/it, lr=1.34e-6, step_loss=0.352] Steps:  93%|█████████▎| 12041/13000 [02:15<39:29,  2.47s/it, lr=1.34e-6, step_loss=0.257]Steps:  93%|█████████▎| 12042/13000 [02:15<34:50,  2.18s/it, lr=1.34e-6, step_loss=0.257]Steps:  93%|█████████▎| 12042/13000 [02:15<34:50,  2.18s/it, lr=1.33e-6, step_loss=0.0175]Steps:  93%|█████████▎| 12042/13000 [02:16<34:50,  2.18s/it, lr=1.33e-6, step_loss=0.00424]Steps:  93%|█████████▎| 12042/13000 [02:16<34:50,  2.18s/it, lr=1.33e-6, step_loss=0.0148] Steps:  93%|█████████▎| 12042/13000 [02:17<34:50,  2.18s/it, lr=1.33e-6, step_loss=0.0474]Steps:  93%|█████████▎| 12043/13000 [02:17<31:14,  1.96s/it, lr=1.33e-6, step_loss=0.0474]Steps:  93%|█████████▎| 12043/13000 [02:17<31:14,  1.96s/it, lr=1.33e-6, step_loss=0.0311]Steps:  93%|█████████▎| 12043/13000 [02:17<31:14,  1.96s/it, lr=1.33e-6, step_loss=0.0491]Steps:  93%|█████████▎| 12043/13000 [02:18<31:14,  1.96s/it, lr=1.33e-6, step_loss=0.046] Steps:  93%|█████████▎| 12043/13000 [02:18<31:14,  1.96s/it, lr=1.33e-6, step_loss=0.029]Steps:  93%|█████████▎| 12044/13000 [02:18<28:48,  1.81s/it, lr=1.33e-6, step_loss=0.029]Steps:  93%|█████████▎| 12044/13000 [02:18<28:48,  1.81s/it, lr=1.33e-6, step_loss=0.345]Steps:  93%|█████████▎| 12044/13000 [02:19<28:48,  1.81s/it, lr=1.33e-6, step_loss=0.109]Steps:  93%|█████████▎| 12045/13000 [02:19<23:29,  1.48s/it, lr=1.33e-6, step_loss=0.109]Steps:  93%|█████████▎| 12045/13000 [02:19<23:29,  1.48s/it, lr=1.33e-6, step_loss=0.0514]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.06it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.97it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.89it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.38it/s]
02/23/2025 15:45:45 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  93%|█████████▎| 12045/13000 [02:34<23:29,  1.48s/it, lr=1.33e-6, step_loss=0.0907]Steps:  93%|█████████▎| 12045/13000 [02:34<23:29,  1.48s/it, lr=1.33e-6, step_loss=0.0612]Steps:  93%|█████████▎| 12045/13000 [02:35<23:29,  1.48s/it, lr=1.33e-6, step_loss=0.0307]Steps:  93%|█████████▎| 12046/13000 [02:35<1:32:13,  5.80s/it, lr=1.33e-6, step_loss=0.0307]Steps:  93%|█████████▎| 12046/13000 [02:35<1:32:13,  5.80s/it, lr=1.32e-6, step_loss=0.0758]Steps:  93%|█████████▎| 12046/13000 [02:35<1:32:13,  5.80s/it, lr=1.32e-6, step_loss=0.229] Steps:  93%|█████████▎| 12046/13000 [02:36<1:32:13,  5.80s/it, lr=1.32e-6, step_loss=0.034]Steps:  93%|█████████▎| 12046/13000 [02:36<1:32:13,  5.80s/it, lr=1.32e-6, step_loss=0.0768]Steps:  93%|█████████▎| 12047/13000 [02:36<1:11:23,  4.49s/it, lr=1.32e-6, step_loss=0.0768]Steps:  93%|█████████▎| 12047/13000 [02:36<1:11:23,  4.49s/it, lr=1.32e-6, step_loss=0.0201]Steps:  93%|█████████▎| 12047/13000 [02:37<1:11:23,  4.49s/it, lr=1.32e-6, step_loss=0.0896]Steps:  93%|█████████▎| 12047/13000 [02:37<1:11:23,  4.49s/it, lr=1.32e-6, step_loss=0.0615]Steps:  93%|█████████▎| 12047/13000 [02:37<1:11:23,  4.49s/it, lr=1.32e-6, step_loss=0.00524]Steps:  93%|█████████▎| 12048/13000 [02:38<56:47,  3.58s/it, lr=1.32e-6, step_loss=0.00524]  Steps:  93%|█████████▎| 12048/13000 [02:38<56:47,  3.58s/it, lr=1.32e-6, step_loss=0.0248] Steps:  93%|█████████▎| 12048/13000 [02:38<56:47,  3.58s/it, lr=1.32e-6, step_loss=0.0193]Steps:  93%|█████████▎| 12048/13000 [02:39<56:47,  3.58s/it, lr=1.32e-6, step_loss=0.0165]Steps:  93%|█████████▎| 12048/13000 [02:39<56:47,  3.58s/it, lr=1.32e-6, step_loss=0.405] Steps:  93%|█████████▎| 12049/13000 [02:39<46:25,  2.93s/it, lr=1.32e-6, step_loss=0.405]Steps:  93%|█████████▎| 12049/13000 [02:39<46:25,  2.93s/it, lr=1.31e-6, step_loss=0.0607]Steps:  93%|█████████▎| 12049/13000 [02:40<46:25,  2.93s/it, lr=1.31e-6, step_loss=0.0755]Steps:  93%|█████████▎| 12049/13000 [02:40<46:25,  2.93s/it, lr=1.31e-6, step_loss=0.0386]Steps:  93%|█████████▎| 12049/13000 [02:40<46:25,  2.93s/it, lr=1.31e-6, step_loss=0.694] Steps:  93%|█████████▎| 12050/13000 [02:41<39:18,  2.48s/it, lr=1.31e-6, step_loss=0.694]Steps:  93%|█████████▎| 12050/13000 [02:41<39:18,  2.48s/it, lr=1.31e-6, step_loss=0.453]Steps:  93%|█████████▎| 12050/13000 [02:41<39:18,  2.48s/it, lr=1.31e-6, step_loss=0.201]Steps:  93%|█████████▎| 12050/13000 [02:42<39:18,  2.48s/it, lr=1.31e-6, step_loss=0.0381]Steps:  93%|█████████▎| 12050/13000 [02:42<39:18,  2.48s/it, lr=1.31e-6, step_loss=0.00822]Steps:  93%|█████████▎| 12051/13000 [02:42<35:10,  2.22s/it, lr=1.31e-6, step_loss=0.00822]Steps:  93%|█████████▎| 12051/13000 [02:42<35:10,  2.22s/it, lr=1.31e-6, step_loss=0.0787] Steps:  93%|█████████▎| 12051/13000 [02:43<35:10,  2.22s/it, lr=1.31e-6, step_loss=0.0246]Steps:  93%|█████████▎| 12051/13000 [02:43<35:10,  2.22s/it, lr=1.31e-6, step_loss=0.0243]Steps:  93%|█████████▎| 12051/13000 [02:43<35:10,  2.22s/it, lr=1.31e-6, step_loss=0.0878]Steps:  93%|█████████▎| 12052/13000 [02:44<31:35,  2.00s/it, lr=1.31e-6, step_loss=0.0878]Steps:  93%|█████████▎| 12052/13000 [02:44<31:35,  2.00s/it, lr=1.31e-6, step_loss=0.418] Steps:  93%|█████████▎| 12052/13000 [02:44<31:35,  2.00s/it, lr=1.31e-6, step_loss=0.0708]Steps:  93%|█████████▎| 12052/13000 [02:44<31:35,  2.00s/it, lr=1.31e-6, step_loss=0.0687]Steps:  93%|█████████▎| 12052/13000 [02:45<31:35,  2.00s/it, lr=1.31e-6, step_loss=0.015] Steps:  93%|█████████▎| 12053/13000 [02:45<28:55,  1.83s/it, lr=1.31e-6, step_loss=0.015]Steps:  93%|█████████▎| 12053/13000 [02:45<28:55,  1.83s/it, lr=1.3e-6, step_loss=0.102] Steps:  93%|█████████▎| 12053/13000 [02:46<28:55,  1.83s/it, lr=1.3e-6, step_loss=0.247]Steps:  93%|█████████▎| 12054/13000 [02:46<23:32,  1.49s/it, lr=1.3e-6, step_loss=0.247]Steps:  93%|█████████▎| 12054/13000 [02:46<23:32,  1.49s/it, lr=1.3e-6, step_loss=0.0274]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.66it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.18it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.67it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.26it/s]
02/23/2025 15:46:12 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12054/13000 [03:00<23:32,  1.49s/it, lr=1.3e-6, step_loss=0.634] Steps:  93%|█████████▎| 12054/13000 [03:01<23:32,  1.49s/it, lr=1.3e-6, step_loss=0.0338]Steps:  93%|█████████▎| 12054/13000 [03:01<23:32,  1.49s/it, lr=1.3e-6, step_loss=0.0157]Steps:  93%|█████████▎| 12055/13000 [03:01<1:30:04,  5.72s/it, lr=1.3e-6, step_loss=0.0157]Steps:  93%|█████████▎| 12055/13000 [03:01<1:30:04,  5.72s/it, lr=1.3e-6, step_loss=0.0828]Steps:  93%|█████████▎| 12055/13000 [03:02<1:30:04,  5.72s/it, lr=1.3e-6, step_loss=0.0178]Steps:  93%|█████████▎| 12055/13000 [03:02<1:30:04,  5.72s/it, lr=1.3e-6, step_loss=0.869] Steps:  93%|█████████▎| 12055/13000 [03:03<1:30:04,  5.72s/it, lr=1.3e-6, step_loss=0.198]Steps:  93%|█████████▎| 12056/13000 [03:03<1:09:49,  4.44s/it, lr=1.3e-6, step_loss=0.198]Steps:  93%|█████████▎| 12056/13000 [03:03<1:09:49,  4.44s/it, lr=1.3e-6, step_loss=0.569]Steps:  93%|█████████▎| 12056/13000 [03:03<1:09:49,  4.44s/it, lr=1.3e-6, step_loss=0.105]Steps:  93%|█████████▎| 12056/13000 [03:04<1:09:49,  4.44s/it, lr=1.3e-6, step_loss=0.00802]Steps:  93%|█████████▎| 12056/13000 [03:04<1:09:49,  4.44s/it, lr=1.3e-6, step_loss=0.00971]Steps:  93%|█████████▎| 12057/13000 [03:04<55:39,  3.54s/it, lr=1.3e-6, step_loss=0.00971]  Steps:  93%|█████████▎| 12057/13000 [03:04<55:39,  3.54s/it, lr=1.29e-6, step_loss=0.102] Steps:  93%|█████████▎| 12057/13000 [03:05<55:39,  3.54s/it, lr=1.29e-6, step_loss=0.00867]Steps:  93%|█████████▎| 12057/13000 [03:05<55:39,  3.54s/it, lr=1.29e-6, step_loss=0.0961] Steps:  93%|█████████▎| 12057/13000 [03:05<55:39,  3.54s/it, lr=1.29e-6, step_loss=0.0285]Steps:  93%|█████████▎| 12058/13000 [03:06<45:31,  2.90s/it, lr=1.29e-6, step_loss=0.0285]Steps:  93%|█████████▎| 12058/13000 [03:06<45:31,  2.90s/it, lr=1.29e-6, step_loss=0.0132]Steps:  93%|█████████▎| 12058/13000 [03:06<45:31,  2.90s/it, lr=1.29e-6, step_loss=0.033] Steps:  93%|█████████▎| 12058/13000 [03:07<45:31,  2.90s/it, lr=1.29e-6, step_loss=0.268]Steps:  93%|█████████▎| 12058/13000 [03:07<45:31,  2.90s/it, lr=1.29e-6, step_loss=0.424]Steps:  93%|█████████▎| 12059/13000 [03:07<38:49,  2.48s/it, lr=1.29e-6, step_loss=0.424]Steps:  93%|█████████▎| 12059/13000 [03:07<38:49,  2.48s/it, lr=1.29e-6, step_loss=0.0691]Steps:  93%|█████████▎| 12059/13000 [03:08<38:49,  2.48s/it, lr=1.29e-6, step_loss=0.255] Steps:  93%|█████████▎| 12059/13000 [03:08<38:49,  2.48s/it, lr=1.29e-6, step_loss=0.0842]Steps:  93%|█████████▎| 12059/13000 [03:08<38:49,  2.48s/it, lr=1.29e-6, step_loss=0.0163]Steps:  93%|█████████▎| 12060/13000 [03:09<34:01,  2.17s/it, lr=1.29e-6, step_loss=0.0163]Steps:  93%|█████████▎| 12060/13000 [03:09<34:01,  2.17s/it, lr=1.28e-6, step_loss=0.251] Steps:  93%|█████████▎| 12060/13000 [03:09<34:01,  2.17s/it, lr=1.28e-6, step_loss=0.0545]Steps:  93%|█████████▎| 12060/13000 [03:09<34:01,  2.17s/it, lr=1.28e-6, step_loss=0.0961]Steps:  93%|█████████▎| 12060/13000 [03:10<34:01,  2.17s/it, lr=1.28e-6, step_loss=0.0465]Steps:  93%|█████████▎| 12061/13000 [03:10<30:45,  1.97s/it, lr=1.28e-6, step_loss=0.0465]Steps:  93%|█████████▎| 12061/13000 [03:10<30:45,  1.97s/it, lr=1.28e-6, step_loss=0.0781]Steps:  93%|█████████▎| 12061/13000 [03:11<30:45,  1.97s/it, lr=1.28e-6, step_loss=0.0947]Steps:  93%|█████████▎| 12061/13000 [03:11<30:45,  1.97s/it, lr=1.28e-6, step_loss=0.0552]Steps:  93%|█████████▎| 12061/13000 [03:11<30:45,  1.97s/it, lr=1.28e-6, step_loss=0.0108]Steps:  93%|█████████▎| 12062/13000 [03:12<28:16,  1.81s/it, lr=1.28e-6, step_loss=0.0108]Steps:  93%|█████████▎| 12062/13000 [03:12<28:16,  1.81s/it, lr=1.28e-6, step_loss=0.0168]Steps:  93%|█████████▎| 12062/13000 [03:12<28:16,  1.81s/it, lr=1.28e-6, step_loss=0.0246]Steps:  93%|█████████▎| 12063/13000 [03:12<22:58,  1.47s/it, lr=1.28e-6, step_loss=0.0246]Steps:  93%|█████████▎| 12063/13000 [03:12<22:58,  1.47s/it, lr=1.28e-6, step_loss=0.434] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.17it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.13it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.87it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.39it/s]
02/23/2025 15:46:39 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  93%|█████████▎| 12063/13000 [03:27<22:58,  1.47s/it, lr=1.28e-6, step_loss=0.0029]Steps:  93%|█████████▎| 12063/13000 [03:27<22:58,  1.47s/it, lr=1.28e-6, step_loss=0.259] Steps:  93%|█████████▎| 12063/13000 [03:28<22:58,  1.47s/it, lr=1.28e-6, step_loss=0.247]Steps:  93%|█████████▎| 12064/13000 [03:28<1:30:13,  5.78s/it, lr=1.28e-6, step_loss=0.247]Steps:  93%|█████████▎| 12064/13000 [03:28<1:30:13,  5.78s/it, lr=1.27e-6, step_loss=0.00323]Steps:  93%|█████████▎| 12064/13000 [03:29<1:30:13,  5.78s/it, lr=1.27e-6, step_loss=0.0461] Steps:  93%|█████████▎| 12064/13000 [03:29<1:30:13,  5.78s/it, lr=1.27e-6, step_loss=0.0255]Steps:  93%|█████████▎| 12064/13000 [03:29<1:30:13,  5.78s/it, lr=1.27e-6, step_loss=0.0111]Steps:  93%|█████████▎| 12065/13000 [03:30<1:09:47,  4.48s/it, lr=1.27e-6, step_loss=0.0111]Steps:  93%|█████████▎| 12065/13000 [03:30<1:09:47,  4.48s/it, lr=1.27e-6, step_loss=0.00557]Steps:  93%|█████████▎| 12065/13000 [03:30<1:09:47,  4.48s/it, lr=1.27e-6, step_loss=0.158]  Steps:  93%|█████████▎| 12065/13000 [03:30<1:09:47,  4.48s/it, lr=1.27e-6, step_loss=0.0612]Steps:  93%|█████████▎| 12065/13000 [03:31<1:09:47,  4.48s/it, lr=1.27e-6, step_loss=0.0359]Steps:  93%|█████████▎| 12066/13000 [03:31<55:48,  3.59s/it, lr=1.27e-6, step_loss=0.0359]  Steps:  93%|█████████▎| 12066/13000 [03:31<55:48,  3.59s/it, lr=1.27e-6, step_loss=0.0661]Steps:  93%|█████████▎| 12066/13000 [03:31<55:48,  3.59s/it, lr=1.27e-6, step_loss=0.0279]Steps:  93%|█████████▎| 12066/13000 [03:32<55:48,  3.59s/it, lr=1.27e-6, step_loss=0.00386]Steps:  93%|█████████▎| 12066/13000 [03:32<55:48,  3.59s/it, lr=1.27e-6, step_loss=0.0221] Steps:  93%|█████████▎| 12067/13000 [03:33<45:43,  2.94s/it, lr=1.27e-6, step_loss=0.0221]Steps:  93%|█████████▎| 12067/13000 [03:33<45:43,  2.94s/it, lr=1.27e-6, step_loss=0.153] Steps:  93%|█████████▎| 12067/13000 [03:33<45:43,  2.94s/it, lr=1.27e-6, step_loss=0.0397]Steps:  93%|█████████▎| 12067/13000 [03:33<45:43,  2.94s/it, lr=1.27e-6, step_loss=0.597] Steps:  93%|█████████▎| 12067/13000 [03:34<45:43,  2.94s/it, lr=1.27e-6, step_loss=0.0744]Steps:  93%|█████████▎| 12068/13000 [03:34<38:42,  2.49s/it, lr=1.27e-6, step_loss=0.0744]Steps:  93%|█████████▎| 12068/13000 [03:34<38:42,  2.49s/it, lr=1.26e-6, step_loss=0.0499]Steps:  93%|█████████▎| 12068/13000 [03:34<38:42,  2.49s/it, lr=1.26e-6, step_loss=0.0193]Steps:  93%|█████████▎| 12068/13000 [03:35<38:42,  2.49s/it, lr=1.26e-6, step_loss=0.0505]Steps:  93%|█████████▎| 12068/13000 [03:35<38:42,  2.49s/it, lr=1.26e-6, step_loss=0.0131]Steps:  93%|█████████▎| 12069/13000 [03:35<33:52,  2.18s/it, lr=1.26e-6, step_loss=0.0131]Steps:  93%|█████████▎| 12069/13000 [03:35<33:52,  2.18s/it, lr=1.26e-6, step_loss=0.159] Steps:  93%|█████████▎| 12069/13000 [03:36<33:52,  2.18s/it, lr=1.26e-6, step_loss=0.0968]Steps:  93%|█████████▎| 12069/13000 [03:36<33:52,  2.18s/it, lr=1.26e-6, step_loss=0.00936]Steps:  93%|█████████▎| 12069/13000 [03:37<33:52,  2.18s/it, lr=1.26e-6, step_loss=0.0462] Steps:  93%|█████████▎| 12070/13000 [03:37<30:27,  1.96s/it, lr=1.26e-6, step_loss=0.0462]Steps:  93%|█████████▎| 12070/13000 [03:37<30:27,  1.96s/it, lr=1.26e-6, step_loss=0.18]  Steps:  93%|█████████▎| 12070/13000 [03:37<30:27,  1.96s/it, lr=1.26e-6, step_loss=0.0307]Steps:  93%|█████████▎| 12070/13000 [03:38<30:27,  1.96s/it, lr=1.26e-6, step_loss=0.0186]Steps:  93%|█████████▎| 12070/13000 [03:38<30:27,  1.96s/it, lr=1.26e-6, step_loss=0.201] Steps:  93%|█████████▎| 12071/13000 [03:38<28:27,  1.84s/it, lr=1.26e-6, step_loss=0.201]Steps:  93%|█████████▎| 12071/13000 [03:38<28:27,  1.84s/it, lr=1.25e-6, step_loss=0.0226]Steps:  93%|█████████▎| 12071/13000 [03:39<28:27,  1.84s/it, lr=1.25e-6, step_loss=0.084] Steps:  93%|█████████▎| 12072/13000 [03:39<23:06,  1.49s/it, lr=1.25e-6, step_loss=0.084]Steps:  93%|█████████▎| 12072/13000 [03:39<23:06,  1.49s/it, lr=1.25e-6, step_loss=0.00327]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.58it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.01it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.20it/s]
02/23/2025 15:47:06 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12072/13000 [03:54<23:06,  1.49s/it, lr=1.25e-6, step_loss=0.541]  Steps:  93%|█████████▎| 12072/13000 [03:54<23:06,  1.49s/it, lr=1.25e-6, step_loss=0.0535]Steps:  93%|█████████▎| 12072/13000 [03:55<23:06,  1.49s/it, lr=1.25e-6, step_loss=0.0072]Steps:  93%|█████████▎| 12073/13000 [03:55<1:29:29,  5.79s/it, lr=1.25e-6, step_loss=0.0072]Steps:  93%|█████████▎| 12073/13000 [03:55<1:29:29,  5.79s/it, lr=1.25e-6, step_loss=0.0702]Steps:  93%|█████████▎| 12073/13000 [03:55<1:29:29,  5.79s/it, lr=1.25e-6, step_loss=0.00363]Steps:  93%|█████████▎| 12073/13000 [03:56<1:29:29,  5.79s/it, lr=1.25e-6, step_loss=0.00649]Steps:  93%|█████████▎| 12073/13000 [03:56<1:29:29,  5.79s/it, lr=1.25e-6, step_loss=0.0481] Steps:  93%|█████████▎| 12074/13000 [03:56<1:09:21,  4.49s/it, lr=1.25e-6, step_loss=0.0481]Steps:  93%|█████████▎| 12074/13000 [03:56<1:09:21,  4.49s/it, lr=1.25e-6, step_loss=0.15]  Steps:  93%|█████████▎| 12074/13000 [03:57<1:09:21,  4.49s/it, lr=1.25e-6, step_loss=0.317]Steps:  93%|█████████▎| 12074/13000 [03:57<1:09:21,  4.49s/it, lr=1.25e-6, step_loss=0.0244]Steps:  93%|█████████▎| 12074/13000 [03:58<1:09:21,  4.49s/it, lr=1.25e-6, step_loss=0.0133]Steps:  93%|█████████▎| 12075/13000 [03:58<55:08,  3.58s/it, lr=1.25e-6, step_loss=0.0133]  Steps:  93%|█████████▎| 12075/13000 [03:58<55:08,  3.58s/it, lr=1.24e-6, step_loss=0.0268]Steps:  93%|█████████▎| 12075/13000 [03:58<55:08,  3.58s/it, lr=1.24e-6, step_loss=0.0349]Steps:  93%|█████████▎| 12075/13000 [03:59<55:08,  3.58s/it, lr=1.24e-6, step_loss=0.173] Steps:  93%|█████████▎| 12075/13000 [04:01<55:08,  3.58s/it, lr=1.24e-6, step_loss=0.303]Steps:  93%|█████████▎| 12076/13000 [04:01<53:33,  3.48s/it, lr=1.24e-6, step_loss=0.303]Steps:  93%|█████████▎| 12076/13000 [04:01<53:33,  3.48s/it, lr=1.24e-6, step_loss=0.198]Steps:  93%|█████████▎| 12076/13000 [04:02<53:33,  3.48s/it, lr=1.24e-6, step_loss=0.00406]Steps:  93%|█████████▎| 12076/13000 [04:02<53:33,  3.48s/it, lr=1.24e-6, step_loss=0.0472] Steps:  93%|█████████▎| 12076/13000 [04:02<53:33,  3.48s/it, lr=1.24e-6, step_loss=0.0175]Steps:  93%|█████████▎| 12077/13000 [04:03<44:03,  2.86s/it, lr=1.24e-6, step_loss=0.0175]Steps:  93%|█████████▎| 12077/13000 [04:03<44:03,  2.86s/it, lr=1.24e-6, step_loss=0.0231]Steps:  93%|█████████▎| 12077/13000 [04:03<44:03,  2.86s/it, lr=1.24e-6, step_loss=0.129] Steps:  93%|█████████▎| 12077/13000 [04:03<44:03,  2.86s/it, lr=1.24e-6, step_loss=0.00255]Steps:  93%|█████████▎| 12077/13000 [04:04<44:03,  2.86s/it, lr=1.24e-6, step_loss=0.0078] Steps:  93%|█████████▎| 12078/13000 [04:04<37:26,  2.44s/it, lr=1.24e-6, step_loss=0.0078]Steps:  93%|█████████▎| 12078/13000 [04:04<37:26,  2.44s/it, lr=1.24e-6, step_loss=0.0993]Steps:  93%|█████████▎| 12078/13000 [04:04<37:26,  2.44s/it, lr=1.24e-6, step_loss=0.017] Steps:  93%|█████████▎| 12078/13000 [04:05<37:26,  2.44s/it, lr=1.24e-6, step_loss=0.0433]Steps:  93%|█████████▎| 12078/13000 [04:05<37:26,  2.44s/it, lr=1.24e-6, step_loss=0.0128]Steps:  93%|█████████▎| 12079/13000 [04:05<32:59,  2.15s/it, lr=1.24e-6, step_loss=0.0128]Steps:  93%|█████████▎| 12079/13000 [04:06<32:59,  2.15s/it, lr=1.23e-6, step_loss=0.00273]Steps:  93%|█████████▎| 12079/13000 [04:06<32:59,  2.15s/it, lr=1.23e-6, step_loss=0.00389]Steps:  93%|█████████▎| 12079/13000 [04:06<32:59,  2.15s/it, lr=1.23e-6, step_loss=0.156]  Steps:  93%|█████████▎| 12079/13000 [04:07<32:59,  2.15s/it, lr=1.23e-6, step_loss=0.0404]Steps:  93%|█████████▎| 12080/13000 [04:07<30:25,  1.98s/it, lr=1.23e-6, step_loss=0.0404]Steps:  93%|█████████▎| 12080/13000 [04:07<30:25,  1.98s/it, lr=1.23e-6, step_loss=0.159] Steps:  93%|█████████▎| 12080/13000 [04:07<30:25,  1.98s/it, lr=1.23e-6, step_loss=0.02] Steps:  93%|█████████▎| 12081/13000 [04:08<24:33,  1.60s/it, lr=1.23e-6, step_loss=0.02]Steps:  93%|█████████▎| 12081/13000 [04:08<24:33,  1.60s/it, lr=1.23e-6, step_loss=0.0409]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.42it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.55it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.83it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.43it/s]
02/23/2025 15:47:34 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12081/13000 [04:22<24:33,  1.60s/it, lr=1.23e-6, step_loss=0.0421]Steps:  93%|█████████▎| 12081/13000 [04:23<24:33,  1.60s/it, lr=1.23e-6, step_loss=0.197] Steps:  93%|█████████▎| 12081/13000 [04:23<24:33,  1.60s/it, lr=1.23e-6, step_loss=0.0155]Steps:  93%|█████████▎| 12082/13000 [04:23<1:28:36,  5.79s/it, lr=1.23e-6, step_loss=0.0155]Steps:  93%|█████████▎| 12082/13000 [04:23<1:28:36,  5.79s/it, lr=1.23e-6, step_loss=0.273] Steps:  93%|█████████▎| 12082/13000 [04:24<1:28:36,  5.79s/it, lr=1.23e-6, step_loss=0.0438]Steps:  93%|█████████▎| 12082/13000 [04:24<1:28:36,  5.79s/it, lr=1.23e-6, step_loss=0.0323]Steps:  93%|█████████▎| 12082/13000 [04:24<1:28:36,  5.79s/it, lr=1.23e-6, step_loss=0.171] Steps:  93%|█████████▎| 12083/13000 [04:25<1:08:28,  4.48s/it, lr=1.23e-6, step_loss=0.171]Steps:  93%|█████████▎| 12083/13000 [04:25<1:08:28,  4.48s/it, lr=1.22e-6, step_loss=0.0128]Steps:  93%|█████████▎| 12083/13000 [04:25<1:08:28,  4.48s/it, lr=1.22e-6, step_loss=0.00799]Steps:  93%|█████████▎| 12083/13000 [04:26<1:08:28,  4.48s/it, lr=1.22e-6, step_loss=0.0138] Steps:  93%|█████████▎| 12083/13000 [04:26<1:08:28,  4.48s/it, lr=1.22e-6, step_loss=0.0199]Steps:  93%|█████████▎| 12084/13000 [04:26<54:31,  3.57s/it, lr=1.22e-6, step_loss=0.0199]  Steps:  93%|█████████▎| 12084/13000 [04:26<54:31,  3.57s/it, lr=1.22e-6, step_loss=0.0975]Steps:  93%|█████████▎| 12084/13000 [04:27<54:31,  3.57s/it, lr=1.22e-6, step_loss=0.17]  Steps:  93%|█████████▎| 12084/13000 [04:27<54:31,  3.57s/it, lr=1.22e-6, step_loss=0.017]Steps:  93%|█████████▎| 12084/13000 [04:27<54:31,  3.57s/it, lr=1.22e-6, step_loss=0.218]Steps:  93%|█████████▎| 12085/13000 [04:28<44:41,  2.93s/it, lr=1.22e-6, step_loss=0.218]Steps:  93%|█████████▎| 12085/13000 [04:28<44:41,  2.93s/it, lr=1.22e-6, step_loss=0.0655]Steps:  93%|█████████▎| 12085/13000 [04:28<44:41,  2.93s/it, lr=1.22e-6, step_loss=0.0638]Steps:  93%|█████████▎| 12085/13000 [04:28<44:41,  2.93s/it, lr=1.22e-6, step_loss=0.084] Steps:  93%|█████████▎| 12085/13000 [04:29<44:41,  2.93s/it, lr=1.22e-6, step_loss=0.064]Steps:  93%|█████████▎| 12086/13000 [04:29<37:54,  2.49s/it, lr=1.22e-6, step_loss=0.064]Steps:  93%|█████████▎| 12086/13000 [04:29<37:54,  2.49s/it, lr=1.21e-6, step_loss=0.0904]Steps:  93%|█████████▎| 12086/13000 [04:29<37:54,  2.49s/it, lr=1.21e-6, step_loss=0.00735]Steps:  93%|█████████▎| 12086/13000 [04:30<37:54,  2.49s/it, lr=1.21e-6, step_loss=0.00688]Steps:  93%|█████████▎| 12086/13000 [04:30<37:54,  2.49s/it, lr=1.21e-6, step_loss=0.111]  Steps:  93%|█████████▎| 12087/13000 [04:31<33:17,  2.19s/it, lr=1.21e-6, step_loss=0.111]Steps:  93%|█████████▎| 12087/13000 [04:31<33:17,  2.19s/it, lr=1.21e-6, step_loss=0.0596]Steps:  93%|█████████▎| 12087/13000 [04:31<33:17,  2.19s/it, lr=1.21e-6, step_loss=0.228] Steps:  93%|█████████▎| 12087/13000 [04:31<33:17,  2.19s/it, lr=1.21e-6, step_loss=0.301]Steps:  93%|█████████▎| 12087/13000 [04:32<33:17,  2.19s/it, lr=1.21e-6, step_loss=0.587]Steps:  93%|█████████▎| 12088/13000 [04:32<29:49,  1.96s/it, lr=1.21e-6, step_loss=0.587]Steps:  93%|█████████▎| 12088/13000 [04:32<29:49,  1.96s/it, lr=1.21e-6, step_loss=0.00716]Steps:  93%|█████████▎| 12088/13000 [04:32<29:49,  1.96s/it, lr=1.21e-6, step_loss=0.0654] Steps:  93%|█████████▎| 12088/13000 [04:33<29:49,  1.96s/it, lr=1.21e-6, step_loss=0.0553]Steps:  93%|█████████▎| 12088/13000 [04:33<29:49,  1.96s/it, lr=1.21e-6, step_loss=0.0259]Steps:  93%|█████████▎| 12089/13000 [04:33<27:28,  1.81s/it, lr=1.21e-6, step_loss=0.0259]Steps:  93%|█████████▎| 12089/13000 [04:33<27:28,  1.81s/it, lr=1.21e-6, step_loss=0.0559]Steps:  93%|█████████▎| 12089/13000 [04:34<27:28,  1.81s/it, lr=1.21e-6, step_loss=0.057] Steps:  93%|█████████▎| 12090/13000 [04:34<22:24,  1.48s/it, lr=1.21e-6, step_loss=0.057]Steps:  93%|█████████▎| 12090/13000 [04:34<22:24,  1.48s/it, lr=1.2e-6, step_loss=0.0492]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.26it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.68it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.62it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.13it/s]
02/23/2025 15:48:01 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12090/13000 [04:49<22:24,  1.48s/it, lr=1.2e-6, step_loss=0.0341]Steps:  93%|█████████▎| 12090/13000 [04:49<22:24,  1.48s/it, lr=1.2e-6, step_loss=0.0719]Steps:  93%|█████████▎| 12090/13000 [04:49<22:24,  1.48s/it, lr=1.2e-6, step_loss=0.0947]Steps:  93%|█████████▎| 12091/13000 [04:50<1:26:44,  5.73s/it, lr=1.2e-6, step_loss=0.0947]Steps:  93%|█████████▎| 12091/13000 [04:51<1:26:44,  5.73s/it, lr=1.2e-6, step_loss=0.0768]Steps:  93%|█████████▎| 12091/13000 [04:51<1:26:44,  5.73s/it, lr=1.2e-6, step_loss=0.144] Steps:  93%|█████████▎| 12091/13000 [04:52<1:26:44,  5.73s/it, lr=1.2e-6, step_loss=0.00429]Steps:  93%|█████████▎| 12091/13000 [04:52<1:26:44,  5.73s/it, lr=1.2e-6, step_loss=0.113]  Steps:  93%|█████████▎| 12092/13000 [04:52<1:12:58,  4.82s/it, lr=1.2e-6, step_loss=0.113]Steps:  93%|█████████▎| 12092/13000 [04:53<1:12:58,  4.82s/it, lr=1.2e-6, step_loss=0.00517]Steps:  93%|█████████▎| 12092/13000 [04:53<1:12:58,  4.82s/it, lr=1.2e-6, step_loss=0.014]  Steps:  93%|█████████▎| 12092/13000 [04:53<1:12:58,  4.82s/it, lr=1.2e-6, step_loss=0.0621]Steps:  93%|█████████▎| 12092/13000 [04:54<1:12:58,  4.82s/it, lr=1.2e-6, step_loss=0.0398]Steps:  93%|█████████▎| 12093/13000 [04:54<57:31,  3.81s/it, lr=1.2e-6, step_loss=0.0398]  Steps:  93%|█████████▎| 12093/13000 [04:54<57:31,  3.81s/it, lr=1.2e-6, step_loss=0.0142]Steps:  93%|█████████▎| 12093/13000 [04:54<57:31,  3.81s/it, lr=1.2e-6, step_loss=0.00281]Steps:  93%|█████████▎| 12093/13000 [04:55<57:31,  3.81s/it, lr=1.2e-6, step_loss=0.0192] Steps:  93%|█████████▎| 12093/13000 [04:55<57:31,  3.81s/it, lr=1.2e-6, step_loss=0.0189]Steps:  93%|█████████▎| 12094/13000 [04:55<46:40,  3.09s/it, lr=1.2e-6, step_loss=0.0189]Steps:  93%|█████████▎| 12094/13000 [04:55<46:40,  3.09s/it, lr=1.19e-6, step_loss=0.0254]Steps:  93%|█████████▎| 12094/13000 [04:56<46:40,  3.09s/it, lr=1.19e-6, step_loss=0.348] Steps:  93%|█████████▎| 12094/13000 [04:56<46:40,  3.09s/it, lr=1.19e-6, step_loss=0.0612]Steps:  93%|█████████▎| 12094/13000 [04:57<46:40,  3.09s/it, lr=1.19e-6, step_loss=0.244] Steps:  93%|█████████▎| 12095/13000 [04:57<41:58,  2.78s/it, lr=1.19e-6, step_loss=0.244]Steps:  93%|█████████▎| 12095/13000 [04:57<41:58,  2.78s/it, lr=1.19e-6, step_loss=0.00921]Steps:  93%|█████████▎| 12095/13000 [04:58<41:58,  2.78s/it, lr=1.19e-6, step_loss=0.174]  Steps:  93%|█████████▎| 12095/13000 [04:58<41:58,  2.78s/it, lr=1.19e-6, step_loss=0.0731]Steps:  93%|█████████▎| 12095/13000 [04:59<41:58,  2.78s/it, lr=1.19e-6, step_loss=0.145] Steps:  93%|█████████▎| 12096/13000 [04:59<36:01,  2.39s/it, lr=1.19e-6, step_loss=0.145]Steps:  93%|█████████▎| 12096/13000 [04:59<36:01,  2.39s/it, lr=1.19e-6, step_loss=0.0098]Steps:  93%|█████████▎| 12096/13000 [04:59<36:01,  2.39s/it, lr=1.19e-6, step_loss=0.00337]Steps:  93%|█████████▎| 12096/13000 [05:00<36:01,  2.39s/it, lr=1.19e-6, step_loss=0.101]  Steps:  93%|█████████▎| 12096/13000 [05:00<36:01,  2.39s/it, lr=1.19e-6, step_loss=0.12] Steps:  93%|█████████▎| 12097/13000 [05:00<31:47,  2.11s/it, lr=1.19e-6, step_loss=0.12]Steps:  93%|█████████▎| 12097/13000 [05:00<31:47,  2.11s/it, lr=1.19e-6, step_loss=0.0341]Steps:  93%|█████████▎| 12097/13000 [05:01<31:47,  2.11s/it, lr=1.19e-6, step_loss=0.0357]Steps:  93%|█████████▎| 12097/13000 [05:01<31:47,  2.11s/it, lr=1.19e-6, step_loss=0.0168]Steps:  93%|█████████▎| 12097/13000 [05:01<31:47,  2.11s/it, lr=1.19e-6, step_loss=0.358] Steps:  93%|█████████▎| 12098/13000 [05:02<28:49,  1.92s/it, lr=1.19e-6, step_loss=0.358]Steps:  93%|█████████▎| 12098/13000 [05:02<28:49,  1.92s/it, lr=1.18e-6, step_loss=0.0603]Steps:  93%|█████████▎| 12098/13000 [05:02<28:49,  1.92s/it, lr=1.18e-6, step_loss=0.0324]Steps:  93%|█████████▎| 12099/13000 [05:03<23:20,  1.55s/it, lr=1.18e-6, step_loss=0.0324]Steps:  93%|█████████▎| 12099/13000 [05:03<23:20,  1.55s/it, lr=1.18e-6, step_loss=0.119] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.19it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.59it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.89it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.47it/s]
02/23/2025 15:48:29 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12099/13000 [05:16<23:20,  1.55s/it, lr=1.18e-6, step_loss=0.0385]Steps:  93%|█████████▎| 12099/13000 [05:17<23:20,  1.55s/it, lr=1.18e-6, step_loss=0.19]  Steps:  93%|█████████▎| 12099/13000 [05:17<23:20,  1.55s/it, lr=1.18e-6, step_loss=0.095]Steps:  93%|█████████▎| 12100/13000 [05:17<1:23:06,  5.54s/it, lr=1.18e-6, step_loss=0.095]Steps:  93%|█████████▎| 12100/13000 [05:17<1:23:06,  5.54s/it, lr=1.18e-6, step_loss=0.104]Steps:  93%|█████████▎| 12100/13000 [05:18<1:23:06,  5.54s/it, lr=1.18e-6, step_loss=0.063]Steps:  93%|█████████▎| 12100/13000 [05:18<1:23:06,  5.54s/it, lr=1.18e-6, step_loss=0.0766]Steps:  93%|█████████▎| 12100/13000 [05:19<1:23:06,  5.54s/it, lr=1.18e-6, step_loss=0.00777]Steps:  93%|█████████▎| 12101/13000 [05:19<1:04:40,  4.32s/it, lr=1.18e-6, step_loss=0.00777]Steps:  93%|█████████▎| 12101/13000 [05:19<1:04:40,  4.32s/it, lr=1.18e-6, step_loss=0.0783] Steps:  93%|█████████▎| 12101/13000 [05:19<1:04:40,  4.32s/it, lr=1.18e-6, step_loss=0.0928]Steps:  93%|█████████▎| 12101/13000 [05:20<1:04:40,  4.32s/it, lr=1.18e-6, step_loss=0.0307]Steps:  93%|█████████▎| 12101/13000 [05:20<1:04:40,  4.32s/it, lr=1.18e-6, step_loss=0.208] Steps:  93%|█████████▎| 12102/13000 [05:20<51:36,  3.45s/it, lr=1.18e-6, step_loss=0.208]  Steps:  93%|█████████▎| 12102/13000 [05:20<51:36,  3.45s/it, lr=1.17e-6, step_loss=0.0105]Steps:  93%|█████████▎| 12102/13000 [05:21<51:36,  3.45s/it, lr=1.17e-6, step_loss=0.0886]Steps:  93%|█████████▎| 12102/13000 [05:21<51:36,  3.45s/it, lr=1.17e-6, step_loss=0.0841]Steps:  93%|█████████▎| 12102/13000 [05:21<51:36,  3.45s/it, lr=1.17e-6, step_loss=0.0364]Steps:  93%|█████████▎| 12103/13000 [05:22<42:38,  2.85s/it, lr=1.17e-6, step_loss=0.0364]Steps:  93%|█████████▎| 12103/13000 [05:22<42:38,  2.85s/it, lr=1.17e-6, step_loss=0.125] Steps:  93%|█████████▎| 12103/13000 [05:22<42:38,  2.85s/it, lr=1.17e-6, step_loss=0.156]Steps:  93%|█████████▎| 12103/13000 [05:22<42:38,  2.85s/it, lr=1.17e-6, step_loss=0.123]Steps:  93%|█████████▎| 12103/13000 [05:23<42:38,  2.85s/it, lr=1.17e-6, step_loss=0.0232]Steps:  93%|█████████▎| 12104/13000 [05:23<36:22,  2.44s/it, lr=1.17e-6, step_loss=0.0232]Steps:  93%|█████████▎| 12104/13000 [05:24<36:22,  2.44s/it, lr=1.17e-6, step_loss=0.0676]Steps:  93%|█████████▎| 12104/13000 [05:24<36:22,  2.44s/it, lr=1.17e-6, step_loss=0.0631]Steps:  93%|█████████▎| 12104/13000 [05:25<36:22,  2.44s/it, lr=1.17e-6, step_loss=0.0379]Steps:  93%|█████████▎| 12104/13000 [05:25<36:22,  2.44s/it, lr=1.17e-6, step_loss=0.00591]Steps:  93%|█████████▎| 12105/13000 [05:25<34:56,  2.34s/it, lr=1.17e-6, step_loss=0.00591]Steps:  93%|█████████▎| 12105/13000 [05:25<34:56,  2.34s/it, lr=1.16e-6, step_loss=0.0104] Steps:  93%|█████████▎| 12105/13000 [05:26<34:56,  2.34s/it, lr=1.16e-6, step_loss=0.0191]Steps:  93%|█████████▎| 12105/13000 [05:26<34:56,  2.34s/it, lr=1.16e-6, step_loss=0.331] Steps:  93%|█████████▎| 12105/13000 [05:26<34:56,  2.34s/it, lr=1.16e-6, step_loss=0.0559]Steps:  93%|█████████▎| 12106/13000 [05:27<30:56,  2.08s/it, lr=1.16e-6, step_loss=0.0559]Steps:  93%|█████████▎| 12106/13000 [05:27<30:56,  2.08s/it, lr=1.16e-6, step_loss=0.049] Steps:  93%|█████████▎| 12106/13000 [05:27<30:56,  2.08s/it, lr=1.16e-6, step_loss=0.0267]Steps:  93%|█████████▎| 12106/13000 [05:28<30:56,  2.08s/it, lr=1.16e-6, step_loss=0.858] Steps:  93%|█████████▎| 12106/13000 [05:28<30:56,  2.08s/it, lr=1.16e-6, step_loss=0.138]Steps:  93%|█████████▎| 12107/13000 [05:28<28:11,  1.89s/it, lr=1.16e-6, step_loss=0.138]Steps:  93%|█████████▎| 12107/13000 [05:29<28:11,  1.89s/it, lr=1.16e-6, step_loss=0.00315]Steps:  93%|█████████▎| 12107/13000 [05:29<28:11,  1.89s/it, lr=1.16e-6, step_loss=0.0539] Steps:  93%|█████████▎| 12108/13000 [05:30<25:29,  1.71s/it, lr=1.16e-6, step_loss=0.0539]Steps:  93%|█████████▎| 12108/13000 [05:30<25:29,  1.71s/it, lr=1.16e-6, step_loss=0.00995]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.55it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.41it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.15it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.68it/s]
02/23/2025 15:48:56 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12108/13000 [05:45<25:29,  1.71s/it, lr=1.16e-6, step_loss=0.125]  Steps:  93%|█████████▎| 12108/13000 [05:45<25:29,  1.71s/it, lr=1.16e-6, step_loss=0.049]Steps:  93%|█████████▎| 12108/13000 [05:45<25:29,  1.71s/it, lr=1.16e-6, step_loss=0.205]Steps:  93%|█████████▎| 12109/13000 [05:46<1:29:55,  6.06s/it, lr=1.16e-6, step_loss=0.205]Steps:  93%|█████████▎| 12109/13000 [05:46<1:29:55,  6.06s/it, lr=1.15e-6, step_loss=0.248]Steps:  93%|█████████▎| 12109/13000 [05:46<1:29:55,  6.06s/it, lr=1.15e-6, step_loss=0.0104]Steps:  93%|█████████▎| 12109/13000 [05:46<1:29:55,  6.06s/it, lr=1.15e-6, step_loss=0.00358]Steps:  93%|█████████▎| 12109/13000 [05:47<1:29:55,  6.06s/it, lr=1.15e-6, step_loss=0.24]   Steps:  93%|█████████▎| 12110/13000 [05:47<1:09:18,  4.67s/it, lr=1.15e-6, step_loss=0.24]Steps:  93%|█████████▎| 12110/13000 [05:47<1:09:18,  4.67s/it, lr=1.15e-6, step_loss=0.0181]Steps:  93%|█████████▎| 12110/13000 [05:48<1:09:18,  4.67s/it, lr=1.15e-6, step_loss=0.0283]Steps:  93%|█████████▎| 12110/13000 [05:48<1:09:18,  4.67s/it, lr=1.15e-6, step_loss=0.0887]Steps:  93%|█████████▎| 12110/13000 [05:48<1:09:18,  4.67s/it, lr=1.15e-6, step_loss=0.0395]Steps:  93%|█████████▎| 12111/13000 [05:49<55:00,  3.71s/it, lr=1.15e-6, step_loss=0.0395]  Steps:  93%|█████████▎| 12111/13000 [05:49<55:00,  3.71s/it, lr=1.15e-6, step_loss=0.328] Steps:  93%|█████████▎| 12111/13000 [05:49<55:00,  3.71s/it, lr=1.15e-6, step_loss=0.0487]Steps:  93%|█████████▎| 12111/13000 [05:49<55:00,  3.71s/it, lr=1.15e-6, step_loss=0.4]   Steps:  93%|█████████▎| 12111/13000 [05:50<55:00,  3.71s/it, lr=1.15e-6, step_loss=0.00486]Steps:  93%|█████████▎| 12112/13000 [05:50<44:49,  3.03s/it, lr=1.15e-6, step_loss=0.00486]Steps:  93%|█████████▎| 12112/13000 [05:50<44:49,  3.03s/it, lr=1.15e-6, step_loss=0.0125] Steps:  93%|█████████▎| 12112/13000 [05:50<44:49,  3.03s/it, lr=1.15e-6, step_loss=0.00231]Steps:  93%|█████████▎| 12112/13000 [05:51<44:49,  3.03s/it, lr=1.15e-6, step_loss=0.0431] Steps:  93%|█████████▎| 12112/13000 [05:51<44:49,  3.03s/it, lr=1.15e-6, step_loss=0.00506]Steps:  93%|█████████▎| 12113/13000 [05:52<37:53,  2.56s/it, lr=1.15e-6, step_loss=0.00506]Steps:  93%|█████████▎| 12113/13000 [05:52<37:53,  2.56s/it, lr=1.14e-6, step_loss=0.162]  Steps:  93%|█████████▎| 12113/13000 [05:52<37:53,  2.56s/it, lr=1.14e-6, step_loss=0.359]Steps:  93%|█████████▎| 12113/13000 [05:52<37:53,  2.56s/it, lr=1.14e-6, step_loss=0.0225]Steps:  93%|█████████▎| 12113/13000 [05:53<37:53,  2.56s/it, lr=1.14e-6, step_loss=0.0832]Steps:  93%|█████████▎| 12114/13000 [05:53<32:43,  2.22s/it, lr=1.14e-6, step_loss=0.0832]Steps:  93%|█████████▎| 12114/13000 [05:53<32:43,  2.22s/it, lr=1.14e-6, step_loss=0.00373]Steps:  93%|█████████▎| 12114/13000 [05:53<32:43,  2.22s/it, lr=1.14e-6, step_loss=0.0686] Steps:  93%|█████████▎| 12114/13000 [05:54<32:43,  2.22s/it, lr=1.14e-6, step_loss=0.00736]Steps:  93%|█████████▎| 12114/13000 [05:54<32:43,  2.22s/it, lr=1.14e-6, step_loss=0.124]  Steps:  93%|█████████▎| 12115/13000 [05:54<29:20,  1.99s/it, lr=1.14e-6, step_loss=0.124]Steps:  93%|█████████▎| 12115/13000 [05:54<29:20,  1.99s/it, lr=1.14e-6, step_loss=0.127]Steps:  93%|█████████▎| 12115/13000 [05:55<29:20,  1.99s/it, lr=1.14e-6, step_loss=0.163]Steps:  93%|█████████▎| 12115/13000 [05:55<29:20,  1.99s/it, lr=1.14e-6, step_loss=0.0767]Steps:  93%|█████████▎| 12115/13000 [05:56<29:20,  1.99s/it, lr=1.14e-6, step_loss=0.0543]Steps:  93%|█████████▎| 12116/13000 [05:56<26:45,  1.82s/it, lr=1.14e-6, step_loss=0.0543]Steps:  93%|█████████▎| 12116/13000 [05:56<26:45,  1.82s/it, lr=1.14e-6, step_loss=0.0172]Steps:  93%|█████████▎| 12116/13000 [05:56<26:45,  1.82s/it, lr=1.14e-6, step_loss=0.215] Steps:  93%|█████████▎| 12117/13000 [05:57<21:51,  1.49s/it, lr=1.14e-6, step_loss=0.215]Steps:  93%|█████████▎| 12117/13000 [05:57<21:51,  1.49s/it, lr=1.13e-6, step_loss=0.536]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.25it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.83it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.59it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.13it/s]
02/23/2025 15:49:23 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12117/13000 [06:11<21:51,  1.49s/it, lr=1.13e-6, step_loss=0.0141]Steps:  93%|█████████▎| 12117/13000 [06:12<21:51,  1.49s/it, lr=1.13e-6, step_loss=0.372] Steps:  93%|█████████▎| 12117/13000 [06:12<21:51,  1.49s/it, lr=1.13e-6, step_loss=0.0778]Steps:  93%|█████████▎| 12118/13000 [06:12<1:25:17,  5.80s/it, lr=1.13e-6, step_loss=0.0778]Steps:  93%|█████████▎| 12118/13000 [06:12<1:25:17,  5.80s/it, lr=1.13e-6, step_loss=0.00767]Steps:  93%|█████████▎| 12118/13000 [06:13<1:25:17,  5.80s/it, lr=1.13e-6, step_loss=0.113]  Steps:  93%|█████████▎| 12118/13000 [06:13<1:25:17,  5.80s/it, lr=1.13e-6, step_loss=0.00739]Steps:  93%|█████████▎| 12118/13000 [06:14<1:25:17,  5.80s/it, lr=1.13e-6, step_loss=0.0372] Steps:  93%|█████████▎| 12119/13000 [06:14<1:06:15,  4.51s/it, lr=1.13e-6, step_loss=0.0372]Steps:  93%|█████████▎| 12119/13000 [06:14<1:06:15,  4.51s/it, lr=1.13e-6, step_loss=0.439] Steps:  93%|█████████▎| 12119/13000 [06:14<1:06:15,  4.51s/it, lr=1.13e-6, step_loss=0.0331]Steps:  93%|█████████▎| 12119/13000 [06:15<1:06:15,  4.51s/it, lr=1.13e-6, step_loss=0.0137]Steps:  93%|█████████▎| 12119/13000 [06:15<1:06:15,  4.51s/it, lr=1.13e-6, step_loss=0.0135]Steps:  93%|█████████▎| 12120/13000 [06:15<52:45,  3.60s/it, lr=1.13e-6, step_loss=0.0135]  Steps:  93%|█████████▎| 12120/13000 [06:15<52:45,  3.60s/it, lr=1.13e-6, step_loss=0.143] Steps:  93%|█████████▎| 12120/13000 [06:16<52:45,  3.60s/it, lr=1.13e-6, step_loss=0.0343]Steps:  93%|█████████▎| 12120/13000 [06:16<52:45,  3.60s/it, lr=1.13e-6, step_loss=0.00269]Steps:  93%|█████████▎| 12120/13000 [06:16<52:45,  3.60s/it, lr=1.13e-6, step_loss=0.0173] Steps:  93%|█████████▎| 12121/13000 [06:17<43:12,  2.95s/it, lr=1.13e-6, step_loss=0.0173]Steps:  93%|█████████▎| 12121/13000 [06:17<43:12,  2.95s/it, lr=1.12e-6, step_loss=0.00607]Steps:  93%|█████████▎| 12121/13000 [06:17<43:12,  2.95s/it, lr=1.12e-6, step_loss=0.0334] Steps:  93%|█████████▎| 12121/13000 [06:18<43:12,  2.95s/it, lr=1.12e-6, step_loss=0.105] Steps:  93%|█████████▎| 12121/13000 [06:18<43:12,  2.95s/it, lr=1.12e-6, step_loss=0.0121]Steps:  93%|█████████▎| 12122/13000 [06:18<36:42,  2.51s/it, lr=1.12e-6, step_loss=0.0121]Steps:  93%|█████████▎| 12122/13000 [06:18<36:42,  2.51s/it, lr=1.12e-6, step_loss=0.0049]Steps:  93%|█████████▎| 12122/13000 [06:19<36:42,  2.51s/it, lr=1.12e-6, step_loss=0.0649]Steps:  93%|█████████▎| 12122/13000 [06:19<36:42,  2.51s/it, lr=1.12e-6, step_loss=0.0209]Steps:  93%|█████████▎| 12122/13000 [06:19<36:42,  2.51s/it, lr=1.12e-6, step_loss=0.0788]Steps:  93%|█████████▎| 12123/13000 [06:20<31:52,  2.18s/it, lr=1.12e-6, step_loss=0.0788]Steps:  93%|█████████▎| 12123/13000 [06:20<31:52,  2.18s/it, lr=1.12e-6, step_loss=0.00915]Steps:  93%|█████████▎| 12123/13000 [06:20<31:52,  2.18s/it, lr=1.12e-6, step_loss=0.0588] Steps:  93%|█████████▎| 12123/13000 [06:20<31:52,  2.18s/it, lr=1.12e-6, step_loss=0.0796]Steps:  93%|█████████▎| 12123/13000 [06:21<31:52,  2.18s/it, lr=1.12e-6, step_loss=0.0781]Steps:  93%|█████████▎| 12124/13000 [06:21<28:33,  1.96s/it, lr=1.12e-6, step_loss=0.0781]Steps:  93%|█████████▎| 12124/13000 [06:21<28:33,  1.96s/it, lr=1.12e-6, step_loss=0.224] Steps:  93%|█████████▎| 12124/13000 [06:22<28:33,  1.96s/it, lr=1.12e-6, step_loss=0.00541]Steps:  93%|█████████▎| 12124/13000 [06:22<28:33,  1.96s/it, lr=1.12e-6, step_loss=0.0726] Steps:  93%|█████████▎| 12124/13000 [06:22<28:33,  1.96s/it, lr=1.12e-6, step_loss=0.147] Steps:  93%|█████████▎| 12125/13000 [06:23<26:13,  1.80s/it, lr=1.12e-6, step_loss=0.147]Steps:  93%|█████████▎| 12125/13000 [06:23<26:13,  1.80s/it, lr=1.11e-6, step_loss=0.00642]Steps:  93%|█████████▎| 12125/13000 [06:23<26:13,  1.80s/it, lr=1.11e-6, step_loss=0.0387] Steps:  93%|█████████▎| 12126/13000 [06:23<21:24,  1.47s/it, lr=1.11e-6, step_loss=0.0387]Steps:  93%|█████████▎| 12126/13000 [06:23<21:24,  1.47s/it, lr=1.11e-6, step_loss=0.0265]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.00it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.48it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.89it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.45it/s]
02/23/2025 15:49:50 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12126/13000 [06:40<21:24,  1.47s/it, lr=1.11e-6, step_loss=0.0628]Steps:  93%|█████████▎| 12126/13000 [06:40<21:24,  1.47s/it, lr=1.11e-6, step_loss=0.125] Steps:  93%|█████████▎| 12126/13000 [06:40<21:24,  1.47s/it, lr=1.11e-6, step_loss=0.00999]Steps:  93%|█████████▎| 12127/13000 [06:41<1:31:07,  6.26s/it, lr=1.11e-6, step_loss=0.00999]Steps:  93%|█████████▎| 12127/13000 [06:41<1:31:07,  6.26s/it, lr=1.11e-6, step_loss=0.0989] Steps:  93%|█████████▎| 12127/13000 [06:41<1:31:07,  6.26s/it, lr=1.11e-6, step_loss=0.0112]Steps:  93%|█████████▎| 12127/13000 [06:42<1:31:07,  6.26s/it, lr=1.11e-6, step_loss=0.143] Steps:  93%|█████████▎| 12127/13000 [06:42<1:31:07,  6.26s/it, lr=1.11e-6, step_loss=0.0851]Steps:  93%|█████████▎| 12128/13000 [06:42<1:10:09,  4.83s/it, lr=1.11e-6, step_loss=0.0851]Steps:  93%|█████████▎| 12128/13000 [06:42<1:10:09,  4.83s/it, lr=1.11e-6, step_loss=0.165] Steps:  93%|█████████▎| 12128/13000 [06:43<1:10:09,  4.83s/it, lr=1.11e-6, step_loss=0.00943]Steps:  93%|█████████▎| 12128/13000 [06:43<1:10:09,  4.83s/it, lr=1.11e-6, step_loss=0.137]  Steps:  93%|█████████▎| 12128/13000 [06:43<1:10:09,  4.83s/it, lr=1.11e-6, step_loss=0.0329]Steps:  93%|█████████▎| 12129/13000 [06:44<55:30,  3.82s/it, lr=1.11e-6, step_loss=0.0329]  Steps:  93%|█████████▎| 12129/13000 [06:44<55:30,  3.82s/it, lr=1.1e-6, step_loss=0.0365] Steps:  93%|█████████▎| 12129/13000 [06:44<55:30,  3.82s/it, lr=1.1e-6, step_loss=0.00771]Steps:  93%|█████████▎| 12129/13000 [06:44<55:30,  3.82s/it, lr=1.1e-6, step_loss=0.146]  Steps:  93%|█████████▎| 12129/13000 [06:45<55:30,  3.82s/it, lr=1.1e-6, step_loss=0.261]Steps:  93%|█████████▎| 12130/13000 [06:45<45:14,  3.12s/it, lr=1.1e-6, step_loss=0.261]Steps:  93%|█████████▎| 12130/13000 [06:45<45:14,  3.12s/it, lr=1.1e-6, step_loss=0.0468]Steps:  93%|█████████▎| 12130/13000 [06:46<45:14,  3.12s/it, lr=1.1e-6, step_loss=0.00874]Steps:  93%|█████████▎| 12130/13000 [06:46<45:14,  3.12s/it, lr=1.1e-6, step_loss=0.164]  Steps:  93%|█████████▎| 12130/13000 [06:46<45:14,  3.12s/it, lr=1.1e-6, step_loss=0.0629]Steps:  93%|█████████▎| 12131/13000 [06:47<38:00,  2.62s/it, lr=1.1e-6, step_loss=0.0629]Steps:  93%|█████████▎| 12131/13000 [06:47<38:00,  2.62s/it, lr=1.1e-6, step_loss=0.0458]Steps:  93%|█████████▎| 12131/13000 [06:47<38:00,  2.62s/it, lr=1.1e-6, step_loss=0.0668]Steps:  93%|█████████▎| 12131/13000 [06:47<38:00,  2.62s/it, lr=1.1e-6, step_loss=0.101] Steps:  93%|█████████▎| 12131/13000 [06:48<38:00,  2.62s/it, lr=1.1e-6, step_loss=0.124]Steps:  93%|█████████▎| 12132/13000 [06:48<32:41,  2.26s/it, lr=1.1e-6, step_loss=0.124]Steps:  93%|█████████▎| 12132/13000 [06:48<32:41,  2.26s/it, lr=1.1e-6, step_loss=0.085]Steps:  93%|█████████▎| 12132/13000 [06:48<32:41,  2.26s/it, lr=1.1e-6, step_loss=0.00829]Steps:  93%|█████████▎| 12132/13000 [06:49<32:41,  2.26s/it, lr=1.1e-6, step_loss=0.153]  Steps:  93%|█████████▎| 12132/13000 [06:49<32:41,  2.26s/it, lr=1.1e-6, step_loss=0.0134]Steps:  93%|█████████▎| 12133/13000 [06:49<28:56,  2.00s/it, lr=1.1e-6, step_loss=0.0134]Steps:  93%|█████████▎| 12133/13000 [06:49<28:56,  2.00s/it, lr=1.09e-6, step_loss=0.0416]Steps:  93%|█████████▎| 12133/13000 [06:50<28:56,  2.00s/it, lr=1.09e-6, step_loss=0.00491]Steps:  93%|█████████▎| 12133/13000 [06:50<28:56,  2.00s/it, lr=1.09e-6, step_loss=0.201]  Steps:  93%|█████████▎| 12133/13000 [06:51<28:56,  2.00s/it, lr=1.09e-6, step_loss=0.399]Steps:  93%|█████████▎| 12134/13000 [06:51<26:27,  1.83s/it, lr=1.09e-6, step_loss=0.399]Steps:  93%|█████████▎| 12134/13000 [06:51<26:27,  1.83s/it, lr=1.09e-6, step_loss=0.0385]Steps:  93%|█████████▎| 12134/13000 [06:51<26:27,  1.83s/it, lr=1.09e-6, step_loss=0.572] Steps:  93%|█████████▎| 12135/13000 [06:52<21:28,  1.49s/it, lr=1.09e-6, step_loss=0.572]Steps:  93%|█████████▎| 12135/13000 [06:52<21:28,  1.49s/it, lr=1.09e-6, step_loss=0.0372]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.20it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.90it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.65it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.18it/s]
02/23/2025 15:50:19 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12135/13000 [07:07<21:28,  1.49s/it, lr=1.09e-6, step_loss=0.0784]Steps:  93%|█████████▎| 12135/13000 [07:07<21:28,  1.49s/it, lr=1.09e-6, step_loss=0.0314]Steps:  93%|█████████▎| 12135/13000 [07:07<21:28,  1.49s/it, lr=1.09e-6, step_loss=0.0395]Steps:  93%|█████████▎| 12136/13000 [07:08<1:24:03,  5.84s/it, lr=1.09e-6, step_loss=0.0395]Steps:  93%|█████████▎| 12136/13000 [07:08<1:24:03,  5.84s/it, lr=1.09e-6, step_loss=0.169] Steps:  93%|█████████▎| 12136/13000 [07:08<1:24:03,  5.84s/it, lr=1.09e-6, step_loss=0.0834]Steps:  93%|█████████▎| 12136/13000 [07:08<1:24:03,  5.84s/it, lr=1.09e-6, step_loss=0.0517]Steps:  93%|█████████▎| 12136/13000 [07:09<1:24:03,  5.84s/it, lr=1.09e-6, step_loss=0.133] Steps:  93%|█████████▎| 12137/13000 [07:09<1:05:50,  4.58s/it, lr=1.09e-6, step_loss=0.133]Steps:  93%|█████████▎| 12137/13000 [07:09<1:05:50,  4.58s/it, lr=1.08e-6, step_loss=0.0377]Steps:  93%|█████████▎| 12137/13000 [07:10<1:05:50,  4.58s/it, lr=1.08e-6, step_loss=0.0216]Steps:  93%|█████████▎| 12137/13000 [07:10<1:05:50,  4.58s/it, lr=1.08e-6, step_loss=0.0409]Steps:  93%|█████████▎| 12137/13000 [07:10<1:05:50,  4.58s/it, lr=1.08e-6, step_loss=0.0136]Steps:  93%|█████████▎| 12138/13000 [07:11<52:12,  3.63s/it, lr=1.08e-6, step_loss=0.0136]  Steps:  93%|█████████▎| 12138/13000 [07:11<52:12,  3.63s/it, lr=1.08e-6, step_loss=0.11]  Steps:  93%|█████████▎| 12138/13000 [07:11<52:12,  3.63s/it, lr=1.08e-6, step_loss=0.0163]Steps:  93%|█████████▎| 12138/13000 [07:12<52:12,  3.63s/it, lr=1.08e-6, step_loss=0.0914]Steps:  93%|█████████▎| 12138/13000 [07:12<52:12,  3.63s/it, lr=1.08e-6, step_loss=0.0543]Steps:  93%|█████████▎| 12139/13000 [07:12<44:12,  3.08s/it, lr=1.08e-6, step_loss=0.0543]Steps:  93%|█████████▎| 12139/13000 [07:12<44:12,  3.08s/it, lr=1.08e-6, step_loss=0.033] Steps:  93%|█████████▎| 12139/13000 [07:13<44:12,  3.08s/it, lr=1.08e-6, step_loss=0.00981]Steps:  93%|█████████▎| 12139/13000 [07:13<44:12,  3.08s/it, lr=1.08e-6, step_loss=0.0465] Steps:  93%|█████████▎| 12139/13000 [07:14<44:12,  3.08s/it, lr=1.08e-6, step_loss=0.0211]Steps:  93%|█████████▎| 12140/13000 [07:14<37:12,  2.60s/it, lr=1.08e-6, step_loss=0.0211]Steps:  93%|█████████▎| 12140/13000 [07:15<37:12,  2.60s/it, lr=1.08e-6, step_loss=0.0794]Steps:  93%|█████████▎| 12140/13000 [07:15<37:12,  2.60s/it, lr=1.08e-6, step_loss=0.39]  Steps:  93%|█████████▎| 12140/13000 [07:16<37:12,  2.60s/it, lr=1.08e-6, step_loss=0.00322]Steps:  93%|█████████▎| 12140/13000 [07:16<37:12,  2.60s/it, lr=1.08e-6, step_loss=0.145]  Steps:  93%|█████████▎| 12141/13000 [07:16<37:04,  2.59s/it, lr=1.08e-6, step_loss=0.145]Steps:  93%|█████████▎| 12141/13000 [07:17<37:04,  2.59s/it, lr=1.07e-6, step_loss=0.0665]Steps:  93%|█████████▎| 12141/13000 [07:17<37:04,  2.59s/it, lr=1.07e-6, step_loss=0.0887]Steps:  93%|█████████▎| 12141/13000 [07:17<37:04,  2.59s/it, lr=1.07e-6, step_loss=0.381] Steps:  93%|█████████▎| 12141/13000 [07:18<37:04,  2.59s/it, lr=1.07e-6, step_loss=0.226]Steps:  93%|█████████▎| 12142/13000 [07:18<33:06,  2.31s/it, lr=1.07e-6, step_loss=0.226]Steps:  93%|█████████▎| 12142/13000 [07:18<33:06,  2.31s/it, lr=1.07e-6, step_loss=0.00762]Steps:  93%|█████████▎| 12142/13000 [07:19<33:06,  2.31s/it, lr=1.07e-6, step_loss=0.228]  Steps:  93%|█████████▎| 12142/13000 [07:19<33:06,  2.31s/it, lr=1.07e-6, step_loss=0.124]Steps:  93%|█████████▎| 12142/13000 [07:19<33:06,  2.31s/it, lr=1.07e-6, step_loss=0.515]Steps:  93%|█████████▎| 12143/13000 [07:20<29:28,  2.06s/it, lr=1.07e-6, step_loss=0.515]Steps:  93%|█████████▎| 12143/13000 [07:20<29:28,  2.06s/it, lr=1.07e-6, step_loss=0.0919]Steps:  93%|█████████▎| 12143/13000 [07:20<29:28,  2.06s/it, lr=1.07e-6, step_loss=0.142] Steps:  93%|█████████▎| 12144/13000 [07:20<23:32,  1.65s/it, lr=1.07e-6, step_loss=0.142]Steps:  93%|█████████▎| 12144/13000 [07:20<23:32,  1.65s/it, lr=1.07e-6, step_loss=0.0139]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.54it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.30it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.76it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.35it/s]
02/23/2025 15:50:47 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12144/13000 [07:35<23:32,  1.65s/it, lr=1.07e-6, step_loss=0.07]  Steps:  93%|█████████▎| 12144/13000 [07:35<23:32,  1.65s/it, lr=1.07e-6, step_loss=0.00429]Steps:  93%|█████████▎| 12144/13000 [07:35<23:32,  1.65s/it, lr=1.07e-6, step_loss=0.187]  Steps:  93%|█████████▎| 12145/13000 [07:36<1:22:07,  5.76s/it, lr=1.07e-6, step_loss=0.187]Steps:  93%|█████████▎| 12145/13000 [07:36<1:22:07,  5.76s/it, lr=1.06e-6, step_loss=0.0106]Steps:  93%|█████████▎| 12145/13000 [07:36<1:22:07,  5.76s/it, lr=1.06e-6, step_loss=0.0041]Steps:  93%|█████████▎| 12145/13000 [07:37<1:22:07,  5.76s/it, lr=1.06e-6, step_loss=0.211] Steps:  93%|█████████▎| 12145/13000 [07:37<1:22:07,  5.76s/it, lr=1.06e-6, step_loss=0.0499]Steps:  93%|█████████▎| 12146/13000 [07:38<1:06:10,  4.65s/it, lr=1.06e-6, step_loss=0.0499]Steps:  93%|█████████▎| 12146/13000 [07:39<1:06:10,  4.65s/it, lr=1.06e-6, step_loss=0.121] Steps:  93%|█████████▎| 12146/13000 [07:40<1:06:10,  4.65s/it, lr=1.06e-6, step_loss=0.00546]Steps:  93%|█████████▎| 12146/13000 [07:40<1:06:10,  4.65s/it, lr=1.06e-6, step_loss=0.139]  Steps:  93%|█████████▎| 12146/13000 [07:40<1:06:10,  4.65s/it, lr=1.06e-6, step_loss=0.0237]Steps:  93%|█████████▎| 12147/13000 [07:41<58:31,  4.12s/it, lr=1.06e-6, step_loss=0.0237]  Steps:  93%|█████████▎| 12147/13000 [07:41<58:31,  4.12s/it, lr=1.06e-6, step_loss=0.172] Steps:  93%|█████████▎| 12147/13000 [07:41<58:31,  4.12s/it, lr=1.06e-6, step_loss=0.021]Steps:  93%|█████████▎| 12147/13000 [07:41<58:31,  4.12s/it, lr=1.06e-6, step_loss=0.115]Steps:  93%|█████████▎| 12147/13000 [07:42<58:31,  4.12s/it, lr=1.06e-6, step_loss=0.1]  Steps:  93%|█████████▎| 12148/13000 [07:45<57:49,  4.07s/it, lr=1.06e-6, step_loss=0.1]Steps:  93%|█████████▎| 12148/13000 [07:45<57:49,  4.07s/it, lr=1.06e-6, step_loss=0.00697]Steps:  93%|█████████▎| 12148/13000 [07:45<57:49,  4.07s/it, lr=1.06e-6, step_loss=0.0937] Steps:  93%|█████████▎| 12148/13000 [07:45<57:49,  4.07s/it, lr=1.06e-6, step_loss=0.00696]Steps:  93%|█████████▎| 12148/13000 [07:46<57:49,  4.07s/it, lr=1.06e-6, step_loss=0.104]  Steps:  93%|█████████▎| 12149/13000 [07:46<46:30,  3.28s/it, lr=1.06e-6, step_loss=0.104]Steps:  93%|█████████▎| 12149/13000 [07:46<46:30,  3.28s/it, lr=1.05e-6, step_loss=0.0323]Steps:  93%|█████████▎| 12149/13000 [07:46<46:30,  3.28s/it, lr=1.05e-6, step_loss=0.439] Steps:  93%|█████████▎| 12149/13000 [07:47<46:30,  3.28s/it, lr=1.05e-6, step_loss=0.0603]Steps:  93%|█████████▎| 12149/13000 [07:47<46:30,  3.28s/it, lr=1.05e-6, step_loss=0.275] Steps:  93%|█████████▎| 12150/13000 [07:47<38:47,  2.74s/it, lr=1.05e-6, step_loss=0.275]Steps:  93%|█████████▎| 12150/13000 [07:47<38:47,  2.74s/it, lr=1.05e-6, step_loss=0.167]Steps:  93%|█████████▎| 12150/13000 [07:48<38:47,  2.74s/it, lr=1.05e-6, step_loss=0.0186]Steps:  93%|█████████▎| 12150/13000 [07:48<38:47,  2.74s/it, lr=1.05e-6, step_loss=0.0912]Steps:  93%|█████████▎| 12150/13000 [07:49<38:47,  2.74s/it, lr=1.05e-6, step_loss=0.252] Steps:  93%|█████████▎| 12151/13000 [07:49<33:21,  2.36s/it, lr=1.05e-6, step_loss=0.252]Steps:  93%|█████████▎| 12151/13000 [07:49<33:21,  2.36s/it, lr=1.05e-6, step_loss=0.0482]Steps:  93%|█████████▎| 12151/13000 [07:49<33:21,  2.36s/it, lr=1.05e-6, step_loss=0.0483]Steps:  93%|█████████▎| 12151/13000 [07:50<33:21,  2.36s/it, lr=1.05e-6, step_loss=0.108] Steps:  93%|█████████▎| 12151/13000 [07:50<33:21,  2.36s/it, lr=1.05e-6, step_loss=0.0074]Steps:  93%|█████████▎| 12152/13000 [07:51<30:35,  2.16s/it, lr=1.05e-6, step_loss=0.0074]Steps:  93%|█████████▎| 12152/13000 [07:51<30:35,  2.16s/it, lr=1.05e-6, step_loss=0.0218]Steps:  93%|█████████▎| 12152/13000 [07:51<30:35,  2.16s/it, lr=1.05e-6, step_loss=0.0726]Steps:  93%|█████████▎| 12153/13000 [07:51<24:22,  1.73s/it, lr=1.05e-6, step_loss=0.0726]Steps:  93%|█████████▎| 12153/13000 [07:51<24:22,  1.73s/it, lr=1.04e-6, step_loss=0.413] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.18it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.50it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.86it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.43it/s]
02/23/2025 15:51:18 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  93%|█████████▎| 12153/13000 [08:06<24:22,  1.73s/it, lr=1.04e-6, step_loss=0.0371]Steps:  93%|█████████▎| 12153/13000 [08:06<24:22,  1.73s/it, lr=1.04e-6, step_loss=0.0141]Steps:  93%|█████████▎| 12153/13000 [08:06<24:22,  1.73s/it, lr=1.04e-6, step_loss=0.0617]Steps:  93%|█████████▎| 12154/13000 [08:07<1:21:29,  5.78s/it, lr=1.04e-6, step_loss=0.0617]Steps:  93%|█████████▎| 12154/13000 [08:07<1:21:29,  5.78s/it, lr=1.04e-6, step_loss=0.174] Steps:  93%|█████████▎| 12154/13000 [08:07<1:21:29,  5.78s/it, lr=1.04e-6, step_loss=0.0386]Steps:  93%|█████████▎| 12154/13000 [08:07<1:21:29,  5.78s/it, lr=1.04e-6, step_loss=0.00341]Steps:  93%|█████████▎| 12154/13000 [08:08<1:21:29,  5.78s/it, lr=1.04e-6, step_loss=0.117]  Steps:  94%|█████████▎| 12155/13000 [08:08<1:03:09,  4.49s/it, lr=1.04e-6, step_loss=0.117]Steps:  94%|█████████▎| 12155/13000 [08:08<1:03:09,  4.49s/it, lr=1.04e-6, step_loss=0.0932]Steps:  94%|█████████▎| 12155/13000 [08:08<1:03:09,  4.49s/it, lr=1.04e-6, step_loss=0.00654]Steps:  94%|█████████▎| 12155/13000 [08:09<1:03:09,  4.49s/it, lr=1.04e-6, step_loss=0.0385] Steps:  94%|█████████▎| 12155/13000 [08:09<1:03:09,  4.49s/it, lr=1.04e-6, step_loss=0.11]  Steps:  94%|█████████▎| 12156/13000 [08:09<50:14,  3.57s/it, lr=1.04e-6, step_loss=0.11]  Steps:  94%|█████████▎| 12156/13000 [08:10<50:14,  3.57s/it, lr=1.04e-6, step_loss=0.0812]Steps:  94%|█████████▎| 12156/13000 [08:10<50:14,  3.57s/it, lr=1.04e-6, step_loss=0.0584]Steps:  94%|█████████▎| 12156/13000 [08:10<50:14,  3.57s/it, lr=1.04e-6, step_loss=0.139] Steps:  94%|█████████▎| 12156/13000 [08:11<50:14,  3.57s/it, lr=1.04e-6, step_loss=0.0534]Steps:  94%|█████████▎| 12157/13000 [08:11<42:04,  2.99s/it, lr=1.04e-6, step_loss=0.0534]Steps:  94%|█████████▎| 12157/13000 [08:11<42:04,  2.99s/it, lr=1.03e-6, step_loss=0.0459]Steps:  94%|█████████▎| 12157/13000 [08:12<42:04,  2.99s/it, lr=1.03e-6, step_loss=0.0333]Steps:  94%|█████████▎| 12157/13000 [08:12<42:04,  2.99s/it, lr=1.03e-6, step_loss=0.36]  Steps:  94%|█████████▎| 12157/13000 [08:12<42:04,  2.99s/it, lr=1.03e-6, step_loss=0.0148]Steps:  94%|█████████▎| 12158/13000 [08:13<35:21,  2.52s/it, lr=1.03e-6, step_loss=0.0148]Steps:  94%|█████████▎| 12158/13000 [08:13<35:21,  2.52s/it, lr=1.03e-6, step_loss=0.0132]Steps:  94%|█████████▎| 12158/13000 [08:13<35:21,  2.52s/it, lr=1.03e-6, step_loss=0.00822]Steps:  94%|█████████▎| 12158/13000 [08:13<35:21,  2.52s/it, lr=1.03e-6, step_loss=0.0773] Steps:  94%|█████████▎| 12158/13000 [08:14<35:21,  2.52s/it, lr=1.03e-6, step_loss=0.0157]Steps:  94%|█████████▎| 12159/13000 [08:14<30:54,  2.21s/it, lr=1.03e-6, step_loss=0.0157]Steps:  94%|█████████▎| 12159/13000 [08:14<30:54,  2.21s/it, lr=1.03e-6, step_loss=0.0169]Steps:  94%|█████████▎| 12159/13000 [08:14<30:54,  2.21s/it, lr=1.03e-6, step_loss=0.194] Steps:  94%|█████████▎| 12159/13000 [08:15<30:54,  2.21s/it, lr=1.03e-6, step_loss=0.0689]Steps:  94%|█████████▎| 12159/13000 [08:15<30:54,  2.21s/it, lr=1.03e-6, step_loss=0.0927]Steps:  94%|█████████▎| 12160/13000 [08:15<27:52,  1.99s/it, lr=1.03e-6, step_loss=0.0927]Steps:  94%|█████████▎| 12160/13000 [08:17<27:52,  1.99s/it, lr=1.03e-6, step_loss=0.0322]Steps:  94%|█████████▎| 12160/13000 [08:18<27:52,  1.99s/it, lr=1.03e-6, step_loss=0.205] Steps:  94%|█████████▎| 12160/13000 [08:18<27:52,  1.99s/it, lr=1.03e-6, step_loss=0.14] Steps:  94%|█████████▎| 12160/13000 [08:18<27:52,  1.99s/it, lr=1.03e-6, step_loss=0.0202]Steps:  94%|█████████▎| 12161/13000 [08:19<32:20,  2.31s/it, lr=1.03e-6, step_loss=0.0202]Steps:  94%|█████████▎| 12161/13000 [08:19<32:20,  2.31s/it, lr=1.02e-6, step_loss=0.6]   Steps:  94%|█████████▎| 12161/13000 [08:19<32:20,  2.31s/it, lr=1.02e-6, step_loss=0.0715]Steps:  94%|█████████▎| 12162/13000 [08:19<25:34,  1.83s/it, lr=1.02e-6, step_loss=0.0715]Steps:  94%|█████████▎| 12162/13000 [08:19<25:34,  1.83s/it, lr=1.02e-6, step_loss=0.165] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.93it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.84it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.58it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.15it/s]
02/23/2025 15:51:46 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▎| 12162/13000 [08:34<25:34,  1.83s/it, lr=1.02e-6, step_loss=0.0439]Steps:  94%|█████████▎| 12162/13000 [08:34<25:34,  1.83s/it, lr=1.02e-6, step_loss=0.219] Steps:  94%|█████████▎| 12162/13000 [08:34<25:34,  1.83s/it, lr=1.02e-6, step_loss=0.0924]Steps:  94%|█████████▎| 12163/13000 [08:35<1:22:07,  5.89s/it, lr=1.02e-6, step_loss=0.0924]Steps:  94%|█████████▎| 12163/13000 [08:35<1:22:07,  5.89s/it, lr=1.02e-6, step_loss=0.0932]Steps:  94%|█████████▎| 12163/13000 [08:35<1:22:07,  5.89s/it, lr=1.02e-6, step_loss=0.0119]Steps:  94%|█████████▎| 12163/13000 [08:35<1:22:07,  5.89s/it, lr=1.02e-6, step_loss=0.0985]Steps:  94%|█████████▎| 12163/13000 [08:36<1:22:07,  5.89s/it, lr=1.02e-6, step_loss=0.022] Steps:  94%|█████████▎| 12164/13000 [08:36<1:03:31,  4.56s/it, lr=1.02e-6, step_loss=0.022]Steps:  94%|█████████▎| 12164/13000 [08:36<1:03:31,  4.56s/it, lr=1.02e-6, step_loss=0.0174]Steps:  94%|█████████▎| 12164/13000 [08:36<1:03:31,  4.56s/it, lr=1.02e-6, step_loss=0.0477]Steps:  94%|█████████▎| 12164/13000 [08:37<1:03:31,  4.56s/it, lr=1.02e-6, step_loss=0.187] Steps:  94%|█████████▎| 12164/13000 [08:37<1:03:31,  4.56s/it, lr=1.02e-6, step_loss=0.0377]Steps:  94%|█████████▎| 12165/13000 [08:37<50:23,  3.62s/it, lr=1.02e-6, step_loss=0.0377]  Steps:  94%|█████████▎| 12165/13000 [08:38<50:23,  3.62s/it, lr=1.01e-6, step_loss=0.00897]Steps:  94%|█████████▎| 12165/13000 [08:38<50:23,  3.62s/it, lr=1.01e-6, step_loss=0.00303]Steps:  94%|█████████▎| 12165/13000 [08:38<50:23,  3.62s/it, lr=1.01e-6, step_loss=0.653]  Steps:  94%|█████████▎| 12165/13000 [08:40<50:23,  3.62s/it, lr=1.01e-6, step_loss=0.0744]Steps:  94%|█████████▎| 12166/13000 [08:40<45:21,  3.26s/it, lr=1.01e-6, step_loss=0.0744]Steps:  94%|█████████▎| 12166/13000 [08:40<45:21,  3.26s/it, lr=1.01e-6, step_loss=0.00617]Steps:  94%|█████████▎| 12166/13000 [08:40<45:21,  3.26s/it, lr=1.01e-6, step_loss=0.0552] Steps:  94%|█████████▎| 12166/13000 [08:41<45:21,  3.26s/it, lr=1.01e-6, step_loss=0.0558]Steps:  94%|█████████▎| 12166/13000 [08:41<45:21,  3.26s/it, lr=1.01e-6, step_loss=0.218] Steps:  94%|█████████▎| 12167/13000 [08:41<37:42,  2.72s/it, lr=1.01e-6, step_loss=0.218]Steps:  94%|█████████▎| 12167/13000 [08:41<37:42,  2.72s/it, lr=1.01e-6, step_loss=0.198]Steps:  94%|█████████▎| 12167/13000 [08:42<37:42,  2.72s/it, lr=1.01e-6, step_loss=0.153]Steps:  94%|█████████▎| 12167/13000 [08:42<37:42,  2.72s/it, lr=1.01e-6, step_loss=0.00395]Steps:  94%|█████████▎| 12167/13000 [08:42<37:42,  2.72s/it, lr=1.01e-6, step_loss=0.0642] Steps:  94%|█████████▎| 12168/13000 [08:43<32:21,  2.33s/it, lr=1.01e-6, step_loss=0.0642]Steps:  94%|█████████▎| 12168/13000 [08:43<32:21,  2.33s/it, lr=1.01e-6, step_loss=0.0025]Steps:  94%|█████████▎| 12168/13000 [08:43<32:21,  2.33s/it, lr=1.01e-6, step_loss=0.0889]Steps:  94%|█████████▎| 12168/13000 [08:44<32:21,  2.33s/it, lr=1.01e-6, step_loss=0.334] Steps:  94%|█████████▎| 12168/13000 [08:44<32:21,  2.33s/it, lr=1.01e-6, step_loss=0.00671]Steps:  94%|█████████▎| 12169/13000 [08:44<29:01,  2.10s/it, lr=1.01e-6, step_loss=0.00671]Steps:  94%|█████████▎| 12169/13000 [08:44<29:01,  2.10s/it, lr=1e-6, step_loss=0.00546]   Steps:  94%|█████████▎| 12169/13000 [08:45<29:01,  2.10s/it, lr=1e-6, step_loss=0.128]  Steps:  94%|█████████▎| 12169/13000 [08:45<29:01,  2.10s/it, lr=1e-6, step_loss=0.0107]Steps:  94%|█████████▎| 12169/13000 [08:46<29:01,  2.10s/it, lr=1e-6, step_loss=0.312] Steps:  94%|█████████▎| 12170/13000 [08:46<26:28,  1.91s/it, lr=1e-6, step_loss=0.312]Steps:  94%|█████████▎| 12170/13000 [08:46<26:28,  1.91s/it, lr=1e-6, step_loss=0.0979]Steps:  94%|█████████▎| 12170/13000 [08:46<26:28,  1.91s/it, lr=1e-6, step_loss=0.00307]Steps:  94%|█████████▎| 12171/13000 [08:47<21:27,  1.55s/it, lr=1e-6, step_loss=0.00307]Steps:  94%|█████████▎| 12171/13000 [08:47<21:27,  1.55s/it, lr=1e-6, step_loss=0.137]  {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.29it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.10it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.62it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.19it/s]
02/23/2025 15:52:13 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▎| 12171/13000 [09:01<21:27,  1.55s/it, lr=1e-6, step_loss=0.151]Steps:  94%|█████████▎| 12171/13000 [09:01<21:27,  1.55s/it, lr=1e-6, step_loss=0.0484]Steps:  94%|█████████▎| 12171/13000 [09:01<21:27,  1.55s/it, lr=1e-6, step_loss=0.529] Steps:  94%|█████████▎| 12172/13000 [09:02<1:17:27,  5.61s/it, lr=1e-6, step_loss=0.529]Steps:  94%|█████████▎| 12172/13000 [09:03<1:17:27,  5.61s/it, lr=9.98e-7, step_loss=0.15]Steps:  94%|█████████▎| 12172/13000 [09:04<1:17:27,  5.61s/it, lr=9.98e-7, step_loss=0.0597]Steps:  94%|█████████▎| 12172/13000 [09:04<1:17:27,  5.61s/it, lr=9.98e-7, step_loss=0.409] Steps:  94%|█████████▎| 12172/13000 [09:04<1:17:27,  5.61s/it, lr=9.98e-7, step_loss=0.0832]Steps:  94%|█████████▎| 12173/13000 [09:05<1:07:04,  4.87s/it, lr=9.98e-7, step_loss=0.0832]Steps:  94%|█████████▎| 12173/13000 [09:05<1:07:04,  4.87s/it, lr=9.95e-7, step_loss=0.0046]Steps:  94%|█████████▎| 12173/13000 [09:05<1:07:04,  4.87s/it, lr=9.95e-7, step_loss=0.0123]Steps:  94%|█████████▎| 12173/13000 [09:06<1:07:04,  4.87s/it, lr=9.95e-7, step_loss=0.128] Steps:  94%|█████████▎| 12173/13000 [09:06<1:07:04,  4.87s/it, lr=9.95e-7, step_loss=0.231]Steps:  94%|█████████▎| 12174/13000 [09:06<52:57,  3.85s/it, lr=9.95e-7, step_loss=0.231]  Steps:  94%|█████████▎| 12174/13000 [09:06<52:57,  3.85s/it, lr=9.93e-7, step_loss=0.3]  Steps:  94%|█████████▎| 12174/13000 [09:07<52:57,  3.85s/it, lr=9.93e-7, step_loss=0.104]Steps:  94%|█████████▎| 12174/13000 [09:07<52:57,  3.85s/it, lr=9.93e-7, step_loss=0.00504]Steps:  94%|█████████▎| 12174/13000 [09:07<52:57,  3.85s/it, lr=9.93e-7, step_loss=0.015]  Steps:  94%|█████████▎| 12175/13000 [09:08<42:48,  3.11s/it, lr=9.93e-7, step_loss=0.015]Steps:  94%|█████████▎| 12175/13000 [09:08<42:48,  3.11s/it, lr=9.9e-7, step_loss=0.542] Steps:  94%|█████████▎| 12175/13000 [09:08<42:48,  3.11s/it, lr=9.9e-7, step_loss=0.309]Steps:  94%|█████████▎| 12175/13000 [09:08<42:48,  3.11s/it, lr=9.9e-7, step_loss=0.0161]Steps:  94%|█████████▎| 12175/13000 [09:09<42:48,  3.11s/it, lr=9.9e-7, step_loss=0.0051]Steps:  94%|█████████▎| 12176/13000 [09:09<36:05,  2.63s/it, lr=9.9e-7, step_loss=0.0051]Steps:  94%|█████████▎| 12176/13000 [09:09<36:05,  2.63s/it, lr=9.88e-7, step_loss=0.0183]Steps:  94%|█████████▎| 12176/13000 [09:10<36:05,  2.63s/it, lr=9.88e-7, step_loss=0.0322]Steps:  94%|█████████▎| 12176/13000 [09:10<36:05,  2.63s/it, lr=9.88e-7, step_loss=0.13]  Steps:  94%|█████████▎| 12176/13000 [09:10<36:05,  2.63s/it, lr=9.88e-7, step_loss=0.0557]Steps:  94%|█████████▎| 12177/13000 [09:11<31:14,  2.28s/it, lr=9.88e-7, step_loss=0.0557]Steps:  94%|█████████▎| 12177/13000 [09:11<31:14,  2.28s/it, lr=9.86e-7, step_loss=0.0766]Steps:  94%|█████████▎| 12177/13000 [09:11<31:14,  2.28s/it, lr=9.86e-7, step_loss=0.198] Steps:  94%|█████████▎| 12177/13000 [09:11<31:14,  2.28s/it, lr=9.86e-7, step_loss=0.396]Steps:  94%|█████████▎| 12177/13000 [09:12<31:14,  2.28s/it, lr=9.86e-7, step_loss=0.0933]Steps:  94%|█████████▎| 12178/13000 [09:12<27:54,  2.04s/it, lr=9.86e-7, step_loss=0.0933]Steps:  94%|█████████▎| 12178/13000 [09:12<27:54,  2.04s/it, lr=9.83e-7, step_loss=0.196] Steps:  94%|█████████▎| 12178/13000 [09:12<27:54,  2.04s/it, lr=9.83e-7, step_loss=0.0117]Steps:  94%|█████████▎| 12178/13000 [09:13<27:54,  2.04s/it, lr=9.83e-7, step_loss=0.0557]Steps:  94%|█████████▎| 12178/13000 [09:13<27:54,  2.04s/it, lr=9.83e-7, step_loss=0.285] Steps:  94%|█████████▎| 12179/13000 [09:13<25:24,  1.86s/it, lr=9.83e-7, step_loss=0.285]Steps:  94%|█████████▎| 12179/13000 [09:14<25:24,  1.86s/it, lr=9.81e-7, step_loss=0.0116]Steps:  94%|█████████▎| 12179/13000 [09:14<25:24,  1.86s/it, lr=9.81e-7, step_loss=0.00565]Steps:  94%|█████████▎| 12180/13000 [09:14<20:33,  1.50s/it, lr=9.81e-7, step_loss=0.00565]Steps:  94%|█████████▎| 12180/13000 [09:14<20:33,  1.50s/it, lr=9.78e-7, step_loss=0.0143] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.17it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.50it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.82it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.40it/s]
02/23/2025 15:52:41 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▎| 12180/13000 [09:29<20:33,  1.50s/it, lr=9.78e-7, step_loss=0.0724]Steps:  94%|█████████▎| 12180/13000 [09:29<20:33,  1.50s/it, lr=9.78e-7, step_loss=0.0736]Steps:  94%|█████████▎| 12180/13000 [09:29<20:33,  1.50s/it, lr=9.78e-7, step_loss=0.0488]Steps:  94%|█████████▎| 12181/13000 [09:30<1:17:30,  5.68s/it, lr=9.78e-7, step_loss=0.0488]Steps:  94%|█████████▎| 12181/13000 [09:30<1:17:30,  5.68s/it, lr=9.76e-7, step_loss=0.0323]Steps:  94%|█████████▎| 12181/13000 [09:30<1:17:30,  5.68s/it, lr=9.76e-7, step_loss=0.0265]Steps:  94%|█████████▎| 12181/13000 [09:30<1:17:30,  5.68s/it, lr=9.76e-7, step_loss=0.106] Steps:  94%|█████████▎| 12181/13000 [09:31<1:17:30,  5.68s/it, lr=9.76e-7, step_loss=0.00766]Steps:  94%|█████████▎| 12182/13000 [09:31<1:00:08,  4.41s/it, lr=9.76e-7, step_loss=0.00766]Steps:  94%|█████████▎| 12182/13000 [09:31<1:00:08,  4.41s/it, lr=9.74e-7, step_loss=0.00557]Steps:  94%|█████████▎| 12182/13000 [09:31<1:00:08,  4.41s/it, lr=9.74e-7, step_loss=0.107]  Steps:  94%|█████████▎| 12182/13000 [09:32<1:00:08,  4.41s/it, lr=9.74e-7, step_loss=0.02] Steps:  94%|█████████▎| 12182/13000 [09:32<1:00:08,  4.41s/it, lr=9.74e-7, step_loss=0.0342]Steps:  94%|█████████▎| 12183/13000 [09:33<48:05,  3.53s/it, lr=9.74e-7, step_loss=0.0342]  Steps:  94%|█████████▎| 12183/13000 [09:33<48:05,  3.53s/it, lr=9.71e-7, step_loss=0.256] Steps:  94%|█████████▎| 12183/13000 [09:33<48:05,  3.53s/it, lr=9.71e-7, step_loss=0.00608]Steps:  94%|█████████▎| 12183/13000 [09:33<48:05,  3.53s/it, lr=9.71e-7, step_loss=0.045]  Steps:  94%|█████████▎| 12183/13000 [09:34<48:05,  3.53s/it, lr=9.71e-7, step_loss=0.0964]Steps:  94%|█████████▎| 12184/13000 [09:34<39:27,  2.90s/it, lr=9.71e-7, step_loss=0.0964]Steps:  94%|█████████▎| 12184/13000 [09:34<39:27,  2.90s/it, lr=9.69e-7, step_loss=0.0108]Steps:  94%|█████████▎| 12184/13000 [09:34<39:27,  2.90s/it, lr=9.69e-7, step_loss=0.038] Steps:  94%|█████████▎| 12184/13000 [09:35<39:27,  2.90s/it, lr=9.69e-7, step_loss=0.0213]Steps:  94%|█████████▎| 12184/13000 [09:35<39:27,  2.90s/it, lr=9.69e-7, step_loss=0.0378]Steps:  94%|█████████▎| 12185/13000 [09:35<33:32,  2.47s/it, lr=9.69e-7, step_loss=0.0378]Steps:  94%|█████████▎| 12185/13000 [09:35<33:32,  2.47s/it, lr=9.67e-7, step_loss=0.218] Steps:  94%|█████████▎| 12185/13000 [09:36<33:32,  2.47s/it, lr=9.67e-7, step_loss=0.0389]Steps:  94%|█████████▎| 12185/13000 [09:36<33:32,  2.47s/it, lr=9.67e-7, step_loss=0.138] Steps:  94%|█████████▎| 12185/13000 [09:37<33:32,  2.47s/it, lr=9.67e-7, step_loss=0.658]Steps:  94%|█████████▎| 12186/13000 [09:37<29:18,  2.16s/it, lr=9.67e-7, step_loss=0.658]Steps:  94%|█████████▎| 12186/13000 [09:37<29:18,  2.16s/it, lr=9.64e-7, step_loss=0.103]Steps:  94%|█████████▎| 12186/13000 [09:37<29:18,  2.16s/it, lr=9.64e-7, step_loss=0.0131]Steps:  94%|█████████▎| 12186/13000 [09:38<29:18,  2.16s/it, lr=9.64e-7, step_loss=0.861] Steps:  94%|█████████▎| 12186/13000 [09:38<29:18,  2.16s/it, lr=9.64e-7, step_loss=0.15] Steps:  94%|█████████▎| 12187/13000 [09:38<26:26,  1.95s/it, lr=9.64e-7, step_loss=0.15]Steps:  94%|█████████▎| 12187/13000 [09:38<26:26,  1.95s/it, lr=9.62e-7, step_loss=0.0219]Steps:  94%|█████████▎| 12187/13000 [09:39<26:26,  1.95s/it, lr=9.62e-7, step_loss=0.00293]Steps:  94%|█████████▎| 12187/13000 [09:39<26:26,  1.95s/it, lr=9.62e-7, step_loss=0.138]  Steps:  94%|█████████▎| 12187/13000 [09:39<26:26,  1.95s/it, lr=9.62e-7, step_loss=0.0215]Steps:  94%|█████████▍| 12188/13000 [09:40<24:16,  1.79s/it, lr=9.62e-7, step_loss=0.0215]Steps:  94%|█████████▍| 12188/13000 [09:40<24:16,  1.79s/it, lr=9.6e-7, step_loss=0.00669]Steps:  94%|█████████▍| 12188/13000 [09:40<24:16,  1.79s/it, lr=9.6e-7, step_loss=0.0234] Steps:  94%|█████████▍| 12189/13000 [09:40<19:50,  1.47s/it, lr=9.6e-7, step_loss=0.0234]Steps:  94%|█████████▍| 12189/13000 [09:41<19:50,  1.47s/it, lr=9.57e-7, step_loss=0.0379]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.76it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.05it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.37it/s]
02/23/2025 15:53:07 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12189/13000 [09:55<19:50,  1.47s/it, lr=9.57e-7, step_loss=0.046] Steps:  94%|█████████▍| 12189/13000 [09:55<19:50,  1.47s/it, lr=9.57e-7, step_loss=0.0288]Steps:  94%|█████████▍| 12189/13000 [09:56<19:50,  1.47s/it, lr=9.57e-7, step_loss=0.0895]Steps:  94%|█████████▍| 12190/13000 [09:56<1:17:07,  5.71s/it, lr=9.57e-7, step_loss=0.0895]Steps:  94%|█████████▍| 12190/13000 [09:56<1:17:07,  5.71s/it, lr=9.55e-7, step_loss=0.0266]Steps:  94%|█████████▍| 12190/13000 [09:57<1:17:07,  5.71s/it, lr=9.55e-7, step_loss=0.192] Steps:  94%|█████████▍| 12190/13000 [09:57<1:17:07,  5.71s/it, lr=9.55e-7, step_loss=0.384]Steps:  94%|█████████▍| 12190/13000 [09:57<1:17:07,  5.71s/it, lr=9.55e-7, step_loss=0.0576]Steps:  94%|█████████▍| 12191/13000 [09:58<59:48,  4.44s/it, lr=9.55e-7, step_loss=0.0576]  Steps:  94%|█████████▍| 12191/13000 [09:58<59:48,  4.44s/it, lr=9.53e-7, step_loss=0.1]   Steps:  94%|█████████▍| 12191/13000 [09:58<59:48,  4.44s/it, lr=9.53e-7, step_loss=0.107]Steps:  94%|█████████▍| 12191/13000 [09:58<59:48,  4.44s/it, lr=9.53e-7, step_loss=0.0589]Steps:  94%|█████████▍| 12191/13000 [09:59<59:48,  4.44s/it, lr=9.53e-7, step_loss=0.119] Steps:  94%|█████████▍| 12192/13000 [09:59<47:37,  3.54s/it, lr=9.53e-7, step_loss=0.119]Steps:  94%|█████████▍| 12192/13000 [09:59<47:37,  3.54s/it, lr=9.5e-7, step_loss=0.0693]Steps:  94%|█████████▍| 12192/13000 [09:59<47:37,  3.54s/it, lr=9.5e-7, step_loss=0.029] Steps:  94%|█████████▍| 12192/13000 [10:00<47:37,  3.54s/it, lr=9.5e-7, step_loss=0.144]Steps:  94%|█████████▍| 12192/13000 [10:01<47:37,  3.54s/it, lr=9.5e-7, step_loss=0.00332]Steps:  94%|█████████▍| 12193/13000 [10:01<42:29,  3.16s/it, lr=9.5e-7, step_loss=0.00332]Steps:  94%|█████████▍| 12193/13000 [10:01<42:29,  3.16s/it, lr=9.48e-7, step_loss=0.0248]Steps:  94%|█████████▍| 12193/13000 [10:02<42:29,  3.16s/it, lr=9.48e-7, step_loss=0.527] Steps:  94%|█████████▍| 12193/13000 [10:02<42:29,  3.16s/it, lr=9.48e-7, step_loss=0.14] Steps:  94%|█████████▍| 12193/13000 [10:02<42:29,  3.16s/it, lr=9.48e-7, step_loss=0.0705]Steps:  94%|█████████▍| 12194/13000 [10:03<35:36,  2.65s/it, lr=9.48e-7, step_loss=0.0705]Steps:  94%|█████████▍| 12194/13000 [10:03<35:36,  2.65s/it, lr=9.45e-7, step_loss=0.00406]Steps:  94%|█████████▍| 12194/13000 [10:03<35:36,  2.65s/it, lr=9.45e-7, step_loss=0.0169] Steps:  94%|█████████▍| 12194/13000 [10:03<35:36,  2.65s/it, lr=9.45e-7, step_loss=0.0151]Steps:  94%|█████████▍| 12194/13000 [10:04<35:36,  2.65s/it, lr=9.45e-7, step_loss=0.0132]Steps:  94%|█████████▍| 12195/13000 [10:04<30:39,  2.29s/it, lr=9.45e-7, step_loss=0.0132]Steps:  94%|█████████▍| 12195/13000 [10:04<30:39,  2.29s/it, lr=9.43e-7, step_loss=0.388] Steps:  94%|█████████▍| 12195/13000 [10:05<30:39,  2.29s/it, lr=9.43e-7, step_loss=0.00674]Steps:  94%|█████████▍| 12195/13000 [10:05<30:39,  2.29s/it, lr=9.43e-7, step_loss=0.0734] Steps:  94%|█████████▍| 12195/13000 [10:05<30:39,  2.29s/it, lr=9.43e-7, step_loss=0.135] Steps:  94%|█████████▍| 12196/13000 [10:06<27:24,  2.05s/it, lr=9.43e-7, step_loss=0.135]Steps:  94%|█████████▍| 12196/13000 [10:06<27:24,  2.05s/it, lr=9.41e-7, step_loss=0.0491]Steps:  94%|█████████▍| 12196/13000 [10:06<27:24,  2.05s/it, lr=9.41e-7, step_loss=0.1]   Steps:  94%|█████████▍| 12196/13000 [10:07<27:24,  2.05s/it, lr=9.41e-7, step_loss=0.122]Steps:  94%|█████████▍| 12196/13000 [10:07<27:24,  2.05s/it, lr=9.41e-7, step_loss=0.166]Steps:  94%|█████████▍| 12197/13000 [10:07<26:14,  1.96s/it, lr=9.41e-7, step_loss=0.166]Steps:  94%|█████████▍| 12197/13000 [10:07<26:14,  1.96s/it, lr=9.38e-7, step_loss=0.00798]Steps:  94%|█████████▍| 12197/13000 [10:08<26:14,  1.96s/it, lr=9.38e-7, step_loss=0.23]   Steps:  94%|█████████▍| 12198/13000 [10:08<21:07,  1.58s/it, lr=9.38e-7, step_loss=0.23]Steps:  94%|█████████▍| 12198/13000 [10:08<21:07,  1.58s/it, lr=9.36e-7, step_loss=0.015]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.34it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.54it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.41it/s]
02/23/2025 15:53:35 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12198/13000 [10:23<21:07,  1.58s/it, lr=9.36e-7, step_loss=0.0132]Steps:  94%|█████████▍| 12198/13000 [10:23<21:07,  1.58s/it, lr=9.36e-7, step_loss=0.15]  Steps:  94%|█████████▍| 12198/13000 [10:24<21:07,  1.58s/it, lr=9.36e-7, step_loss=0.134]Steps:  94%|█████████▍| 12199/13000 [10:24<1:18:19,  5.87s/it, lr=9.36e-7, step_loss=0.134]Steps:  94%|█████████▍| 12199/13000 [10:24<1:18:19,  5.87s/it, lr=9.34e-7, step_loss=0.0879]Steps:  94%|█████████▍| 12199/13000 [10:24<1:18:19,  5.87s/it, lr=9.34e-7, step_loss=0.0636]Steps:  94%|█████████▍| 12199/13000 [10:25<1:18:19,  5.87s/it, lr=9.34e-7, step_loss=0.302] Steps:  94%|█████████▍| 12199/13000 [10:25<1:18:19,  5.87s/it, lr=9.34e-7, step_loss=0.177]Steps:  94%|█████████▍| 12200/13000 [10:25<1:00:28,  4.54s/it, lr=9.34e-7, step_loss=0.177]Steps:  94%|█████████▍| 12200/13000 [10:25<1:00:28,  4.54s/it, lr=9.31e-7, step_loss=0.103]Steps:  94%|█████████▍| 12200/13000 [10:26<1:00:28,  4.54s/it, lr=9.31e-7, step_loss=0.123]Steps:  94%|█████████▍| 12200/13000 [10:26<1:00:28,  4.54s/it, lr=9.31e-7, step_loss=0.292]Steps:  94%|█████████▍| 12200/13000 [10:27<1:00:28,  4.54s/it, lr=9.31e-7, step_loss=0.0179]Steps:  94%|█████████▍| 12201/13000 [10:27<48:06,  3.61s/it, lr=9.31e-7, step_loss=0.0179]  Steps:  94%|█████████▍| 12201/13000 [10:27<48:06,  3.61s/it, lr=9.29e-7, step_loss=0.0563]Steps:  94%|█████████▍| 12201/13000 [10:27<48:06,  3.61s/it, lr=9.29e-7, step_loss=0.11]  Steps:  94%|█████████▍| 12201/13000 [10:28<48:06,  3.61s/it, lr=9.29e-7, step_loss=0.102]Steps:  94%|█████████▍| 12201/13000 [10:28<48:06,  3.61s/it, lr=9.29e-7, step_loss=0.386]Steps:  94%|█████████▍| 12202/13000 [10:28<39:26,  2.97s/it, lr=9.29e-7, step_loss=0.386]Steps:  94%|█████████▍| 12202/13000 [10:28<39:26,  2.97s/it, lr=9.27e-7, step_loss=0.066]Steps:  94%|█████████▍| 12202/13000 [10:29<39:26,  2.97s/it, lr=9.27e-7, step_loss=0.0519]Steps:  94%|█████████▍| 12202/13000 [10:29<39:26,  2.97s/it, lr=9.27e-7, step_loss=0.116] Steps:  94%|█████████▍| 12202/13000 [10:29<39:26,  2.97s/it, lr=9.27e-7, step_loss=0.279]Steps:  94%|█████████▍| 12203/13000 [10:30<33:27,  2.52s/it, lr=9.27e-7, step_loss=0.279]Steps:  94%|█████████▍| 12203/13000 [10:30<33:27,  2.52s/it, lr=9.25e-7, step_loss=0.21] Steps:  94%|█████████▍| 12203/13000 [10:30<33:27,  2.52s/it, lr=9.25e-7, step_loss=0.205]Steps:  94%|█████████▍| 12203/13000 [10:31<33:27,  2.52s/it, lr=9.25e-7, step_loss=0.0511]Steps:  94%|█████████▍| 12203/13000 [10:31<33:27,  2.52s/it, lr=9.25e-7, step_loss=0.00435]Steps:  94%|█████████▍| 12204/13000 [10:31<29:10,  2.20s/it, lr=9.25e-7, step_loss=0.00435]Steps:  94%|█████████▍| 12204/13000 [10:31<29:10,  2.20s/it, lr=9.22e-7, step_loss=0.0652] Steps:  94%|█████████▍| 12204/13000 [10:32<29:10,  2.20s/it, lr=9.22e-7, step_loss=0.0189]Steps:  94%|█████████▍| 12204/13000 [10:32<29:10,  2.20s/it, lr=9.22e-7, step_loss=0.067] Steps:  94%|█████████▍| 12204/13000 [10:32<29:10,  2.20s/it, lr=9.22e-7, step_loss=0.104]Steps:  94%|█████████▍| 12205/13000 [10:33<26:13,  1.98s/it, lr=9.22e-7, step_loss=0.104]Steps:  94%|█████████▍| 12205/13000 [10:33<26:13,  1.98s/it, lr=9.2e-7, step_loss=0.0162]Steps:  94%|█████████▍| 12205/13000 [10:34<26:13,  1.98s/it, lr=9.2e-7, step_loss=0.00708]Steps:  94%|█████████▍| 12205/13000 [10:34<26:13,  1.98s/it, lr=9.2e-7, step_loss=0.0695] Steps:  94%|█████████▍| 12205/13000 [10:35<26:13,  1.98s/it, lr=9.2e-7, step_loss=0.0547]Steps:  94%|█████████▍| 12206/13000 [10:35<26:52,  2.03s/it, lr=9.2e-7, step_loss=0.0547]Steps:  94%|█████████▍| 12206/13000 [10:35<26:52,  2.03s/it, lr=9.18e-7, step_loss=0.00564]Steps:  94%|█████████▍| 12206/13000 [10:35<26:52,  2.03s/it, lr=9.18e-7, step_loss=0.121]  Steps:  94%|█████████▍| 12207/13000 [10:36<21:31,  1.63s/it, lr=9.18e-7, step_loss=0.121]Steps:  94%|█████████▍| 12207/13000 [10:36<21:31,  1.63s/it, lr=9.15e-7, step_loss=0.0117]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.10it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.91it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.60it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.14it/s]
02/23/2025 15:54:02 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12207/13000 [10:51<21:31,  1.63s/it, lr=9.15e-7, step_loss=0.212] Steps:  94%|█████████▍| 12207/13000 [10:51<21:31,  1.63s/it, lr=9.15e-7, step_loss=0.114]Steps:  94%|█████████▍| 12207/13000 [10:52<21:31,  1.63s/it, lr=9.15e-7, step_loss=0.0302]Steps:  94%|█████████▍| 12208/13000 [10:52<1:19:55,  6.06s/it, lr=9.15e-7, step_loss=0.0302]Steps:  94%|█████████▍| 12208/13000 [10:52<1:19:55,  6.06s/it, lr=9.13e-7, step_loss=0.0932]Steps:  94%|█████████▍| 12208/13000 [10:52<1:19:55,  6.06s/it, lr=9.13e-7, step_loss=0.208] Steps:  94%|█████████▍| 12208/13000 [10:53<1:19:55,  6.06s/it, lr=9.13e-7, step_loss=0.0414]Steps:  94%|█████████▍| 12208/13000 [10:53<1:19:55,  6.06s/it, lr=9.13e-7, step_loss=0.0331]Steps:  94%|█████████▍| 12209/13000 [10:53<1:01:36,  4.67s/it, lr=9.13e-7, step_loss=0.0331]Steps:  94%|█████████▍| 12209/13000 [10:53<1:01:36,  4.67s/it, lr=9.11e-7, step_loss=0.0616]Steps:  94%|█████████▍| 12209/13000 [10:54<1:01:36,  4.67s/it, lr=9.11e-7, step_loss=0.427] Steps:  94%|█████████▍| 12209/13000 [10:54<1:01:36,  4.67s/it, lr=9.11e-7, step_loss=0.0175]Steps:  94%|█████████▍| 12209/13000 [10:55<1:01:36,  4.67s/it, lr=9.11e-7, step_loss=0.0344]Steps:  94%|█████████▍| 12210/13000 [10:55<48:46,  3.70s/it, lr=9.11e-7, step_loss=0.0344]  Steps:  94%|█████████▍| 12210/13000 [10:55<48:46,  3.70s/it, lr=9.08e-7, step_loss=0.0212]Steps:  94%|█████████▍| 12210/13000 [10:55<48:46,  3.70s/it, lr=9.08e-7, step_loss=0.0108]Steps:  94%|█████████▍| 12210/13000 [10:56<48:46,  3.70s/it, lr=9.08e-7, step_loss=0.0054]Steps:  94%|█████████▍| 12210/13000 [10:56<48:46,  3.70s/it, lr=9.08e-7, step_loss=0.0732]Steps:  94%|█████████▍| 12211/13000 [10:56<39:53,  3.03s/it, lr=9.08e-7, step_loss=0.0732]Steps:  94%|█████████▍| 12211/13000 [10:56<39:53,  3.03s/it, lr=9.06e-7, step_loss=0.111] Steps:  94%|█████████▍| 12211/13000 [10:57<39:53,  3.03s/it, lr=9.06e-7, step_loss=0.179]Steps:  94%|█████████▍| 12211/13000 [10:57<39:53,  3.03s/it, lr=9.06e-7, step_loss=0.162]Steps:  94%|█████████▍| 12211/13000 [10:57<39:53,  3.03s/it, lr=9.06e-7, step_loss=0.0213]Steps:  94%|█████████▍| 12212/13000 [10:58<33:34,  2.56s/it, lr=9.06e-7, step_loss=0.0213]Steps:  94%|█████████▍| 12212/13000 [10:58<33:34,  2.56s/it, lr=9.04e-7, step_loss=0.201] Steps:  94%|█████████▍| 12212/13000 [10:58<33:34,  2.56s/it, lr=9.04e-7, step_loss=0.0486]Steps:  94%|█████████▍| 12212/13000 [10:59<33:34,  2.56s/it, lr=9.04e-7, step_loss=0.0384]Steps:  94%|█████████▍| 12212/13000 [10:59<33:34,  2.56s/it, lr=9.04e-7, step_loss=0.00451]Steps:  94%|█████████▍| 12213/13000 [10:59<29:14,  2.23s/it, lr=9.04e-7, step_loss=0.00451]Steps:  94%|█████████▍| 12213/13000 [10:59<29:14,  2.23s/it, lr=9.02e-7, step_loss=0.0555] Steps:  94%|█████████▍| 12213/13000 [11:00<29:14,  2.23s/it, lr=9.02e-7, step_loss=0.00411]Steps:  94%|█████████▍| 12213/13000 [11:00<29:14,  2.23s/it, lr=9.02e-7, step_loss=0.118]  Steps:  94%|█████████▍| 12213/13000 [11:00<29:14,  2.23s/it, lr=9.02e-7, step_loss=0.0127]Steps:  94%|█████████▍| 12214/13000 [11:01<26:13,  2.00s/it, lr=9.02e-7, step_loss=0.0127]Steps:  94%|█████████▍| 12214/13000 [11:01<26:13,  2.00s/it, lr=8.99e-7, step_loss=0.149] Steps:  94%|█████████▍| 12214/13000 [11:01<26:13,  2.00s/it, lr=8.99e-7, step_loss=0.127]Steps:  94%|█████████▍| 12214/13000 [11:03<26:13,  2.00s/it, lr=8.99e-7, step_loss=0.149]Steps:  94%|█████████▍| 12214/13000 [11:04<26:13,  2.00s/it, lr=8.99e-7, step_loss=0.0108]Steps:  94%|█████████▍| 12215/13000 [11:04<31:46,  2.43s/it, lr=8.99e-7, step_loss=0.0108]Steps:  94%|█████████▍| 12215/13000 [11:04<31:46,  2.43s/it, lr=8.97e-7, step_loss=0.168] Steps:  94%|█████████▍| 12215/13000 [11:04<31:46,  2.43s/it, lr=8.97e-7, step_loss=0.102]Steps:  94%|█████████▍| 12216/13000 [11:05<24:52,  1.90s/it, lr=8.97e-7, step_loss=0.102]Steps:  94%|█████████▍| 12216/13000 [11:05<24:52,  1.90s/it, lr=8.95e-7, step_loss=0.0107]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.31it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.99it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.18it/s]
02/23/2025 15:54:31 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12216/13000 [11:19<24:52,  1.90s/it, lr=8.95e-7, step_loss=0.386] Steps:  94%|█████████▍| 12216/13000 [11:20<24:52,  1.90s/it, lr=8.95e-7, step_loss=0.0375]Steps:  94%|█████████▍| 12216/13000 [11:20<24:52,  1.90s/it, lr=8.95e-7, step_loss=0.0333]Steps:  94%|█████████▍| 12217/13000 [11:20<1:18:07,  5.99s/it, lr=8.95e-7, step_loss=0.0333]Steps:  94%|█████████▍| 12217/13000 [11:20<1:18:07,  5.99s/it, lr=8.92e-7, step_loss=0.027] Steps:  94%|█████████▍| 12217/13000 [11:21<1:18:07,  5.99s/it, lr=8.92e-7, step_loss=0.0104]Steps:  94%|█████████▍| 12217/13000 [11:21<1:18:07,  5.99s/it, lr=8.92e-7, step_loss=0.0228]Steps:  94%|█████████▍| 12217/13000 [11:21<1:18:07,  5.99s/it, lr=8.92e-7, step_loss=0.016] Steps:  94%|█████████▍| 12218/13000 [11:22<1:00:13,  4.62s/it, lr=8.92e-7, step_loss=0.016]Steps:  94%|█████████▍| 12218/13000 [11:22<1:00:13,  4.62s/it, lr=8.9e-7, step_loss=0.0101]Steps:  94%|█████████▍| 12218/13000 [11:22<1:00:13,  4.62s/it, lr=8.9e-7, step_loss=0.16]  Steps:  94%|█████████▍| 12218/13000 [11:23<1:00:13,  4.62s/it, lr=8.9e-7, step_loss=0.0817]Steps:  94%|█████████▍| 12218/13000 [11:23<1:00:13,  4.62s/it, lr=8.9e-7, step_loss=0.119] Steps:  94%|█████████▍| 12219/13000 [11:23<47:57,  3.68s/it, lr=8.9e-7, step_loss=0.119]  Steps:  94%|█████████▍| 12219/13000 [11:23<47:57,  3.68s/it, lr=8.88e-7, step_loss=0.0166]Steps:  94%|█████████▍| 12219/13000 [11:24<47:57,  3.68s/it, lr=8.88e-7, step_loss=0.0928]Steps:  94%|█████████▍| 12219/13000 [11:24<47:57,  3.68s/it, lr=8.88e-7, step_loss=0.00637]Steps:  94%|█████████▍| 12219/13000 [11:24<47:57,  3.68s/it, lr=8.88e-7, step_loss=0.0263] Steps:  94%|█████████▍| 12220/13000 [11:25<39:13,  3.02s/it, lr=8.88e-7, step_loss=0.0263]Steps:  94%|█████████▍| 12220/13000 [11:25<39:13,  3.02s/it, lr=8.86e-7, step_loss=0.445] Steps:  94%|█████████▍| 12220/13000 [11:25<39:13,  3.02s/it, lr=8.86e-7, step_loss=0.035]Steps:  94%|█████████▍| 12220/13000 [11:25<39:13,  3.02s/it, lr=8.86e-7, step_loss=0.15] Steps:  94%|█████████▍| 12220/13000 [11:26<39:13,  3.02s/it, lr=8.86e-7, step_loss=0.0388]Steps:  94%|█████████▍| 12221/13000 [11:26<33:05,  2.55s/it, lr=8.86e-7, step_loss=0.0388]Steps:  94%|█████████▍| 12221/13000 [11:26<33:05,  2.55s/it, lr=8.83e-7, step_loss=0.0247]Steps:  94%|█████████▍| 12221/13000 [11:27<33:05,  2.55s/it, lr=8.83e-7, step_loss=0.00589]Steps:  94%|█████████▍| 12221/13000 [11:27<33:05,  2.55s/it, lr=8.83e-7, step_loss=0.0697] Steps:  94%|█████████▍| 12221/13000 [11:27<33:05,  2.55s/it, lr=8.83e-7, step_loss=0.0132]Steps:  94%|█████████▍| 12222/13000 [11:28<28:49,  2.22s/it, lr=8.83e-7, step_loss=0.0132]Steps:  94%|█████████▍| 12222/13000 [11:28<28:49,  2.22s/it, lr=8.81e-7, step_loss=0.00336]Steps:  94%|█████████▍| 12222/13000 [11:28<28:49,  2.22s/it, lr=8.81e-7, step_loss=0.183]  Steps:  94%|█████████▍| 12222/13000 [11:28<28:49,  2.22s/it, lr=8.81e-7, step_loss=0.114]Steps:  94%|█████████▍| 12222/13000 [11:29<28:49,  2.22s/it, lr=8.81e-7, step_loss=0.114]Steps:  94%|█████████▍| 12223/13000 [11:29<25:41,  1.98s/it, lr=8.81e-7, step_loss=0.114]Steps:  94%|█████████▍| 12223/13000 [11:29<25:41,  1.98s/it, lr=8.79e-7, step_loss=0.123]Steps:  94%|█████████▍| 12223/13000 [11:30<25:41,  1.98s/it, lr=8.79e-7, step_loss=0.0565]Steps:  94%|█████████▍| 12223/13000 [11:30<25:41,  1.98s/it, lr=8.79e-7, step_loss=0.057] Steps:  94%|█████████▍| 12223/13000 [11:30<25:41,  1.98s/it, lr=8.79e-7, step_loss=0.0136]Steps:  94%|█████████▍| 12224/13000 [11:31<24:54,  1.93s/it, lr=8.79e-7, step_loss=0.0136]Steps:  94%|█████████▍| 12224/13000 [11:31<24:54,  1.93s/it, lr=8.77e-7, step_loss=0.126] Steps:  94%|█████████▍| 12224/13000 [11:31<24:54,  1.93s/it, lr=8.77e-7, step_loss=0.0942]Steps:  94%|█████████▍| 12225/13000 [11:32<20:06,  1.56s/it, lr=8.77e-7, step_loss=0.0942]Steps:  94%|█████████▍| 12225/13000 [11:32<20:06,  1.56s/it, lr=8.74e-7, step_loss=0.0205]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.31it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.94it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.20it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.78it/s]
02/23/2025 15:54:58 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12225/13000 [11:46<20:06,  1.56s/it, lr=8.74e-7, step_loss=0.0297]Steps:  94%|█████████▍| 12225/13000 [11:46<20:06,  1.56s/it, lr=8.74e-7, step_loss=0.00387]Steps:  94%|█████████▍| 12225/13000 [11:47<20:06,  1.56s/it, lr=8.74e-7, step_loss=0.0812] Steps:  94%|█████████▍| 12226/13000 [11:47<1:14:38,  5.79s/it, lr=8.74e-7, step_loss=0.0812]Steps:  94%|█████████▍| 12226/13000 [11:47<1:14:38,  5.79s/it, lr=8.72e-7, step_loss=0.0482]Steps:  94%|█████████▍| 12226/13000 [11:48<1:14:38,  5.79s/it, lr=8.72e-7, step_loss=0.0466]Steps:  94%|█████████▍| 12226/13000 [11:48<1:14:38,  5.79s/it, lr=8.72e-7, step_loss=0.0271]Steps:  94%|█████████▍| 12226/13000 [11:48<1:14:38,  5.79s/it, lr=8.72e-7, step_loss=0.285] Steps:  94%|█████████▍| 12227/13000 [11:49<57:48,  4.49s/it, lr=8.72e-7, step_loss=0.285]  Steps:  94%|█████████▍| 12227/13000 [11:49<57:48,  4.49s/it, lr=8.7e-7, step_loss=0.0256]Steps:  94%|█████████▍| 12227/13000 [11:49<57:48,  4.49s/it, lr=8.7e-7, step_loss=0.0165]Steps:  94%|█████████▍| 12227/13000 [11:49<57:48,  4.49s/it, lr=8.7e-7, step_loss=0.0907]Steps:  94%|█████████▍| 12227/13000 [11:50<57:48,  4.49s/it, lr=8.7e-7, step_loss=0.0266]Steps:  94%|█████████▍| 12228/13000 [11:50<45:55,  3.57s/it, lr=8.7e-7, step_loss=0.0266]Steps:  94%|█████████▍| 12228/13000 [11:50<45:55,  3.57s/it, lr=8.68e-7, step_loss=0.00504]Steps:  94%|█████████▍| 12228/13000 [11:50<45:55,  3.57s/it, lr=8.68e-7, step_loss=0.68]   Steps:  94%|█████████▍| 12228/13000 [11:51<45:55,  3.57s/it, lr=8.68e-7, step_loss=0.0259]Steps:  94%|█████████▍| 12228/13000 [11:52<45:55,  3.57s/it, lr=8.68e-7, step_loss=0.0872]Steps:  94%|█████████▍| 12229/13000 [11:53<42:32,  3.31s/it, lr=8.68e-7, step_loss=0.0872]Steps:  94%|█████████▍| 12229/13000 [11:53<42:32,  3.31s/it, lr=8.65e-7, step_loss=0.115] Steps:  94%|█████████▍| 12229/13000 [11:53<42:32,  3.31s/it, lr=8.65e-7, step_loss=0.0088]Steps:  94%|█████████▍| 12229/13000 [11:54<42:32,  3.31s/it, lr=8.65e-7, step_loss=0.0898]Steps:  94%|█████████▍| 12229/13000 [11:54<42:32,  3.31s/it, lr=8.65e-7, step_loss=0.363] Steps:  94%|█████████▍| 12230/13000 [11:54<35:15,  2.75s/it, lr=8.65e-7, step_loss=0.363]Steps:  94%|█████████▍| 12230/13000 [11:54<35:15,  2.75s/it, lr=8.63e-7, step_loss=0.00799]Steps:  94%|█████████▍| 12230/13000 [11:55<35:15,  2.75s/it, lr=8.63e-7, step_loss=0.0151] Steps:  94%|█████████▍| 12230/13000 [11:55<35:15,  2.75s/it, lr=8.63e-7, step_loss=0.033] Steps:  94%|█████████▍| 12230/13000 [11:55<35:15,  2.75s/it, lr=8.63e-7, step_loss=0.117]Steps:  94%|█████████▍| 12231/13000 [11:56<30:12,  2.36s/it, lr=8.63e-7, step_loss=0.117]Steps:  94%|█████████▍| 12231/13000 [11:56<30:12,  2.36s/it, lr=8.61e-7, step_loss=0.025]Steps:  94%|█████████▍| 12231/13000 [11:56<30:12,  2.36s/it, lr=8.61e-7, step_loss=0.02] Steps:  94%|█████████▍| 12231/13000 [11:56<30:12,  2.36s/it, lr=8.61e-7, step_loss=0.00985]Steps:  94%|█████████▍| 12231/13000 [11:57<30:12,  2.36s/it, lr=8.61e-7, step_loss=0.262]  Steps:  94%|█████████▍| 12232/13000 [11:57<26:28,  2.07s/it, lr=8.61e-7, step_loss=0.262]Steps:  94%|█████████▍| 12232/13000 [11:58<26:28,  2.07s/it, lr=8.59e-7, step_loss=0.197]Steps:  94%|█████████▍| 12232/13000 [11:58<26:28,  2.07s/it, lr=8.59e-7, step_loss=0.00908]Steps:  94%|█████████▍| 12232/13000 [11:58<26:28,  2.07s/it, lr=8.59e-7, step_loss=0.0513] Steps:  94%|█████████▍| 12232/13000 [11:59<26:28,  2.07s/it, lr=8.59e-7, step_loss=0.0462]Steps:  94%|█████████▍| 12233/13000 [11:59<26:37,  2.08s/it, lr=8.59e-7, step_loss=0.0462]Steps:  94%|█████████▍| 12233/13000 [11:59<26:37,  2.08s/it, lr=8.56e-7, step_loss=0.0557]Steps:  94%|█████████▍| 12233/13000 [12:00<26:37,  2.08s/it, lr=8.56e-7, step_loss=0.00345]Steps:  94%|█████████▍| 12234/13000 [12:00<21:15,  1.67s/it, lr=8.56e-7, step_loss=0.00345]Steps:  94%|█████████▍| 12234/13000 [12:00<21:15,  1.67s/it, lr=8.54e-7, step_loss=0.0396] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.95it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.77it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.13it/s]
02/23/2025 15:55:26 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  94%|█████████▍| 12234/13000 [12:14<21:15,  1.67s/it, lr=8.54e-7, step_loss=0.0329]Steps:  94%|█████████▍| 12234/13000 [12:15<21:15,  1.67s/it, lr=8.54e-7, step_loss=0.0143]Steps:  94%|█████████▍| 12234/13000 [12:15<21:15,  1.67s/it, lr=8.54e-7, step_loss=0.058] Steps:  94%|█████████▍| 12235/13000 [12:15<1:14:27,  5.84s/it, lr=8.54e-7, step_loss=0.058]Steps:  94%|█████████▍| 12235/13000 [12:15<1:14:27,  5.84s/it, lr=8.52e-7, step_loss=0.232]Steps:  94%|█████████▍| 12235/13000 [12:16<1:14:27,  5.84s/it, lr=8.52e-7, step_loss=0.0279]Steps:  94%|█████████▍| 12235/13000 [12:16<1:14:27,  5.84s/it, lr=8.52e-7, step_loss=0.00586]Steps:  94%|█████████▍| 12235/13000 [12:17<1:14:27,  5.84s/it, lr=8.52e-7, step_loss=0.394]  Steps:  94%|█████████▍| 12236/13000 [12:17<57:41,  4.53s/it, lr=8.52e-7, step_loss=0.394]  Steps:  94%|█████████▍| 12236/13000 [12:17<57:41,  4.53s/it, lr=8.5e-7, step_loss=0.125] Steps:  94%|█████████▍| 12236/13000 [12:17<57:41,  4.53s/it, lr=8.5e-7, step_loss=0.0783]Steps:  94%|█████████▍| 12236/13000 [12:18<57:41,  4.53s/it, lr=8.5e-7, step_loss=0.212] Steps:  94%|█████████▍| 12236/13000 [12:18<57:41,  4.53s/it, lr=8.5e-7, step_loss=0.062]Steps:  94%|█████████▍| 12237/13000 [12:18<45:42,  3.59s/it, lr=8.5e-7, step_loss=0.062]Steps:  94%|█████████▍| 12237/13000 [12:18<45:42,  3.59s/it, lr=8.48e-7, step_loss=0.0767]Steps:  94%|█████████▍| 12237/13000 [12:19<45:42,  3.59s/it, lr=8.48e-7, step_loss=0.0501]Steps:  94%|█████████▍| 12237/13000 [12:19<45:42,  3.59s/it, lr=8.48e-7, step_loss=0.00808]Steps:  94%|█████████▍| 12237/13000 [12:19<45:42,  3.59s/it, lr=8.48e-7, step_loss=0.0157] Steps:  94%|█████████▍| 12238/13000 [12:20<37:17,  2.94s/it, lr=8.48e-7, step_loss=0.0157]Steps:  94%|█████████▍| 12238/13000 [12:20<37:17,  2.94s/it, lr=8.45e-7, step_loss=0.0417]Steps:  94%|█████████▍| 12238/13000 [12:20<37:17,  2.94s/it, lr=8.45e-7, step_loss=0.00475]Steps:  94%|█████████▍| 12238/13000 [12:20<37:17,  2.94s/it, lr=8.45e-7, step_loss=0.42]   Steps:  94%|█████████▍| 12238/13000 [12:21<37:17,  2.94s/it, lr=8.45e-7, step_loss=0.101]Steps:  94%|█████████▍| 12239/13000 [12:21<31:30,  2.48s/it, lr=8.45e-7, step_loss=0.101]Steps:  94%|█████████▍| 12239/13000 [12:21<31:30,  2.48s/it, lr=8.43e-7, step_loss=0.0106]Steps:  94%|█████████▍| 12239/13000 [12:22<31:30,  2.48s/it, lr=8.43e-7, step_loss=0.0239]Steps:  94%|█████████▍| 12239/13000 [12:22<31:30,  2.48s/it, lr=8.43e-7, step_loss=0.0716]Steps:  94%|█████████▍| 12239/13000 [12:22<31:30,  2.48s/it, lr=8.43e-7, step_loss=0.0412]Steps:  94%|█████████▍| 12240/13000 [12:23<27:40,  2.19s/it, lr=8.43e-7, step_loss=0.0412]Steps:  94%|█████████▍| 12240/13000 [12:23<27:40,  2.19s/it, lr=8.41e-7, step_loss=0.173] Steps:  94%|█████████▍| 12240/13000 [12:23<27:40,  2.19s/it, lr=8.41e-7, step_loss=0.0157]Steps:  94%|█████████▍| 12240/13000 [12:23<27:40,  2.19s/it, lr=8.41e-7, step_loss=0.0687]Steps:  94%|█████████▍| 12240/13000 [12:24<27:40,  2.19s/it, lr=8.41e-7, step_loss=0.0381]Steps:  94%|█████████▍| 12241/13000 [12:24<24:58,  1.97s/it, lr=8.41e-7, step_loss=0.0381]Steps:  94%|█████████▍| 12241/13000 [12:24<24:58,  1.97s/it, lr=8.39e-7, step_loss=0.0137]Steps:  94%|█████████▍| 12241/13000 [12:25<24:58,  1.97s/it, lr=8.39e-7, step_loss=0.0771]Steps:  94%|█████████▍| 12241/13000 [12:25<24:58,  1.97s/it, lr=8.39e-7, step_loss=0.0589]Steps:  94%|█████████▍| 12241/13000 [12:25<24:58,  1.97s/it, lr=8.39e-7, step_loss=0.0375]Steps:  94%|█████████▍| 12242/13000 [12:26<23:06,  1.83s/it, lr=8.39e-7, step_loss=0.0375]Steps:  94%|█████████▍| 12242/13000 [12:26<23:06,  1.83s/it, lr=8.37e-7, step_loss=0.0851]Steps:  94%|█████████▍| 12242/13000 [12:26<23:06,  1.83s/it, lr=8.37e-7, step_loss=0.0288]Steps:  94%|█████████▍| 12243/13000 [12:26<18:50,  1.49s/it, lr=8.37e-7, step_loss=0.0288]Steps:  94%|█████████▍| 12243/13000 [12:26<18:50,  1.49s/it, lr=8.34e-7, step_loss=0.0289]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.68it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.30it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.85it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.43it/s]
02/23/2025 15:55:53 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12243/13000 [12:40<18:50,  1.49s/it, lr=8.34e-7, step_loss=0.0368]Steps:  94%|█████████▍| 12243/13000 [12:41<18:50,  1.49s/it, lr=8.34e-7, step_loss=0.129] Steps:  94%|█████████▍| 12243/13000 [12:41<18:50,  1.49s/it, lr=8.34e-7, step_loss=0.306]Steps:  94%|█████████▍| 12244/13000 [12:42<1:10:40,  5.61s/it, lr=8.34e-7, step_loss=0.306]Steps:  94%|█████████▍| 12244/13000 [12:42<1:10:40,  5.61s/it, lr=8.32e-7, step_loss=0.561]Steps:  94%|█████████▍| 12244/13000 [12:42<1:10:40,  5.61s/it, lr=8.32e-7, step_loss=0.399]Steps:  94%|█████████▍| 12244/13000 [12:42<1:10:40,  5.61s/it, lr=8.32e-7, step_loss=0.148]Steps:  94%|█████████▍| 12244/13000 [12:43<1:10:40,  5.61s/it, lr=8.32e-7, step_loss=0.0128]Steps:  94%|█████████▍| 12245/13000 [12:43<54:58,  4.37s/it, lr=8.32e-7, step_loss=0.0128]  Steps:  94%|█████████▍| 12245/13000 [12:43<54:58,  4.37s/it, lr=8.3e-7, step_loss=0.0787] Steps:  94%|█████████▍| 12245/13000 [12:43<54:58,  4.37s/it, lr=8.3e-7, step_loss=0.0164]Steps:  94%|█████████▍| 12245/13000 [12:44<54:58,  4.37s/it, lr=8.3e-7, step_loss=0.00392]Steps:  94%|█████████▍| 12245/13000 [12:44<54:58,  4.37s/it, lr=8.3e-7, step_loss=0.00968]Steps:  94%|█████████▍| 12246/13000 [12:44<43:59,  3.50s/it, lr=8.3e-7, step_loss=0.00968]Steps:  94%|█████████▍| 12246/13000 [12:45<43:59,  3.50s/it, lr=8.28e-7, step_loss=0.0159]Steps:  94%|█████████▍| 12246/13000 [12:45<43:59,  3.50s/it, lr=8.28e-7, step_loss=0.443] Steps:  94%|█████████▍| 12246/13000 [12:45<43:59,  3.50s/it, lr=8.28e-7, step_loss=0.0618]Steps:  94%|█████████▍| 12246/13000 [12:46<43:59,  3.50s/it, lr=8.28e-7, step_loss=0.0679]Steps:  94%|█████████▍| 12247/13000 [12:46<36:18,  2.89s/it, lr=8.28e-7, step_loss=0.0679]Steps:  94%|█████████▍| 12247/13000 [12:46<36:18,  2.89s/it, lr=8.26e-7, step_loss=0.352] Steps:  94%|█████████▍| 12247/13000 [12:46<36:18,  2.89s/it, lr=8.26e-7, step_loss=0.3]  Steps:  94%|█████████▍| 12247/13000 [12:47<36:18,  2.89s/it, lr=8.26e-7, step_loss=0.0195]Steps:  94%|█████████▍| 12247/13000 [12:47<36:18,  2.89s/it, lr=8.26e-7, step_loss=0.144] Steps:  94%|█████████▍| 12248/13000 [12:49<38:19,  3.06s/it, lr=8.26e-7, step_loss=0.144]Steps:  94%|█████████▍| 12248/13000 [12:49<38:19,  3.06s/it, lr=8.23e-7, step_loss=0.297]Steps:  94%|█████████▍| 12248/13000 [12:50<38:19,  3.06s/it, lr=8.23e-7, step_loss=0.013]Steps:  94%|█████████▍| 12248/13000 [12:50<38:19,  3.06s/it, lr=8.23e-7, step_loss=0.386]Steps:  94%|█████████▍| 12248/13000 [12:51<38:19,  3.06s/it, lr=8.23e-7, step_loss=0.068]Steps:  94%|█████████▍| 12249/13000 [12:51<32:10,  2.57s/it, lr=8.23e-7, step_loss=0.068]Steps:  94%|█████████▍| 12249/13000 [12:51<32:10,  2.57s/it, lr=8.21e-7, step_loss=0.00486]Steps:  94%|█████████▍| 12249/13000 [12:51<32:10,  2.57s/it, lr=8.21e-7, step_loss=0.0201] Steps:  94%|█████████▍| 12249/13000 [12:52<32:10,  2.57s/it, lr=8.21e-7, step_loss=0.194] Steps:  94%|█████████▍| 12249/13000 [12:52<32:10,  2.57s/it, lr=8.21e-7, step_loss=0.00304]Steps:  94%|█████████▍| 12250/13000 [12:52<28:00,  2.24s/it, lr=8.21e-7, step_loss=0.00304]Steps:  94%|█████████▍| 12250/13000 [12:52<28:00,  2.24s/it, lr=8.19e-7, step_loss=0.0169] Steps:  94%|█████████▍| 12250/13000 [12:53<28:00,  2.24s/it, lr=8.19e-7, step_loss=0.0625]Steps:  94%|█████████▍| 12250/13000 [12:53<28:00,  2.24s/it, lr=8.19e-7, step_loss=0.11]  Steps:  94%|█████████▍| 12250/13000 [12:53<28:00,  2.24s/it, lr=8.19e-7, step_loss=0.199]Steps:  94%|█████████▍| 12251/13000 [12:54<24:51,  1.99s/it, lr=8.19e-7, step_loss=0.199]Steps:  94%|█████████▍| 12251/13000 [12:54<24:51,  1.99s/it, lr=8.17e-7, step_loss=0.0197]Steps:  94%|█████████▍| 12251/13000 [12:54<24:51,  1.99s/it, lr=8.17e-7, step_loss=0.0154]Steps:  94%|█████████▍| 12252/13000 [12:54<19:57,  1.60s/it, lr=8.17e-7, step_loss=0.0154]Steps:  94%|█████████▍| 12252/13000 [12:54<19:57,  1.60s/it, lr=8.15e-7, step_loss=0.00284]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.76it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.69it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.89it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.51it/s]
02/23/2025 15:56:21 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12252/13000 [13:09<19:57,  1.60s/it, lr=8.15e-7, step_loss=0.0152] Steps:  94%|█████████▍| 12252/13000 [13:09<19:57,  1.60s/it, lr=8.15e-7, step_loss=0.0261]Steps:  94%|█████████▍| 12252/13000 [13:09<19:57,  1.60s/it, lr=8.15e-7, step_loss=0.0149]Steps:  94%|█████████▍| 12253/13000 [13:10<1:11:27,  5.74s/it, lr=8.15e-7, step_loss=0.0149]Steps:  94%|█████████▍| 12253/13000 [13:10<1:11:27,  5.74s/it, lr=8.12e-7, step_loss=0.0181]Steps:  94%|█████████▍| 12253/13000 [13:10<1:11:27,  5.74s/it, lr=8.12e-7, step_loss=0.109] Steps:  94%|█████████▍| 12253/13000 [13:11<1:11:27,  5.74s/it, lr=8.12e-7, step_loss=0.169]Steps:  94%|█████████▍| 12253/13000 [13:11<1:11:27,  5.74s/it, lr=8.12e-7, step_loss=0.0882]Steps:  94%|█████████▍| 12254/13000 [13:11<55:22,  4.45s/it, lr=8.12e-7, step_loss=0.0882]  Steps:  94%|█████████▍| 12254/13000 [13:11<55:22,  4.45s/it, lr=8.1e-7, step_loss=0.0378] Steps:  94%|█████████▍| 12254/13000 [13:12<55:22,  4.45s/it, lr=8.1e-7, step_loss=0.00274]Steps:  94%|█████████▍| 12254/13000 [13:12<55:22,  4.45s/it, lr=8.1e-7, step_loss=0.0712] Steps:  94%|█████████▍| 12254/13000 [13:12<55:22,  4.45s/it, lr=8.1e-7, step_loss=0.243] Steps:  94%|█████████▍| 12255/13000 [13:13<44:10,  3.56s/it, lr=8.1e-7, step_loss=0.243]Steps:  94%|█████████▍| 12255/13000 [13:13<44:10,  3.56s/it, lr=8.08e-7, step_loss=0.0622]Steps:  94%|█████████▍| 12255/13000 [13:13<44:10,  3.56s/it, lr=8.08e-7, step_loss=0.00477]Steps:  94%|█████████▍| 12255/13000 [13:14<44:10,  3.56s/it, lr=8.08e-7, step_loss=0.533]  Steps:  94%|█████████▍| 12255/13000 [13:14<44:10,  3.56s/it, lr=8.08e-7, step_loss=0.0636]Steps:  94%|█████████▍| 12256/13000 [13:15<38:29,  3.10s/it, lr=8.08e-7, step_loss=0.0636]Steps:  94%|█████████▍| 12256/13000 [13:15<38:29,  3.10s/it, lr=8.06e-7, step_loss=0.0577]Steps:  94%|█████████▍| 12256/13000 [13:15<38:29,  3.10s/it, lr=8.06e-7, step_loss=0.0979]Steps:  94%|█████████▍| 12256/13000 [13:16<38:29,  3.10s/it, lr=8.06e-7, step_loss=0.0223]Steps:  94%|█████████▍| 12256/13000 [13:16<38:29,  3.10s/it, lr=8.06e-7, step_loss=0.0784]Steps:  94%|█████████▍| 12257/13000 [13:16<32:16,  2.61s/it, lr=8.06e-7, step_loss=0.0784]Steps:  94%|█████████▍| 12257/13000 [13:16<32:16,  2.61s/it, lr=8.04e-7, step_loss=0.00671]Steps:  94%|█████████▍| 12257/13000 [13:17<32:16,  2.61s/it, lr=8.04e-7, step_loss=0.132]  Steps:  94%|█████████▍| 12257/13000 [13:17<32:16,  2.61s/it, lr=8.04e-7, step_loss=0.024]Steps:  94%|█████████▍| 12257/13000 [13:17<32:16,  2.61s/it, lr=8.04e-7, step_loss=0.298]Steps:  94%|█████████▍| 12258/13000 [13:18<27:55,  2.26s/it, lr=8.04e-7, step_loss=0.298]Steps:  94%|█████████▍| 12258/13000 [13:18<27:55,  2.26s/it, lr=8.02e-7, step_loss=0.00991]Steps:  94%|█████████▍| 12258/13000 [13:18<27:55,  2.26s/it, lr=8.02e-7, step_loss=0.0336] Steps:  94%|█████████▍| 12258/13000 [13:18<27:55,  2.26s/it, lr=8.02e-7, step_loss=0.109] Steps:  94%|█████████▍| 12258/13000 [13:19<27:55,  2.26s/it, lr=8.02e-7, step_loss=0.0202]Steps:  94%|█████████▍| 12259/13000 [13:19<24:48,  2.01s/it, lr=8.02e-7, step_loss=0.0202]Steps:  94%|█████████▍| 12259/13000 [13:20<24:48,  2.01s/it, lr=8e-7, step_loss=0.0937]   Steps:  94%|█████████▍| 12259/13000 [13:21<24:48,  2.01s/it, lr=8e-7, step_loss=0.0819]Steps:  94%|█████████▍| 12259/13000 [13:21<24:48,  2.01s/it, lr=8e-7, step_loss=0.0322]Steps:  94%|█████████▍| 12259/13000 [13:22<24:48,  2.01s/it, lr=8e-7, step_loss=0.0622]Steps:  94%|█████████▍| 12260/13000 [13:22<27:38,  2.24s/it, lr=8e-7, step_loss=0.0622]Steps:  94%|█████████▍| 12260/13000 [13:22<27:38,  2.24s/it, lr=7.97e-7, step_loss=0.0993]Steps:  94%|█████████▍| 12260/13000 [13:22<27:38,  2.24s/it, lr=7.97e-7, step_loss=0.0116]Steps:  94%|█████████▍| 12261/13000 [13:23<21:55,  1.78s/it, lr=7.97e-7, step_loss=0.0116]Steps:  94%|█████████▍| 12261/13000 [13:23<21:55,  1.78s/it, lr=7.95e-7, step_loss=0.0733]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.89it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.44it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.65it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.10it/s]
02/23/2025 15:56:49 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12261/13000 [13:37<21:55,  1.78s/it, lr=7.95e-7, step_loss=0.101] Steps:  94%|█████████▍| 12261/13000 [13:37<21:55,  1.78s/it, lr=7.95e-7, step_loss=0.168]Steps:  94%|█████████▍| 12261/13000 [13:38<21:55,  1.78s/it, lr=7.95e-7, step_loss=0.131]Steps:  94%|█████████▍| 12262/13000 [13:38<1:12:52,  5.93s/it, lr=7.95e-7, step_loss=0.131]Steps:  94%|█████████▍| 12262/13000 [13:38<1:12:52,  5.93s/it, lr=7.93e-7, step_loss=0.144]Steps:  94%|█████████▍| 12262/13000 [13:39<1:12:52,  5.93s/it, lr=7.93e-7, step_loss=0.117]Steps:  94%|█████████▍| 12262/13000 [13:39<1:12:52,  5.93s/it, lr=7.93e-7, step_loss=0.00626]Steps:  94%|█████████▍| 12262/13000 [13:39<1:12:52,  5.93s/it, lr=7.93e-7, step_loss=0.383]  Steps:  94%|█████████▍| 12263/13000 [13:40<56:23,  4.59s/it, lr=7.93e-7, step_loss=0.383]  Steps:  94%|█████████▍| 12263/13000 [13:40<56:23,  4.59s/it, lr=7.91e-7, step_loss=0.119]Steps:  94%|█████████▍| 12263/13000 [13:40<56:23,  4.59s/it, lr=7.91e-7, step_loss=0.0219]Steps:  94%|█████████▍| 12263/13000 [13:40<56:23,  4.59s/it, lr=7.91e-7, step_loss=0.0239]Steps:  94%|█████████▍| 12263/13000 [13:41<56:23,  4.59s/it, lr=7.91e-7, step_loss=0.124] Steps:  94%|█████████▍| 12264/13000 [13:41<44:45,  3.65s/it, lr=7.91e-7, step_loss=0.124]Steps:  94%|█████████▍| 12264/13000 [13:41<44:45,  3.65s/it, lr=7.89e-7, step_loss=0.0304]Steps:  94%|█████████▍| 12264/13000 [13:42<44:45,  3.65s/it, lr=7.89e-7, step_loss=0.0333]Steps:  94%|█████████▍| 12264/13000 [13:42<44:45,  3.65s/it, lr=7.89e-7, step_loss=0.171] Steps:  94%|█████████▍| 12264/13000 [13:42<44:45,  3.65s/it, lr=7.89e-7, step_loss=0.0151]Steps:  94%|█████████▍| 12265/13000 [13:43<36:38,  2.99s/it, lr=7.89e-7, step_loss=0.0151]Steps:  94%|█████████▍| 12265/13000 [13:43<36:38,  2.99s/it, lr=7.87e-7, step_loss=0.0359]Steps:  94%|█████████▍| 12265/13000 [13:43<36:38,  2.99s/it, lr=7.87e-7, step_loss=0.0296]Steps:  94%|█████████▍| 12265/13000 [13:44<36:38,  2.99s/it, lr=7.87e-7, step_loss=0.0541]Steps:  94%|█████████▍| 12265/13000 [13:44<36:38,  2.99s/it, lr=7.87e-7, step_loss=0.0238]Steps:  94%|█████████▍| 12266/13000 [13:45<33:00,  2.70s/it, lr=7.87e-7, step_loss=0.0238]Steps:  94%|█████████▍| 12266/13000 [13:45<33:00,  2.70s/it, lr=7.85e-7, step_loss=0.537] Steps:  94%|█████████▍| 12266/13000 [13:45<33:00,  2.70s/it, lr=7.85e-7, step_loss=0.165]Steps:  94%|█████████▍| 12266/13000 [13:45<33:00,  2.70s/it, lr=7.85e-7, step_loss=0.0101]Steps:  94%|█████████▍| 12266/13000 [13:46<33:00,  2.70s/it, lr=7.85e-7, step_loss=0.0305]Steps:  94%|█████████▍| 12267/13000 [13:46<28:20,  2.32s/it, lr=7.85e-7, step_loss=0.0305]Steps:  94%|█████████▍| 12267/13000 [13:46<28:20,  2.32s/it, lr=7.82e-7, step_loss=0.037] Steps:  94%|█████████▍| 12267/13000 [13:46<28:20,  2.32s/it, lr=7.82e-7, step_loss=0.304]Steps:  94%|█████████▍| 12267/13000 [13:47<28:20,  2.32s/it, lr=7.82e-7, step_loss=0.0161]Steps:  94%|█████████▍| 12267/13000 [13:47<28:20,  2.32s/it, lr=7.82e-7, step_loss=0.0482]Steps:  94%|█████████▍| 12268/13000 [13:47<25:07,  2.06s/it, lr=7.82e-7, step_loss=0.0482]Steps:  94%|█████████▍| 12268/13000 [13:47<25:07,  2.06s/it, lr=7.8e-7, step_loss=0.159]  Steps:  94%|█████████▍| 12268/13000 [13:48<25:07,  2.06s/it, lr=7.8e-7, step_loss=0.0148]Steps:  94%|█████████▍| 12268/13000 [13:48<25:07,  2.06s/it, lr=7.8e-7, step_loss=0.0148]Steps:  94%|█████████▍| 12268/13000 [13:49<25:07,  2.06s/it, lr=7.8e-7, step_loss=0.0554]Steps:  94%|█████████▍| 12269/13000 [13:49<22:51,  1.88s/it, lr=7.8e-7, step_loss=0.0554]Steps:  94%|█████████▍| 12269/13000 [13:49<22:51,  1.88s/it, lr=7.78e-7, step_loss=0.00415]Steps:  94%|█████████▍| 12269/13000 [13:49<22:51,  1.88s/it, lr=7.78e-7, step_loss=0.0688] Steps:  94%|█████████▍| 12270/13000 [13:50<18:30,  1.52s/it, lr=7.78e-7, step_loss=0.0688]Steps:  94%|█████████▍| 12270/13000 [13:50<18:30,  1.52s/it, lr=7.76e-7, step_loss=0.0792]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.52it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.54it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.42it/s]
02/23/2025 15:57:16 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12270/13000 [14:04<18:30,  1.52s/it, lr=7.76e-7, step_loss=0.278] Steps:  94%|█████████▍| 12270/13000 [14:04<18:30,  1.52s/it, lr=7.76e-7, step_loss=0.088]Steps:  94%|█████████▍| 12270/13000 [14:05<18:30,  1.52s/it, lr=7.76e-7, step_loss=0.0727]Steps:  94%|█████████▍| 12271/13000 [14:05<1:09:01,  5.68s/it, lr=7.76e-7, step_loss=0.0727]Steps:  94%|█████████▍| 12271/13000 [14:05<1:09:01,  5.68s/it, lr=7.74e-7, step_loss=0.119] Steps:  94%|█████████▍| 12271/13000 [14:05<1:09:01,  5.68s/it, lr=7.74e-7, step_loss=0.059]Steps:  94%|█████████▍| 12271/13000 [14:06<1:09:01,  5.68s/it, lr=7.74e-7, step_loss=0.126]Steps:  94%|█████████▍| 12271/13000 [14:06<1:09:01,  5.68s/it, lr=7.74e-7, step_loss=0.0717]Steps:  94%|█████████▍| 12272/13000 [14:06<53:32,  4.41s/it, lr=7.74e-7, step_loss=0.0717]  Steps:  94%|█████████▍| 12272/13000 [14:06<53:32,  4.41s/it, lr=7.72e-7, step_loss=0.123] Steps:  94%|█████████▍| 12272/13000 [14:07<53:32,  4.41s/it, lr=7.72e-7, step_loss=0.00759]Steps:  94%|█████████▍| 12272/13000 [14:07<53:32,  4.41s/it, lr=7.72e-7, step_loss=0.0738] Steps:  94%|█████████▍| 12272/13000 [14:08<53:32,  4.41s/it, lr=7.72e-7, step_loss=0.0052]Steps:  94%|█████████▍| 12273/13000 [14:08<42:50,  3.54s/it, lr=7.72e-7, step_loss=0.0052]Steps:  94%|█████████▍| 12273/13000 [14:08<42:50,  3.54s/it, lr=7.7e-7, step_loss=0.0649] Steps:  94%|█████████▍| 12273/13000 [14:08<42:50,  3.54s/it, lr=7.7e-7, step_loss=0.00991]Steps:  94%|█████████▍| 12273/13000 [14:09<42:50,  3.54s/it, lr=7.7e-7, step_loss=0.112]  Steps:  94%|█████████▍| 12273/13000 [14:09<42:50,  3.54s/it, lr=7.7e-7, step_loss=0.0053]Steps:  94%|█████████▍| 12274/13000 [14:09<35:22,  2.92s/it, lr=7.7e-7, step_loss=0.0053]Steps:  94%|█████████▍| 12274/13000 [14:10<35:22,  2.92s/it, lr=7.68e-7, step_loss=0.0234]Steps:  94%|█████████▍| 12274/13000 [14:10<35:22,  2.92s/it, lr=7.68e-7, step_loss=0.0361]Steps:  94%|█████████▍| 12274/13000 [14:11<35:22,  2.92s/it, lr=7.68e-7, step_loss=0.281] Steps:  94%|█████████▍| 12274/13000 [14:11<35:22,  2.92s/it, lr=7.68e-7, step_loss=0.36] Steps:  94%|█████████▍| 12275/13000 [14:12<33:19,  2.76s/it, lr=7.68e-7, step_loss=0.36]Steps:  94%|█████████▍| 12275/13000 [14:12<33:19,  2.76s/it, lr=7.65e-7, step_loss=0.192]Steps:  94%|█████████▍| 12275/13000 [14:12<33:19,  2.76s/it, lr=7.65e-7, step_loss=0.238]Steps:  94%|█████████▍| 12275/13000 [14:13<33:19,  2.76s/it, lr=7.65e-7, step_loss=0.535]Steps:  94%|█████████▍| 12275/13000 [14:13<33:19,  2.76s/it, lr=7.65e-7, step_loss=0.00807]Steps:  94%|█████████▍| 12276/13000 [14:13<28:33,  2.37s/it, lr=7.65e-7, step_loss=0.00807]Steps:  94%|█████████▍| 12276/13000 [14:13<28:33,  2.37s/it, lr=7.63e-7, step_loss=0.0894] Steps:  94%|█████████▍| 12276/13000 [14:14<28:33,  2.37s/it, lr=7.63e-7, step_loss=0.0391]Steps:  94%|█████████▍| 12276/13000 [14:14<28:33,  2.37s/it, lr=7.63e-7, step_loss=0.189] Steps:  94%|█████████▍| 12276/13000 [14:14<28:33,  2.37s/it, lr=7.63e-7, step_loss=0.0585]Steps:  94%|█████████▍| 12277/13000 [14:15<25:12,  2.09s/it, lr=7.63e-7, step_loss=0.0585]Steps:  94%|█████████▍| 12277/13000 [14:15<25:12,  2.09s/it, lr=7.61e-7, step_loss=0.00519]Steps:  94%|█████████▍| 12277/13000 [14:15<25:12,  2.09s/it, lr=7.61e-7, step_loss=0.0963] Steps:  94%|█████████▍| 12277/13000 [14:15<25:12,  2.09s/it, lr=7.61e-7, step_loss=0.0996]Steps:  94%|█████████▍| 12277/13000 [14:16<25:12,  2.09s/it, lr=7.61e-7, step_loss=0.00317]Steps:  94%|█████████▍| 12278/13000 [14:16<22:48,  1.90s/it, lr=7.61e-7, step_loss=0.00317]Steps:  94%|█████████▍| 12278/13000 [14:16<22:48,  1.90s/it, lr=7.59e-7, step_loss=0.0276] Steps:  94%|█████████▍| 12278/13000 [14:17<22:48,  1.90s/it, lr=7.59e-7, step_loss=0.00594]Steps:  94%|█████████▍| 12279/13000 [14:17<18:27,  1.54s/it, lr=7.59e-7, step_loss=0.00594]Steps:  94%|█████████▍| 12279/13000 [14:17<18:27,  1.54s/it, lr=7.57e-7, step_loss=0.00635]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.38it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.29it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.90it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.45it/s]
02/23/2025 15:57:43 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  94%|█████████▍| 12279/13000 [14:32<18:27,  1.54s/it, lr=7.57e-7, step_loss=0.0765] Steps:  94%|█████████▍| 12279/13000 [14:32<18:27,  1.54s/it, lr=7.57e-7, step_loss=0.0352]Steps:  94%|█████████▍| 12279/13000 [14:33<18:27,  1.54s/it, lr=7.57e-7, step_loss=0.00528]Steps:  94%|█████████▍| 12280/13000 [14:33<1:11:09,  5.93s/it, lr=7.57e-7, step_loss=0.00528]Steps:  94%|█████████▍| 12280/13000 [14:33<1:11:09,  5.93s/it, lr=7.55e-7, step_loss=0.042]  Steps:  94%|█████████▍| 12280/13000 [14:33<1:11:09,  5.93s/it, lr=7.55e-7, step_loss=0.0676]Steps:  94%|█████████▍| 12280/13000 [14:34<1:11:09,  5.93s/it, lr=7.55e-7, step_loss=0.0495]Steps:  94%|█████████▍| 12280/13000 [14:34<1:11:09,  5.93s/it, lr=7.55e-7, step_loss=0.216] Steps:  94%|█████████▍| 12281/13000 [14:34<54:58,  4.59s/it, lr=7.55e-7, step_loss=0.216]  Steps:  94%|█████████▍| 12281/13000 [14:35<54:58,  4.59s/it, lr=7.53e-7, step_loss=0.0562]Steps:  94%|█████████▍| 12281/13000 [14:35<54:58,  4.59s/it, lr=7.53e-7, step_loss=0.189] Steps:  94%|█████████▍| 12281/13000 [14:35<54:58,  4.59s/it, lr=7.53e-7, step_loss=0.0148]Steps:  94%|█████████▍| 12281/13000 [14:36<54:58,  4.59s/it, lr=7.53e-7, step_loss=0.0163]Steps:  94%|█████████▍| 12282/13000 [14:36<43:37,  3.65s/it, lr=7.53e-7, step_loss=0.0163]Steps:  94%|█████████▍| 12282/13000 [14:36<43:37,  3.65s/it, lr=7.51e-7, step_loss=0.0386]Steps:  94%|█████████▍| 12282/13000 [14:36<43:37,  3.65s/it, lr=7.51e-7, step_loss=0.122] Steps:  94%|█████████▍| 12282/13000 [14:37<43:37,  3.65s/it, lr=7.51e-7, step_loss=0.0156]Steps:  94%|█████████▍| 12282/13000 [14:37<43:37,  3.65s/it, lr=7.51e-7, step_loss=0.0146]Steps:  94%|█████████▍| 12283/13000 [14:37<35:38,  2.98s/it, lr=7.51e-7, step_loss=0.0146]Steps:  94%|█████████▍| 12283/13000 [14:37<35:38,  2.98s/it, lr=7.49e-7, step_loss=0.138] Steps:  94%|█████████▍| 12283/13000 [14:38<35:38,  2.98s/it, lr=7.49e-7, step_loss=0.0212]Steps:  94%|█████████▍| 12283/13000 [14:38<35:38,  2.98s/it, lr=7.49e-7, step_loss=0.0778]Steps:  94%|█████████▍| 12283/13000 [14:38<35:38,  2.98s/it, lr=7.49e-7, step_loss=0.0169]Steps:  94%|█████████▍| 12284/13000 [14:39<30:05,  2.52s/it, lr=7.49e-7, step_loss=0.0169]Steps:  94%|█████████▍| 12284/13000 [14:39<30:05,  2.52s/it, lr=7.47e-7, step_loss=0.0387]Steps:  94%|█████████▍| 12284/13000 [14:39<30:05,  2.52s/it, lr=7.47e-7, step_loss=0.135] Steps:  94%|█████████▍| 12284/13000 [14:40<30:05,  2.52s/it, lr=7.47e-7, step_loss=0.00933]Steps:  94%|█████████▍| 12284/13000 [14:40<30:05,  2.52s/it, lr=7.47e-7, step_loss=0.0105] Steps:  94%|█████████▍| 12285/13000 [14:40<26:10,  2.20s/it, lr=7.47e-7, step_loss=0.0105]Steps:  94%|█████████▍| 12285/13000 [14:40<26:10,  2.20s/it, lr=7.45e-7, step_loss=0.0902]Steps:  94%|█████████▍| 12285/13000 [14:41<26:10,  2.20s/it, lr=7.45e-7, step_loss=0.0257]Steps:  94%|█████████▍| 12285/13000 [14:41<26:10,  2.20s/it, lr=7.45e-7, step_loss=0.463] Steps:  94%|█████████▍| 12285/13000 [14:41<26:10,  2.20s/it, lr=7.45e-7, step_loss=0.0289]Steps:  95%|█████████▍| 12286/13000 [14:42<23:27,  1.97s/it, lr=7.45e-7, step_loss=0.0289]Steps:  95%|█████████▍| 12286/13000 [14:42<23:27,  1.97s/it, lr=7.42e-7, step_loss=0.0307]Steps:  95%|█████████▍| 12286/13000 [14:42<23:27,  1.97s/it, lr=7.42e-7, step_loss=0.091] Steps:  95%|█████████▍| 12286/13000 [14:42<23:27,  1.97s/it, lr=7.42e-7, step_loss=0.0106]Steps:  95%|█████████▍| 12286/13000 [14:43<23:27,  1.97s/it, lr=7.42e-7, step_loss=0.0486]Steps:  95%|█████████▍| 12287/13000 [14:43<21:34,  1.82s/it, lr=7.42e-7, step_loss=0.0486]Steps:  95%|█████████▍| 12287/13000 [14:43<21:34,  1.82s/it, lr=7.4e-7, step_loss=0.212]  Steps:  95%|█████████▍| 12287/13000 [14:44<21:34,  1.82s/it, lr=7.4e-7, step_loss=0.014]Steps:  95%|█████████▍| 12288/13000 [14:44<17:37,  1.49s/it, lr=7.4e-7, step_loss=0.014]Steps:  95%|█████████▍| 12288/13000 [14:44<17:37,  1.49s/it, lr=7.38e-7, step_loss=0.00332]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.10it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.91it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.64it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.17it/s]
02/23/2025 15:58:11 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▍| 12288/13000 [14:58<17:37,  1.49s/it, lr=7.38e-7, step_loss=0.0297] Steps:  95%|█████████▍| 12288/13000 [14:59<17:37,  1.49s/it, lr=7.38e-7, step_loss=0.0135]Steps:  95%|█████████▍| 12288/13000 [14:59<17:37,  1.49s/it, lr=7.38e-7, step_loss=0.0531]Steps:  95%|█████████▍| 12289/13000 [15:00<1:08:07,  5.75s/it, lr=7.38e-7, step_loss=0.0531]Steps:  95%|█████████▍| 12289/13000 [15:00<1:08:07,  5.75s/it, lr=7.36e-7, step_loss=0.0082]Steps:  95%|█████████▍| 12289/13000 [15:00<1:08:07,  5.75s/it, lr=7.36e-7, step_loss=0.0752]Steps:  95%|█████████▍| 12289/13000 [15:00<1:08:07,  5.75s/it, lr=7.36e-7, step_loss=0.17]  Steps:  95%|█████████▍| 12289/13000 [15:01<1:08:07,  5.75s/it, lr=7.36e-7, step_loss=0.172]Steps:  95%|█████████▍| 12290/13000 [15:01<52:39,  4.45s/it, lr=7.36e-7, step_loss=0.172]  Steps:  95%|█████████▍| 12290/13000 [15:01<52:39,  4.45s/it, lr=7.34e-7, step_loss=0.00459]Steps:  95%|█████████▍| 12290/13000 [15:01<52:39,  4.45s/it, lr=7.34e-7, step_loss=0.199]  Steps:  95%|█████████▍| 12290/13000 [15:02<52:39,  4.45s/it, lr=7.34e-7, step_loss=0.0213]Steps:  95%|█████████▍| 12290/13000 [15:02<52:39,  4.45s/it, lr=7.34e-7, step_loss=0.0894]Steps:  95%|█████████▍| 12291/13000 [15:02<42:02,  3.56s/it, lr=7.34e-7, step_loss=0.0894]Steps:  95%|█████████▍| 12291/13000 [15:02<42:02,  3.56s/it, lr=7.32e-7, step_loss=0.0926]Steps:  95%|█████████▍| 12291/13000 [15:03<42:02,  3.56s/it, lr=7.32e-7, step_loss=0.04]  Steps:  95%|█████████▍| 12291/13000 [15:03<42:02,  3.56s/it, lr=7.32e-7, step_loss=0.0954]Steps:  95%|█████████▍| 12291/13000 [15:04<42:02,  3.56s/it, lr=7.32e-7, step_loss=0.0638]Steps:  95%|█████████▍| 12292/13000 [15:04<34:31,  2.93s/it, lr=7.32e-7, step_loss=0.0638]Steps:  95%|█████████▍| 12292/13000 [15:04<34:31,  2.93s/it, lr=7.3e-7, step_loss=0.022]  Steps:  95%|█████████▍| 12292/13000 [15:04<34:31,  2.93s/it, lr=7.3e-7, step_loss=0.206]Steps:  95%|█████████▍| 12292/13000 [15:05<34:31,  2.93s/it, lr=7.3e-7, step_loss=0.298]Steps:  95%|█████████▍| 12292/13000 [15:05<34:31,  2.93s/it, lr=7.3e-7, step_loss=0.0284]Steps:  95%|█████████▍| 12293/13000 [15:05<29:10,  2.48s/it, lr=7.3e-7, step_loss=0.0284]Steps:  95%|█████████▍| 12293/13000 [15:05<29:10,  2.48s/it, lr=7.28e-7, step_loss=0.175]Steps:  95%|█████████▍| 12293/13000 [15:06<29:10,  2.48s/it, lr=7.28e-7, step_loss=0.0856]Steps:  95%|█████████▍| 12293/13000 [15:06<29:10,  2.48s/it, lr=7.28e-7, step_loss=0.0228]Steps:  95%|█████████▍| 12293/13000 [15:06<29:10,  2.48s/it, lr=7.28e-7, step_loss=0.0532]Steps:  95%|█████████▍| 12294/13000 [15:07<25:29,  2.17s/it, lr=7.28e-7, step_loss=0.0532]Steps:  95%|█████████▍| 12294/13000 [15:07<25:29,  2.17s/it, lr=7.26e-7, step_loss=0.0521]Steps:  95%|█████████▍| 12294/13000 [15:07<25:29,  2.17s/it, lr=7.26e-7, step_loss=0.342] Steps:  95%|█████████▍| 12294/13000 [15:08<25:29,  2.17s/it, lr=7.26e-7, step_loss=0.0176]Steps:  95%|█████████▍| 12294/13000 [15:08<25:29,  2.17s/it, lr=7.26e-7, step_loss=0.3]   Steps:  95%|█████████▍| 12295/13000 [15:08<22:56,  1.95s/it, lr=7.26e-7, step_loss=0.3]Steps:  95%|█████████▍| 12295/13000 [15:08<22:56,  1.95s/it, lr=7.24e-7, step_loss=0.0776]Steps:  95%|█████████▍| 12295/13000 [15:09<22:56,  1.95s/it, lr=7.24e-7, step_loss=0.00322]Steps:  95%|█████████▍| 12295/13000 [15:09<22:56,  1.95s/it, lr=7.24e-7, step_loss=0.598]  Steps:  95%|█████████▍| 12295/13000 [15:09<22:56,  1.95s/it, lr=7.24e-7, step_loss=0.0244]Steps:  95%|█████████▍| 12296/13000 [15:10<21:08,  1.80s/it, lr=7.24e-7, step_loss=0.0244]Steps:  95%|█████████▍| 12296/13000 [15:10<21:08,  1.80s/it, lr=7.22e-7, step_loss=0.00328]Steps:  95%|█████████▍| 12296/13000 [15:10<21:08,  1.80s/it, lr=7.22e-7, step_loss=0.17]   Steps:  95%|█████████▍| 12297/13000 [15:12<21:45,  1.86s/it, lr=7.22e-7, step_loss=0.17]Steps:  95%|█████████▍| 12297/13000 [15:12<21:45,  1.86s/it, lr=7.2e-7, step_loss=0.35] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.30it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.49it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.79it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.38it/s]
02/23/2025 15:58:38 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▍| 12297/13000 [15:27<21:45,  1.86s/it, lr=7.2e-7, step_loss=0.0283]Steps:  95%|█████████▍| 12297/13000 [15:27<21:45,  1.86s/it, lr=7.2e-7, step_loss=0.12]  Steps:  95%|█████████▍| 12297/13000 [15:28<21:45,  1.86s/it, lr=7.2e-7, step_loss=0.0315]Steps:  95%|█████████▍| 12298/13000 [15:28<1:13:16,  6.26s/it, lr=7.2e-7, step_loss=0.0315]Steps:  95%|█████████▍| 12298/13000 [15:28<1:13:16,  6.26s/it, lr=7.18e-7, step_loss=0.0544]Steps:  95%|█████████▍| 12298/13000 [15:29<1:13:16,  6.26s/it, lr=7.18e-7, step_loss=0.0131]Steps:  95%|█████████▍| 12298/13000 [15:29<1:13:16,  6.26s/it, lr=7.18e-7, step_loss=0.101] Steps:  95%|█████████▍| 12298/13000 [15:29<1:13:16,  6.26s/it, lr=7.18e-7, step_loss=0.0853]Steps:  95%|█████████▍| 12299/13000 [15:30<56:20,  4.82s/it, lr=7.18e-7, step_loss=0.0853]  Steps:  95%|█████████▍| 12299/13000 [15:30<56:20,  4.82s/it, lr=7.16e-7, step_loss=0.022] Steps:  95%|█████████▍| 12299/13000 [15:30<56:20,  4.82s/it, lr=7.16e-7, step_loss=0.678]Steps:  95%|█████████▍| 12299/13000 [15:30<56:20,  4.82s/it, lr=7.16e-7, step_loss=0.0979]Steps:  95%|█████████▍| 12299/13000 [15:31<56:20,  4.82s/it, lr=7.16e-7, step_loss=0.0604]Steps:  95%|█████████▍| 12300/13000 [15:31<44:26,  3.81s/it, lr=7.16e-7, step_loss=0.0604]Steps:  95%|█████████▍| 12300/13000 [15:31<44:26,  3.81s/it, lr=7.14e-7, step_loss=0.265] Steps:  95%|█████████▍| 12300/13000 [15:32<44:26,  3.81s/it, lr=7.14e-7, step_loss=0.124]Steps:  95%|█████████▍| 12300/13000 [15:32<44:26,  3.81s/it, lr=7.14e-7, step_loss=0.0161]Steps:  95%|█████████▍| 12300/13000 [15:32<44:26,  3.81s/it, lr=7.14e-7, step_loss=0.531] Steps:  95%|█████████▍| 12301/13000 [15:33<36:13,  3.11s/it, lr=7.14e-7, step_loss=0.531]Steps:  95%|█████████▍| 12301/13000 [15:33<36:13,  3.11s/it, lr=7.12e-7, step_loss=0.111]Steps:  95%|█████████▍| 12301/13000 [15:33<36:13,  3.11s/it, lr=7.12e-7, step_loss=0.0247]Steps:  95%|█████████▍| 12301/13000 [15:33<36:13,  3.11s/it, lr=7.12e-7, step_loss=0.0193]Steps:  95%|█████████▍| 12301/13000 [15:34<36:13,  3.11s/it, lr=7.12e-7, step_loss=0.14]  Steps:  95%|█████████▍| 12302/13000 [15:34<30:29,  2.62s/it, lr=7.12e-7, step_loss=0.14]Steps:  95%|█████████▍| 12302/13000 [15:34<30:29,  2.62s/it, lr=7.1e-7, step_loss=0.104]Steps:  95%|█████████▍| 12302/13000 [15:34<30:29,  2.62s/it, lr=7.1e-7, step_loss=0.042]Steps:  95%|█████████▍| 12302/13000 [15:35<30:29,  2.62s/it, lr=7.1e-7, step_loss=0.0761]Steps:  95%|█████████▍| 12302/13000 [15:35<30:29,  2.62s/it, lr=7.1e-7, step_loss=0.00289]Steps:  95%|█████████▍| 12303/13000 [15:35<26:18,  2.26s/it, lr=7.1e-7, step_loss=0.00289]Steps:  95%|█████████▍| 12303/13000 [15:36<26:18,  2.26s/it, lr=7.08e-7, step_loss=0.0318]Steps:  95%|█████████▍| 12303/13000 [15:36<26:18,  2.26s/it, lr=7.08e-7, step_loss=0.199] Steps:  95%|█████████▍| 12303/13000 [15:36<26:18,  2.26s/it, lr=7.08e-7, step_loss=0.274]Steps:  95%|█████████▍| 12303/13000 [15:37<26:18,  2.26s/it, lr=7.08e-7, step_loss=0.0261]Steps:  95%|█████████▍| 12304/13000 [15:37<23:25,  2.02s/it, lr=7.08e-7, step_loss=0.0261]Steps:  95%|█████████▍| 12304/13000 [15:37<23:25,  2.02s/it, lr=7.06e-7, step_loss=0.0122]Steps:  95%|█████████▍| 12304/13000 [15:37<23:25,  2.02s/it, lr=7.06e-7, step_loss=0.0253]Steps:  95%|█████████▍| 12304/13000 [15:38<23:25,  2.02s/it, lr=7.06e-7, step_loss=0.0246]Steps:  95%|█████████▍| 12304/13000 [15:38<23:25,  2.02s/it, lr=7.06e-7, step_loss=0.0531]Steps:  95%|█████████▍| 12305/13000 [15:38<21:21,  1.84s/it, lr=7.06e-7, step_loss=0.0531]Steps:  95%|█████████▍| 12305/13000 [15:38<21:21,  1.84s/it, lr=7.04e-7, step_loss=0.00618]Steps:  95%|█████████▍| 12305/13000 [15:39<21:21,  1.84s/it, lr=7.04e-7, step_loss=0.231]  Steps:  95%|█████████▍| 12306/13000 [15:39<17:22,  1.50s/it, lr=7.04e-7, step_loss=0.231]Steps:  95%|█████████▍| 12306/13000 [15:39<17:22,  1.50s/it, lr=7.02e-7, step_loss=0.128]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.90it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.11it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.94it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.43it/s]
02/23/2025 15:59:06 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▍| 12306/13000 [15:54<17:22,  1.50s/it, lr=7.02e-7, step_loss=0.0741]Steps:  95%|█████████▍| 12306/13000 [15:54<17:22,  1.50s/it, lr=7.02e-7, step_loss=0.113] Steps:  95%|█████████▍| 12306/13000 [15:55<17:22,  1.50s/it, lr=7.02e-7, step_loss=0.0213]Steps:  95%|█████████▍| 12307/13000 [15:55<1:06:56,  5.80s/it, lr=7.02e-7, step_loss=0.0213]Steps:  95%|█████████▍| 12307/13000 [15:55<1:06:56,  5.80s/it, lr=7e-7, step_loss=0.00789]  Steps:  95%|█████████▍| 12307/13000 [15:55<1:06:56,  5.80s/it, lr=7e-7, step_loss=0.028]  Steps:  95%|█████████▍| 12307/13000 [15:56<1:06:56,  5.80s/it, lr=7e-7, step_loss=0.511]Steps:  95%|█████████▍| 12307/13000 [15:56<1:06:56,  5.80s/it, lr=7e-7, step_loss=0.159]Steps:  95%|█████████▍| 12308/13000 [15:56<51:46,  4.49s/it, lr=7e-7, step_loss=0.159]  Steps:  95%|█████████▍| 12308/13000 [15:56<51:46,  4.49s/it, lr=6.98e-7, step_loss=0.0755]Steps:  95%|█████████▍| 12308/13000 [15:57<51:46,  4.49s/it, lr=6.98e-7, step_loss=0.112] Steps:  95%|█████████▍| 12308/13000 [15:57<51:46,  4.49s/it, lr=6.98e-7, step_loss=0.0505]Steps:  95%|█████████▍| 12308/13000 [15:57<51:46,  4.49s/it, lr=6.98e-7, step_loss=0.0116]Steps:  95%|█████████▍| 12309/13000 [15:58<41:15,  3.58s/it, lr=6.98e-7, step_loss=0.0116]Steps:  95%|█████████▍| 12309/13000 [15:59<41:15,  3.58s/it, lr=6.96e-7, step_loss=0.0657]Steps:  95%|█████████▍| 12309/13000 [15:59<41:15,  3.58s/it, lr=6.96e-7, step_loss=0.0386]Steps:  95%|█████████▍| 12309/13000 [15:59<41:15,  3.58s/it, lr=6.96e-7, step_loss=0.0144]Steps:  95%|█████████▍| 12309/13000 [16:00<41:15,  3.58s/it, lr=6.96e-7, step_loss=0.169] Steps:  95%|█████████▍| 12310/13000 [16:00<36:54,  3.21s/it, lr=6.96e-7, step_loss=0.169]Steps:  95%|█████████▍| 12310/13000 [16:00<36:54,  3.21s/it, lr=6.93e-7, step_loss=0.212]Steps:  95%|█████████▍| 12310/13000 [16:01<36:54,  3.21s/it, lr=6.93e-7, step_loss=0.526]Steps:  95%|█████████▍| 12310/13000 [16:01<36:54,  3.21s/it, lr=6.93e-7, step_loss=0.0908]Steps:  95%|█████████▍| 12310/13000 [16:01<36:54,  3.21s/it, lr=6.93e-7, step_loss=0.12]  Steps:  95%|█████████▍| 12311/13000 [16:02<30:48,  2.68s/it, lr=6.93e-7, step_loss=0.12]Steps:  95%|█████████▍| 12311/13000 [16:02<30:48,  2.68s/it, lr=6.91e-7, step_loss=0.0779]Steps:  95%|█████████▍| 12311/13000 [16:02<30:48,  2.68s/it, lr=6.91e-7, step_loss=0.288] Steps:  95%|█████████▍| 12311/13000 [16:02<30:48,  2.68s/it, lr=6.91e-7, step_loss=0.0751]Steps:  95%|█████████▍| 12311/13000 [16:03<30:48,  2.68s/it, lr=6.91e-7, step_loss=0.281] Steps:  95%|█████████▍| 12312/13000 [16:03<26:29,  2.31s/it, lr=6.91e-7, step_loss=0.281]Steps:  95%|█████████▍| 12312/13000 [16:03<26:29,  2.31s/it, lr=6.89e-7, step_loss=0.0226]Steps:  95%|█████████▍| 12312/13000 [16:03<26:29,  2.31s/it, lr=6.89e-7, step_loss=0.0278]Steps:  95%|█████████▍| 12312/13000 [16:04<26:29,  2.31s/it, lr=6.89e-7, step_loss=0.0163]Steps:  95%|█████████▍| 12312/13000 [16:04<26:29,  2.31s/it, lr=6.89e-7, step_loss=0.0197]Steps:  95%|█████████▍| 12313/13000 [16:04<23:33,  2.06s/it, lr=6.89e-7, step_loss=0.0197]Steps:  95%|█████████▍| 12313/13000 [16:05<23:33,  2.06s/it, lr=6.87e-7, step_loss=0.00603]Steps:  95%|█████████▍| 12313/13000 [16:05<23:33,  2.06s/it, lr=6.87e-7, step_loss=0.331]  Steps:  95%|█████████▍| 12313/13000 [16:05<23:33,  2.06s/it, lr=6.87e-7, step_loss=0.00368]Steps:  95%|█████████▍| 12313/13000 [16:06<23:33,  2.06s/it, lr=6.87e-7, step_loss=0.00781]Steps:  95%|█████████▍| 12314/13000 [16:06<21:26,  1.88s/it, lr=6.87e-7, step_loss=0.00781]Steps:  95%|█████████▍| 12314/13000 [16:06<21:26,  1.88s/it, lr=6.85e-7, step_loss=0.0166] Steps:  95%|█████████▍| 12314/13000 [16:06<21:26,  1.88s/it, lr=6.85e-7, step_loss=0.0128]Steps:  95%|█████████▍| 12315/13000 [16:07<17:25,  1.53s/it, lr=6.85e-7, step_loss=0.0128]Steps:  95%|█████████▍| 12315/13000 [16:07<17:25,  1.53s/it, lr=6.84e-7, step_loss=0.119] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.18it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.96it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.61it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.16it/s]
02/23/2025 15:59:33 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▍| 12315/13000 [16:21<17:25,  1.53s/it, lr=6.84e-7, step_loss=0.174]Steps:  95%|█████████▍| 12315/13000 [16:21<17:25,  1.53s/it, lr=6.84e-7, step_loss=0.162]Steps:  95%|█████████▍| 12315/13000 [16:22<17:25,  1.53s/it, lr=6.84e-7, step_loss=0.105]Steps:  95%|█████████▍| 12316/13000 [16:22<1:04:55,  5.69s/it, lr=6.84e-7, step_loss=0.105]Steps:  95%|█████████▍| 12316/13000 [16:22<1:04:55,  5.69s/it, lr=6.82e-7, step_loss=0.0108]Steps:  95%|█████████▍| 12316/13000 [16:22<1:04:55,  5.69s/it, lr=6.82e-7, step_loss=0.26]  Steps:  95%|█████████▍| 12316/13000 [16:23<1:04:55,  5.69s/it, lr=6.82e-7, step_loss=0.00286]Steps:  95%|█████████▍| 12316/13000 [16:23<1:04:55,  5.69s/it, lr=6.82e-7, step_loss=0.0269] Steps:  95%|█████████▍| 12317/13000 [16:24<50:20,  4.42s/it, lr=6.82e-7, step_loss=0.0269]  Steps:  95%|█████████▍| 12317/13000 [16:24<50:20,  4.42s/it, lr=6.8e-7, step_loss=0.00368]Steps:  95%|█████████▍| 12317/13000 [16:24<50:20,  4.42s/it, lr=6.8e-7, step_loss=0.00976]Steps:  95%|█████████▍| 12317/13000 [16:24<50:20,  4.42s/it, lr=6.8e-7, step_loss=0.0112] Steps:  95%|█████████▍| 12317/13000 [16:25<50:20,  4.42s/it, lr=6.8e-7, step_loss=0.151] Steps:  95%|█████████▍| 12318/13000 [16:25<40:15,  3.54s/it, lr=6.8e-7, step_loss=0.151]Steps:  95%|█████████▍| 12318/13000 [16:25<40:15,  3.54s/it, lr=6.78e-7, step_loss=0.121]Steps:  95%|█████████▍| 12318/13000 [16:25<40:15,  3.54s/it, lr=6.78e-7, step_loss=0.0058]Steps:  95%|█████████▍| 12318/13000 [16:26<40:15,  3.54s/it, lr=6.78e-7, step_loss=0.0405]Steps:  95%|█████████▍| 12318/13000 [16:30<40:15,  3.54s/it, lr=6.78e-7, step_loss=0.0769]Steps:  95%|█████████▍| 12319/13000 [16:30<44:43,  3.94s/it, lr=6.78e-7, step_loss=0.0769]Steps:  95%|█████████▍| 12319/13000 [16:30<44:43,  3.94s/it, lr=6.76e-7, step_loss=0.0697]Steps:  95%|█████████▍| 12319/13000 [16:30<44:43,  3.94s/it, lr=6.76e-7, step_loss=0.00601]Steps:  95%|█████████▍| 12319/13000 [16:31<44:43,  3.94s/it, lr=6.76e-7, step_loss=0.00354]Steps:  95%|█████████▍| 12319/13000 [16:31<44:43,  3.94s/it, lr=6.76e-7, step_loss=0.026]  Steps:  95%|█████████▍| 12320/13000 [16:31<36:05,  3.18s/it, lr=6.76e-7, step_loss=0.026]Steps:  95%|█████████▍| 12320/13000 [16:31<36:05,  3.18s/it, lr=6.74e-7, step_loss=0.0249]Steps:  95%|█████████▍| 12320/13000 [16:32<36:05,  3.18s/it, lr=6.74e-7, step_loss=0.222] Steps:  95%|█████████▍| 12320/13000 [16:32<36:05,  3.18s/it, lr=6.74e-7, step_loss=0.0159]Steps:  95%|█████████▍| 12320/13000 [16:32<36:05,  3.18s/it, lr=6.74e-7, step_loss=0.343] Steps:  95%|█████████▍| 12321/13000 [16:33<30:22,  2.68s/it, lr=6.74e-7, step_loss=0.343]Steps:  95%|█████████▍| 12321/13000 [16:33<30:22,  2.68s/it, lr=6.72e-7, step_loss=0.0168]Steps:  95%|█████████▍| 12321/13000 [16:33<30:22,  2.68s/it, lr=6.72e-7, step_loss=0.0713]Steps:  95%|█████████▍| 12321/13000 [16:34<30:22,  2.68s/it, lr=6.72e-7, step_loss=0.125] Steps:  95%|█████████▍| 12321/13000 [16:34<30:22,  2.68s/it, lr=6.72e-7, step_loss=0.00708]Steps:  95%|█████████▍| 12322/13000 [16:34<26:09,  2.31s/it, lr=6.72e-7, step_loss=0.00708]Steps:  95%|█████████▍| 12322/13000 [16:35<26:09,  2.31s/it, lr=6.7e-7, step_loss=0.0301]  Steps:  95%|█████████▍| 12322/13000 [16:35<26:09,  2.31s/it, lr=6.7e-7, step_loss=0.03]  Steps:  95%|█████████▍| 12322/13000 [16:35<26:09,  2.31s/it, lr=6.7e-7, step_loss=0.117]Steps:  95%|█████████▍| 12322/13000 [16:36<26:09,  2.31s/it, lr=6.7e-7, step_loss=0.0145]Steps:  95%|█████████▍| 12323/13000 [16:36<24:31,  2.17s/it, lr=6.7e-7, step_loss=0.0145]Steps:  95%|█████████▍| 12323/13000 [16:36<24:31,  2.17s/it, lr=6.68e-7, step_loss=0.135]Steps:  95%|█████████▍| 12323/13000 [16:37<24:31,  2.17s/it, lr=6.68e-7, step_loss=0.0446]Steps:  95%|█████████▍| 12324/13000 [16:37<19:33,  1.74s/it, lr=6.68e-7, step_loss=0.0446]Steps:  95%|█████████▍| 12324/13000 [16:37<19:33,  1.74s/it, lr=6.66e-7, step_loss=0.00797]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.24it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.65it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.98it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.56it/s]
02/23/2025 16:00:03 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▍| 12324/13000 [16:51<19:33,  1.74s/it, lr=6.66e-7, step_loss=0.00433]Steps:  95%|█████████▍| 12324/13000 [16:52<19:33,  1.74s/it, lr=6.66e-7, step_loss=0.0633] Steps:  95%|█████████▍| 12324/13000 [16:52<19:33,  1.74s/it, lr=6.66e-7, step_loss=0.0713]Steps:  95%|█████████▍| 12325/13000 [16:52<1:05:54,  5.86s/it, lr=6.66e-7, step_loss=0.0713]Steps:  95%|█████████▍| 12325/13000 [16:52<1:05:54,  5.86s/it, lr=6.64e-7, step_loss=0.00371]Steps:  95%|█████████▍| 12325/13000 [16:53<1:05:54,  5.86s/it, lr=6.64e-7, step_loss=0.075]  Steps:  95%|█████████▍| 12325/13000 [16:53<1:05:54,  5.86s/it, lr=6.64e-7, step_loss=0.125]Steps:  95%|█████████▍| 12325/13000 [16:53<1:05:54,  5.86s/it, lr=6.64e-7, step_loss=0.0532]Steps:  95%|█████████▍| 12326/13000 [16:54<51:02,  4.54s/it, lr=6.64e-7, step_loss=0.0532]  Steps:  95%|█████████▍| 12326/13000 [16:54<51:02,  4.54s/it, lr=6.62e-7, step_loss=0.18]  Steps:  95%|█████████▍| 12326/13000 [16:54<51:02,  4.54s/it, lr=6.62e-7, step_loss=0.028]Steps:  95%|█████████▍| 12326/13000 [16:55<51:02,  4.54s/it, lr=6.62e-7, step_loss=0.00678]Steps:  95%|█████████▍| 12326/13000 [16:55<51:02,  4.54s/it, lr=6.62e-7, step_loss=0.154]  Steps:  95%|█████████▍| 12327/13000 [16:55<40:39,  3.62s/it, lr=6.62e-7, step_loss=0.154]Steps:  95%|█████████▍| 12327/13000 [16:55<40:39,  3.62s/it, lr=6.6e-7, step_loss=0.0519]Steps:  95%|█████████▍| 12327/13000 [16:56<40:39,  3.62s/it, lr=6.6e-7, step_loss=0.0409]Steps:  95%|█████████▍| 12327/13000 [16:56<40:39,  3.62s/it, lr=6.6e-7, step_loss=0.0545]Steps:  95%|█████████▍| 12327/13000 [16:56<40:39,  3.62s/it, lr=6.6e-7, step_loss=0.0143]Steps:  95%|█████████▍| 12328/13000 [16:57<33:16,  2.97s/it, lr=6.6e-7, step_loss=0.0143]Steps:  95%|█████████▍| 12328/13000 [16:57<33:16,  2.97s/it, lr=6.58e-7, step_loss=0.00522]Steps:  95%|█████████▍| 12328/13000 [16:57<33:16,  2.97s/it, lr=6.58e-7, step_loss=0.0945] Steps:  95%|█████████▍| 12328/13000 [16:58<33:16,  2.97s/it, lr=6.58e-7, step_loss=0.169] Steps:  95%|█████████▍| 12328/13000 [16:58<33:16,  2.97s/it, lr=6.58e-7, step_loss=0.00924]Steps:  95%|█████████▍| 12329/13000 [16:58<28:21,  2.54s/it, lr=6.58e-7, step_loss=0.00924]Steps:  95%|█████████▍| 12329/13000 [16:58<28:21,  2.54s/it, lr=6.56e-7, step_loss=0.00996]Steps:  95%|█████████▍| 12329/13000 [16:59<28:21,  2.54s/it, lr=6.56e-7, step_loss=0.101]  Steps:  95%|█████████▍| 12329/13000 [16:59<28:21,  2.54s/it, lr=6.56e-7, step_loss=0.169]Steps:  95%|█████████▍| 12329/13000 [16:59<28:21,  2.54s/it, lr=6.56e-7, step_loss=0.00462]Steps:  95%|█████████▍| 12330/13000 [17:00<24:41,  2.21s/it, lr=6.56e-7, step_loss=0.00462]Steps:  95%|█████████▍| 12330/13000 [17:00<24:41,  2.21s/it, lr=6.54e-7, step_loss=0.0665] Steps:  95%|█████████▍| 12330/13000 [17:00<24:41,  2.21s/it, lr=6.54e-7, step_loss=0.0409]Steps:  95%|█████████▍| 12330/13000 [17:00<24:41,  2.21s/it, lr=6.54e-7, step_loss=0.0872]Steps:  95%|█████████▍| 12330/13000 [17:01<24:41,  2.21s/it, lr=6.54e-7, step_loss=0.0038]Steps:  95%|█████████▍| 12331/13000 [17:01<22:07,  1.98s/it, lr=6.54e-7, step_loss=0.0038]Steps:  95%|█████████▍| 12331/13000 [17:04<22:07,  1.98s/it, lr=6.52e-7, step_loss=0.0441]Steps:  95%|█████████▍| 12331/13000 [17:04<22:07,  1.98s/it, lr=6.52e-7, step_loss=0.0255]Steps:  95%|█████████▍| 12331/13000 [17:04<22:07,  1.98s/it, lr=6.52e-7, step_loss=0.123] Steps:  95%|█████████▍| 12331/13000 [17:05<22:07,  1.98s/it, lr=6.52e-7, step_loss=0.0462]Steps:  95%|█████████▍| 12332/13000 [17:05<28:50,  2.59s/it, lr=6.52e-7, step_loss=0.0462]Steps:  95%|█████████▍| 12332/13000 [17:05<28:50,  2.59s/it, lr=6.5e-7, step_loss=0.0917] Steps:  95%|█████████▍| 12332/13000 [17:06<28:50,  2.59s/it, lr=6.5e-7, step_loss=0.00504]Steps:  95%|█████████▍| 12333/13000 [17:06<22:26,  2.02s/it, lr=6.5e-7, step_loss=0.00504]Steps:  95%|█████████▍| 12333/13000 [17:06<22:26,  2.02s/it, lr=6.48e-7, step_loss=0.0311]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.59it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.47it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.46it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.93it/s]
02/23/2025 16:00:33 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  95%|█████████▍| 12333/13000 [17:21<22:26,  2.02s/it, lr=6.48e-7, step_loss=0.5]   Steps:  95%|█████████▍| 12333/13000 [17:21<22:26,  2.02s/it, lr=6.48e-7, step_loss=0.43]Steps:  95%|█████████▍| 12333/13000 [17:22<22:26,  2.02s/it, lr=6.48e-7, step_loss=0.0921]Steps:  95%|█████████▍| 12334/13000 [17:22<1:09:11,  6.23s/it, lr=6.48e-7, step_loss=0.0921]Steps:  95%|█████████▍| 12334/13000 [17:22<1:09:11,  6.23s/it, lr=6.46e-7, step_loss=0.0318]Steps:  95%|█████████▍| 12334/13000 [17:22<1:09:11,  6.23s/it, lr=6.46e-7, step_loss=0.0252]Steps:  95%|█████████▍| 12334/13000 [17:23<1:09:11,  6.23s/it, lr=6.46e-7, step_loss=0.129] Steps:  95%|█████████▍| 12334/13000 [17:23<1:09:11,  6.23s/it, lr=6.46e-7, step_loss=0.0337]Steps:  95%|█████████▍| 12335/13000 [17:23<53:12,  4.80s/it, lr=6.46e-7, step_loss=0.0337]  Steps:  95%|█████████▍| 12335/13000 [17:23<53:12,  4.80s/it, lr=6.44e-7, step_loss=0.057] Steps:  95%|█████████▍| 12335/13000 [17:24<53:12,  4.80s/it, lr=6.44e-7, step_loss=0.119]Steps:  95%|█████████▍| 12335/13000 [17:24<53:12,  4.80s/it, lr=6.44e-7, step_loss=0.00653]Steps:  95%|█████████▍| 12335/13000 [17:25<53:12,  4.80s/it, lr=6.44e-7, step_loss=0.368]  Steps:  95%|█████████▍| 12336/13000 [17:25<42:00,  3.80s/it, lr=6.44e-7, step_loss=0.368]Steps:  95%|█████████▍| 12336/13000 [17:28<42:00,  3.80s/it, lr=6.42e-7, step_loss=0.144]Steps:  95%|█████████▍| 12336/13000 [17:28<42:00,  3.80s/it, lr=6.42e-7, step_loss=0.015]Steps:  95%|█████████▍| 12336/13000 [17:28<42:00,  3.80s/it, lr=6.42e-7, step_loss=0.0673]Steps:  95%|█████████▍| 12336/13000 [17:29<42:00,  3.80s/it, lr=6.42e-7, step_loss=0.0429]Steps:  95%|█████████▍| 12337/13000 [17:29<43:41,  3.95s/it, lr=6.42e-7, step_loss=0.0429]Steps:  95%|█████████▍| 12337/13000 [17:29<43:41,  3.95s/it, lr=6.4e-7, step_loss=0.0336] Steps:  95%|█████████▍| 12337/13000 [17:30<43:41,  3.95s/it, lr=6.4e-7, step_loss=0.0178]Steps:  95%|█████████▍| 12337/13000 [17:30<43:41,  3.95s/it, lr=6.4e-7, step_loss=0.00529]Steps:  95%|█████████▍| 12337/13000 [17:30<43:41,  3.95s/it, lr=6.4e-7, step_loss=0.00289]Steps:  95%|█████████▍| 12338/13000 [17:31<35:26,  3.21s/it, lr=6.4e-7, step_loss=0.00289]Steps:  95%|█████████▍| 12338/13000 [17:31<35:26,  3.21s/it, lr=6.38e-7, step_loss=0.249] Steps:  95%|█████████▍| 12338/13000 [17:31<35:26,  3.21s/it, lr=6.38e-7, step_loss=0.0781]Steps:  95%|█████████▍| 12338/13000 [17:31<35:26,  3.21s/it, lr=6.38e-7, step_loss=0.061] Steps:  95%|█████████▍| 12338/13000 [17:32<35:26,  3.21s/it, lr=6.38e-7, step_loss=0.0157]Steps:  95%|█████████▍| 12339/13000 [17:32<29:30,  2.68s/it, lr=6.38e-7, step_loss=0.0157]Steps:  95%|█████████▍| 12339/13000 [17:32<29:30,  2.68s/it, lr=6.37e-7, step_loss=0.0146]Steps:  95%|█████████▍| 12339/13000 [17:32<29:30,  2.68s/it, lr=6.37e-7, step_loss=0.137] Steps:  95%|█████████▍| 12339/13000 [17:33<29:30,  2.68s/it, lr=6.37e-7, step_loss=0.0674]Steps:  95%|█████████▍| 12339/13000 [17:33<29:30,  2.68s/it, lr=6.37e-7, step_loss=0.111] Steps:  95%|█████████▍| 12340/13000 [17:34<25:48,  2.35s/it, lr=6.37e-7, step_loss=0.111]Steps:  95%|█████████▍| 12340/13000 [17:34<25:48,  2.35s/it, lr=6.35e-7, step_loss=0.722]Steps:  95%|█████████▍| 12340/13000 [17:35<25:48,  2.35s/it, lr=6.35e-7, step_loss=0.182]Steps:  95%|█████████▍| 12340/13000 [17:35<25:48,  2.35s/it, lr=6.35e-7, step_loss=0.041]Steps:  95%|█████████▍| 12340/13000 [17:35<25:48,  2.35s/it, lr=6.35e-7, step_loss=0.296]Steps:  95%|█████████▍| 12341/13000 [17:36<24:59,  2.28s/it, lr=6.35e-7, step_loss=0.296]Steps:  95%|█████████▍| 12341/13000 [17:36<24:59,  2.28s/it, lr=6.33e-7, step_loss=0.221]Steps:  95%|█████████▍| 12341/13000 [17:36<24:59,  2.28s/it, lr=6.33e-7, step_loss=0.00695]Steps:  95%|█████████▍| 12342/13000 [17:36<19:44,  1.80s/it, lr=6.33e-7, step_loss=0.00695]Steps:  95%|█████████▍| 12342/13000 [17:36<19:44,  1.80s/it, lr=6.31e-7, step_loss=0.00779]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.79it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.96it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.60it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.13it/s]
02/23/2025 16:01:03 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  95%|█████████▍| 12342/13000 [17:51<19:44,  1.80s/it, lr=6.31e-7, step_loss=0.0159] Steps:  95%|█████████▍| 12342/13000 [17:51<19:44,  1.80s/it, lr=6.31e-7, step_loss=0.0234]Steps:  95%|█████████▍| 12342/13000 [17:52<19:44,  1.80s/it, lr=6.31e-7, step_loss=0.00409]Steps:  95%|█████████▍| 12343/13000 [17:52<1:05:17,  5.96s/it, lr=6.31e-7, step_loss=0.00409]Steps:  95%|█████████▍| 12343/13000 [17:52<1:05:17,  5.96s/it, lr=6.29e-7, step_loss=0.186]  Steps:  95%|█████████▍| 12343/13000 [17:52<1:05:17,  5.96s/it, lr=6.29e-7, step_loss=0.331]Steps:  95%|█████████▍| 12343/13000 [17:53<1:05:17,  5.96s/it, lr=6.29e-7, step_loss=0.0671]Steps:  95%|█████████▍| 12343/13000 [17:53<1:05:17,  5.96s/it, lr=6.29e-7, step_loss=0.0324]Steps:  95%|█████████▍| 12344/13000 [17:54<50:23,  4.61s/it, lr=6.29e-7, step_loss=0.0324]  Steps:  95%|█████████▍| 12344/13000 [17:54<50:23,  4.61s/it, lr=6.27e-7, step_loss=0.103] Steps:  95%|█████████▍| 12344/13000 [17:54<50:23,  4.61s/it, lr=6.27e-7, step_loss=0.134]Steps:  95%|█████████▍| 12344/13000 [17:54<50:23,  4.61s/it, lr=6.27e-7, step_loss=0.0416]Steps:  95%|█████████▍| 12344/13000 [17:55<50:23,  4.61s/it, lr=6.27e-7, step_loss=0.00412]Steps:  95%|█████████▍| 12345/13000 [17:55<39:49,  3.65s/it, lr=6.27e-7, step_loss=0.00412]Steps:  95%|█████████▍| 12345/13000 [17:55<39:49,  3.65s/it, lr=6.25e-7, step_loss=0.189]  Steps:  95%|█████████▍| 12345/13000 [17:55<39:49,  3.65s/it, lr=6.25e-7, step_loss=0.0105]Steps:  95%|█████████▍| 12345/13000 [17:56<39:49,  3.65s/it, lr=6.25e-7, step_loss=0.00742]Steps:  95%|█████████▍| 12345/13000 [17:56<39:49,  3.65s/it, lr=6.25e-7, step_loss=0.0151] Steps:  95%|█████████▍| 12346/13000 [17:56<32:41,  3.00s/it, lr=6.25e-7, step_loss=0.0151]Steps:  95%|█████████▍| 12346/13000 [17:56<32:41,  3.00s/it, lr=6.23e-7, step_loss=0.00525]Steps:  95%|█████████▍| 12346/13000 [17:57<32:41,  3.00s/it, lr=6.23e-7, step_loss=0.12]   Steps:  95%|█████████▍| 12346/13000 [17:57<32:41,  3.00s/it, lr=6.23e-7, step_loss=0.00575]Steps:  95%|█████████▍| 12346/13000 [17:58<32:41,  3.00s/it, lr=6.23e-7, step_loss=0.596]  Steps:  95%|█████████▍| 12347/13000 [17:58<27:36,  2.54s/it, lr=6.23e-7, step_loss=0.596]Steps:  95%|█████████▍| 12347/13000 [17:58<27:36,  2.54s/it, lr=6.21e-7, step_loss=0.102]Steps:  95%|█████████▍| 12347/13000 [17:58<27:36,  2.54s/it, lr=6.21e-7, step_loss=0.119]Steps:  95%|█████████▍| 12347/13000 [17:59<27:36,  2.54s/it, lr=6.21e-7, step_loss=0.299]Steps:  95%|█████████▍| 12347/13000 [17:59<27:36,  2.54s/it, lr=6.21e-7, step_loss=0.0811]Steps:  95%|█████████▍| 12348/13000 [17:59<24:02,  2.21s/it, lr=6.21e-7, step_loss=0.0811]Steps:  95%|█████████▍| 12348/13000 [17:59<24:02,  2.21s/it, lr=6.19e-7, step_loss=0.12]  Steps:  95%|█████████▍| 12348/13000 [18:00<24:02,  2.21s/it, lr=6.19e-7, step_loss=0.311]Steps:  95%|█████████▍| 12348/13000 [18:00<24:02,  2.21s/it, lr=6.19e-7, step_loss=0.00519]Steps:  95%|█████████▍| 12348/13000 [18:00<24:02,  2.21s/it, lr=6.19e-7, step_loss=0.0223] Steps:  95%|█████████▍| 12349/13000 [18:01<21:32,  1.99s/it, lr=6.19e-7, step_loss=0.0223]Steps:  95%|█████████▍| 12349/13000 [18:01<21:32,  1.99s/it, lr=6.17e-7, step_loss=0.176] Steps:  95%|█████████▍| 12349/13000 [18:01<21:32,  1.99s/it, lr=6.17e-7, step_loss=0.00528]Steps:  95%|█████████▍| 12349/13000 [18:02<21:32,  1.99s/it, lr=6.17e-7, step_loss=0.0481] Steps:  95%|█████████▍| 12349/13000 [18:02<21:32,  1.99s/it, lr=6.17e-7, step_loss=0.0652]Steps:  95%|█████████▌| 12350/13000 [18:02<19:49,  1.83s/it, lr=6.17e-7, step_loss=0.0652]Steps:  95%|█████████▌| 12350/13000 [18:02<19:49,  1.83s/it, lr=6.16e-7, step_loss=0.00476]Steps:  95%|█████████▌| 12350/13000 [18:03<19:49,  1.83s/it, lr=6.16e-7, step_loss=0.175]  Steps:  95%|█████████▌| 12351/13000 [18:03<16:07,  1.49s/it, lr=6.16e-7, step_loss=0.175]Steps:  95%|█████████▌| 12351/13000 [18:03<16:07,  1.49s/it, lr=6.14e-7, step_loss=0.106]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.23it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.49it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.07it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.61it/s]
02/23/2025 16:01:29 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12351/13000 [18:17<16:07,  1.49s/it, lr=6.14e-7, step_loss=0.223]Steps:  95%|█████████▌| 12351/13000 [18:18<16:07,  1.49s/it, lr=6.14e-7, step_loss=0.00426]Steps:  95%|█████████▌| 12351/13000 [18:18<16:07,  1.49s/it, lr=6.14e-7, step_loss=0.0444] Steps:  95%|█████████▌| 12352/13000 [18:19<1:01:46,  5.72s/it, lr=6.14e-7, step_loss=0.0444]Steps:  95%|█████████▌| 12352/13000 [18:19<1:01:46,  5.72s/it, lr=6.12e-7, step_loss=0.0345]Steps:  95%|█████████▌| 12352/13000 [18:19<1:01:46,  5.72s/it, lr=6.12e-7, step_loss=0.00645]Steps:  95%|█████████▌| 12352/13000 [18:19<1:01:46,  5.72s/it, lr=6.12e-7, step_loss=0.0667] Steps:  95%|█████████▌| 12352/13000 [18:20<1:01:46,  5.72s/it, lr=6.12e-7, step_loss=0.212] Steps:  95%|█████████▌| 12353/13000 [18:20<47:52,  4.44s/it, lr=6.12e-7, step_loss=0.212]  Steps:  95%|█████████▌| 12353/13000 [18:20<47:52,  4.44s/it, lr=6.1e-7, step_loss=0.409] Steps:  95%|█████████▌| 12353/13000 [18:20<47:52,  4.44s/it, lr=6.1e-7, step_loss=0.384]Steps:  95%|█████████▌| 12353/13000 [18:21<47:52,  4.44s/it, lr=6.1e-7, step_loss=0.0106]Steps:  95%|█████████▌| 12353/13000 [18:21<47:52,  4.44s/it, lr=6.1e-7, step_loss=0.0147]Steps:  95%|█████████▌| 12354/13000 [18:21<38:02,  3.53s/it, lr=6.1e-7, step_loss=0.0147]Steps:  95%|█████████▌| 12354/13000 [18:21<38:02,  3.53s/it, lr=6.08e-7, step_loss=0.0744]Steps:  95%|█████████▌| 12354/13000 [18:22<38:02,  3.53s/it, lr=6.08e-7, step_loss=0.152] Steps:  95%|█████████▌| 12354/13000 [18:22<38:02,  3.53s/it, lr=6.08e-7, step_loss=0.00228]Steps:  95%|█████████▌| 12354/13000 [18:23<38:02,  3.53s/it, lr=6.08e-7, step_loss=0.00719]Steps:  95%|█████████▌| 12355/13000 [18:23<31:12,  2.90s/it, lr=6.08e-7, step_loss=0.00719]Steps:  95%|█████████▌| 12355/13000 [18:23<31:12,  2.90s/it, lr=6.06e-7, step_loss=0.084]  Steps:  95%|█████████▌| 12355/13000 [18:23<31:12,  2.90s/it, lr=6.06e-7, step_loss=0.1]  Steps:  95%|█████████▌| 12355/13000 [18:24<31:12,  2.90s/it, lr=6.06e-7, step_loss=0.0246]Steps:  95%|█████████▌| 12355/13000 [18:24<31:12,  2.90s/it, lr=6.06e-7, step_loss=0.0569]Steps:  95%|█████████▌| 12356/13000 [18:24<26:18,  2.45s/it, lr=6.06e-7, step_loss=0.0569]Steps:  95%|█████████▌| 12356/13000 [18:24<26:18,  2.45s/it, lr=6.04e-7, step_loss=0.0146]Steps:  95%|█████████▌| 12356/13000 [18:25<26:18,  2.45s/it, lr=6.04e-7, step_loss=0.0727]Steps:  95%|█████████▌| 12356/13000 [18:25<26:18,  2.45s/it, lr=6.04e-7, step_loss=0.0626]Steps:  95%|█████████▌| 12356/13000 [18:25<26:18,  2.45s/it, lr=6.04e-7, step_loss=0.482] Steps:  95%|█████████▌| 12357/13000 [18:26<23:22,  2.18s/it, lr=6.04e-7, step_loss=0.482]Steps:  95%|█████████▌| 12357/13000 [18:26<23:22,  2.18s/it, lr=6.02e-7, step_loss=0.0908]Steps:  95%|█████████▌| 12357/13000 [18:26<23:22,  2.18s/it, lr=6.02e-7, step_loss=0.0701]Steps:  95%|█████████▌| 12357/13000 [18:27<23:22,  2.18s/it, lr=6.02e-7, step_loss=0.357] Steps:  95%|█████████▌| 12357/13000 [18:27<23:22,  2.18s/it, lr=6.02e-7, step_loss=0.00371]Steps:  95%|█████████▌| 12358/13000 [18:27<21:00,  1.96s/it, lr=6.02e-7, step_loss=0.00371]Steps:  95%|█████████▌| 12358/13000 [18:27<21:00,  1.96s/it, lr=6.01e-7, step_loss=0.00885]Steps:  95%|█████████▌| 12358/13000 [18:28<21:00,  1.96s/it, lr=6.01e-7, step_loss=0.00324]Steps:  95%|█████████▌| 12358/13000 [18:28<21:00,  1.96s/it, lr=6.01e-7, step_loss=0.0067] Steps:  95%|█████████▌| 12358/13000 [18:28<21:00,  1.96s/it, lr=6.01e-7, step_loss=0.00609]Steps:  95%|█████████▌| 12359/13000 [18:29<19:24,  1.82s/it, lr=6.01e-7, step_loss=0.00609]Steps:  95%|█████████▌| 12359/13000 [18:29<19:24,  1.82s/it, lr=5.99e-7, step_loss=0.0869] Steps:  95%|█████████▌| 12359/13000 [18:29<19:24,  1.82s/it, lr=5.99e-7, step_loss=0.0177]Steps:  95%|█████████▌| 12360/13000 [18:29<15:49,  1.48s/it, lr=5.99e-7, step_loss=0.0177]Steps:  95%|█████████▌| 12360/13000 [18:31<15:49,  1.48s/it, lr=5.97e-7, step_loss=0.115] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.69it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.63it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.50it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.06it/s]
02/23/2025 16:01:58 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12360/13000 [18:45<15:49,  1.48s/it, lr=5.97e-7, step_loss=0.00558]Steps:  95%|█████████▌| 12360/13000 [18:46<15:49,  1.48s/it, lr=5.97e-7, step_loss=0.221]  Steps:  95%|█████████▌| 12360/13000 [18:46<15:49,  1.48s/it, lr=5.97e-7, step_loss=0.0278]Steps:  95%|█████████▌| 12361/13000 [18:46<1:05:14,  6.13s/it, lr=5.97e-7, step_loss=0.0278]Steps:  95%|█████████▌| 12361/13000 [18:46<1:05:14,  6.13s/it, lr=5.95e-7, step_loss=0.0377]Steps:  95%|█████████▌| 12361/13000 [18:47<1:05:14,  6.13s/it, lr=5.95e-7, step_loss=0.0297]Steps:  95%|█████████▌| 12361/13000 [18:47<1:05:14,  6.13s/it, lr=5.95e-7, step_loss=0.146] Steps:  95%|█████████▌| 12361/13000 [18:48<1:05:14,  6.13s/it, lr=5.95e-7, step_loss=0.16] Steps:  95%|█████████▌| 12362/13000 [18:48<50:21,  4.74s/it, lr=5.95e-7, step_loss=0.16]  Steps:  95%|█████████▌| 12362/13000 [18:48<50:21,  4.74s/it, lr=5.93e-7, step_loss=0.0817]Steps:  95%|█████████▌| 12362/13000 [18:48<50:21,  4.74s/it, lr=5.93e-7, step_loss=0.0113]Steps:  95%|█████████▌| 12362/13000 [18:49<50:21,  4.74s/it, lr=5.93e-7, step_loss=0.0388]Steps:  95%|█████████▌| 12362/13000 [18:49<50:21,  4.74s/it, lr=5.93e-7, step_loss=0.125] Steps:  95%|█████████▌| 12363/13000 [18:49<39:51,  3.76s/it, lr=5.93e-7, step_loss=0.125]Steps:  95%|█████████▌| 12363/13000 [18:49<39:51,  3.76s/it, lr=5.91e-7, step_loss=0.0414]Steps:  95%|█████████▌| 12363/13000 [18:50<39:51,  3.76s/it, lr=5.91e-7, step_loss=0.0108]Steps:  95%|█████████▌| 12363/13000 [18:50<39:51,  3.76s/it, lr=5.91e-7, step_loss=0.114] Steps:  95%|█████████▌| 12363/13000 [18:50<39:51,  3.76s/it, lr=5.91e-7, step_loss=0.00492]Steps:  95%|█████████▌| 12364/13000 [18:51<32:25,  3.06s/it, lr=5.91e-7, step_loss=0.00492]Steps:  95%|█████████▌| 12364/13000 [18:51<32:25,  3.06s/it, lr=5.89e-7, step_loss=0.459]  Steps:  95%|█████████▌| 12364/13000 [18:52<32:25,  3.06s/it, lr=5.89e-7, step_loss=0.0774]Steps:  95%|█████████▌| 12364/13000 [18:52<32:25,  3.06s/it, lr=5.89e-7, step_loss=0.137] Steps:  95%|█████████▌| 12364/13000 [18:52<32:25,  3.06s/it, lr=5.89e-7, step_loss=0.00727]Steps:  95%|█████████▌| 12365/13000 [18:53<28:40,  2.71s/it, lr=5.89e-7, step_loss=0.00727]Steps:  95%|█████████▌| 12365/13000 [18:53<28:40,  2.71s/it, lr=5.88e-7, step_loss=0.175]  Steps:  95%|█████████▌| 12365/13000 [18:53<28:40,  2.71s/it, lr=5.88e-7, step_loss=0.0151]Steps:  95%|█████████▌| 12365/13000 [18:53<28:40,  2.71s/it, lr=5.88e-7, step_loss=0.0272]Steps:  95%|█████████▌| 12365/13000 [18:54<28:40,  2.71s/it, lr=5.88e-7, step_loss=0.12]  Steps:  95%|█████████▌| 12366/13000 [18:54<24:38,  2.33s/it, lr=5.88e-7, step_loss=0.12]Steps:  95%|█████████▌| 12366/13000 [18:54<24:38,  2.33s/it, lr=5.86e-7, step_loss=0.338]Steps:  95%|█████████▌| 12366/13000 [18:55<24:38,  2.33s/it, lr=5.86e-7, step_loss=0.237]Steps:  95%|█████████▌| 12366/13000 [18:55<24:38,  2.33s/it, lr=5.86e-7, step_loss=0.0536]Steps:  95%|█████████▌| 12366/13000 [18:55<24:38,  2.33s/it, lr=5.86e-7, step_loss=0.0596]Steps:  95%|█████████▌| 12367/13000 [18:56<21:51,  2.07s/it, lr=5.86e-7, step_loss=0.0596]Steps:  95%|█████████▌| 12367/13000 [18:56<21:51,  2.07s/it, lr=5.84e-7, step_loss=0.0468]Steps:  95%|█████████▌| 12367/13000 [18:56<21:51,  2.07s/it, lr=5.84e-7, step_loss=0.0609]Steps:  95%|█████████▌| 12367/13000 [18:56<21:51,  2.07s/it, lr=5.84e-7, step_loss=0.248] Steps:  95%|█████████▌| 12367/13000 [18:57<21:51,  2.07s/it, lr=5.84e-7, step_loss=0.0328]Steps:  95%|█████████▌| 12368/13000 [18:57<19:45,  1.88s/it, lr=5.84e-7, step_loss=0.0328]Steps:  95%|█████████▌| 12368/13000 [18:57<19:45,  1.88s/it, lr=5.82e-7, step_loss=0.0137]Steps:  95%|█████████▌| 12368/13000 [18:57<19:45,  1.88s/it, lr=5.82e-7, step_loss=0.0238]Steps:  95%|█████████▌| 12369/13000 [18:58<15:58,  1.52s/it, lr=5.82e-7, step_loss=0.0238]Steps:  95%|█████████▌| 12369/13000 [18:58<15:58,  1.52s/it, lr=5.8e-7, step_loss=0.0733] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.24it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.13it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.68it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.24it/s]
02/23/2025 16:02:24 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12369/13000 [19:12<15:58,  1.52s/it, lr=5.8e-7, step_loss=0.0215]Steps:  95%|█████████▌| 12369/13000 [19:12<15:58,  1.52s/it, lr=5.8e-7, step_loss=0.115] Steps:  95%|█████████▌| 12369/13000 [19:13<15:58,  1.52s/it, lr=5.8e-7, step_loss=0.0267]Steps:  95%|█████████▌| 12370/13000 [19:13<59:42,  5.69s/it, lr=5.8e-7, step_loss=0.0267]Steps:  95%|█████████▌| 12370/13000 [19:13<59:42,  5.69s/it, lr=5.78e-7, step_loss=0.412]Steps:  95%|█████████▌| 12370/13000 [19:14<59:42,  5.69s/it, lr=5.78e-7, step_loss=0.0331]Steps:  95%|█████████▌| 12370/13000 [19:14<59:42,  5.69s/it, lr=5.78e-7, step_loss=0.106] Steps:  95%|█████████▌| 12370/13000 [19:14<59:42,  5.69s/it, lr=5.78e-7, step_loss=0.0471]Steps:  95%|█████████▌| 12371/13000 [19:15<46:16,  4.41s/it, lr=5.78e-7, step_loss=0.0471]Steps:  95%|█████████▌| 12371/13000 [19:15<46:16,  4.41s/it, lr=5.77e-7, step_loss=0.022] Steps:  95%|█████████▌| 12371/13000 [19:15<46:16,  4.41s/it, lr=5.77e-7, step_loss=0.0165]Steps:  95%|█████████▌| 12371/13000 [19:15<46:16,  4.41s/it, lr=5.77e-7, step_loss=0.126] Steps:  95%|█████████▌| 12371/13000 [19:16<46:16,  4.41s/it, lr=5.77e-7, step_loss=0.193]Steps:  95%|█████████▌| 12372/13000 [19:16<37:02,  3.54s/it, lr=5.77e-7, step_loss=0.193]Steps:  95%|█████████▌| 12372/13000 [19:16<37:02,  3.54s/it, lr=5.75e-7, step_loss=0.0773]Steps:  95%|█████████▌| 12372/13000 [19:16<37:02,  3.54s/it, lr=5.75e-7, step_loss=0.0229]Steps:  95%|█████████▌| 12372/13000 [19:17<37:02,  3.54s/it, lr=5.75e-7, step_loss=0.00377]Steps:  95%|█████████▌| 12372/13000 [19:17<37:02,  3.54s/it, lr=5.75e-7, step_loss=0.00922]Steps:  95%|█████████▌| 12373/13000 [19:17<30:20,  2.90s/it, lr=5.75e-7, step_loss=0.00922]Steps:  95%|█████████▌| 12373/13000 [19:18<30:20,  2.90s/it, lr=5.73e-7, step_loss=0.0777] Steps:  95%|█████████▌| 12373/13000 [19:18<30:20,  2.90s/it, lr=5.73e-7, step_loss=0.103] Steps:  95%|█████████▌| 12373/13000 [19:18<30:20,  2.90s/it, lr=5.73e-7, step_loss=0.00379]Steps:  95%|█████████▌| 12373/13000 [19:19<30:20,  2.90s/it, lr=5.73e-7, step_loss=0.0873] Steps:  95%|█████████▌| 12374/13000 [19:19<25:50,  2.48s/it, lr=5.73e-7, step_loss=0.0873]Steps:  95%|█████████▌| 12374/13000 [19:19<25:50,  2.48s/it, lr=5.71e-7, step_loss=0.172] Steps:  95%|█████████▌| 12374/13000 [19:19<25:50,  2.48s/it, lr=5.71e-7, step_loss=0.137]Steps:  95%|█████████▌| 12374/13000 [19:20<25:50,  2.48s/it, lr=5.71e-7, step_loss=0.00351]Steps:  95%|█████████▌| 12374/13000 [19:20<25:50,  2.48s/it, lr=5.71e-7, step_loss=0.0496] Steps:  95%|█████████▌| 12375/13000 [19:20<22:37,  2.17s/it, lr=5.71e-7, step_loss=0.0496]Steps:  95%|█████████▌| 12375/13000 [19:20<22:37,  2.17s/it, lr=5.69e-7, step_loss=0.252] Steps:  95%|█████████▌| 12375/13000 [19:21<22:37,  2.17s/it, lr=5.69e-7, step_loss=0.202]Steps:  95%|█████████▌| 12375/13000 [19:21<22:37,  2.17s/it, lr=5.69e-7, step_loss=0.0882]Steps:  95%|█████████▌| 12375/13000 [19:22<22:37,  2.17s/it, lr=5.69e-7, step_loss=0.54]  Steps:  95%|█████████▌| 12376/13000 [19:22<20:22,  1.96s/it, lr=5.69e-7, step_loss=0.54]Steps:  95%|█████████▌| 12376/13000 [19:22<20:22,  1.96s/it, lr=5.67e-7, step_loss=0.029]Steps:  95%|█████████▌| 12376/13000 [19:22<20:22,  1.96s/it, lr=5.67e-7, step_loss=0.228]Steps:  95%|█████████▌| 12376/13000 [19:23<20:22,  1.96s/it, lr=5.67e-7, step_loss=0.022]Steps:  95%|█████████▌| 12376/13000 [19:23<20:22,  1.96s/it, lr=5.67e-7, step_loss=0.0275]Steps:  95%|█████████▌| 12377/13000 [19:23<18:43,  1.80s/it, lr=5.67e-7, step_loss=0.0275]Steps:  95%|█████████▌| 12377/13000 [19:23<18:43,  1.80s/it, lr=5.66e-7, step_loss=0.0315]Steps:  95%|█████████▌| 12377/13000 [19:24<18:43,  1.80s/it, lr=5.66e-7, step_loss=0.0664]Steps:  95%|█████████▌| 12378/13000 [19:24<15:14,  1.47s/it, lr=5.66e-7, step_loss=0.0664]Steps:  95%|█████████▌| 12378/13000 [19:24<15:14,  1.47s/it, lr=5.64e-7, step_loss=0.0809]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.32it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.50it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.11it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.64it/s]
02/23/2025 16:02:51 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12378/13000 [19:39<15:14,  1.47s/it, lr=5.64e-7, step_loss=0.151] Steps:  95%|█████████▌| 12378/13000 [19:39<15:14,  1.47s/it, lr=5.64e-7, step_loss=0.0179]Steps:  95%|█████████▌| 12378/13000 [19:39<15:14,  1.47s/it, lr=5.64e-7, step_loss=0.0837]Steps:  95%|█████████▌| 12379/13000 [19:40<59:19,  5.73s/it, lr=5.64e-7, step_loss=0.0837]Steps:  95%|█████████▌| 12379/13000 [19:40<59:19,  5.73s/it, lr=5.62e-7, step_loss=0.0153]Steps:  95%|█████████▌| 12379/13000 [19:40<59:19,  5.73s/it, lr=5.62e-7, step_loss=0.00702]Steps:  95%|█████████▌| 12379/13000 [19:40<59:19,  5.73s/it, lr=5.62e-7, step_loss=0.0319] Steps:  95%|█████████▌| 12379/13000 [19:41<59:19,  5.73s/it, lr=5.62e-7, step_loss=0.00516]Steps:  95%|█████████▌| 12380/13000 [19:41<45:55,  4.45s/it, lr=5.62e-7, step_loss=0.00516]Steps:  95%|█████████▌| 12380/13000 [19:41<45:55,  4.45s/it, lr=5.6e-7, step_loss=0.0109]  Steps:  95%|█████████▌| 12380/13000 [19:42<45:55,  4.45s/it, lr=5.6e-7, step_loss=0.0974]Steps:  95%|█████████▌| 12380/13000 [19:42<45:55,  4.45s/it, lr=5.6e-7, step_loss=0.12]  Steps:  95%|█████████▌| 12380/13000 [19:42<45:55,  4.45s/it, lr=5.6e-7, step_loss=0.0146]Steps:  95%|█████████▌| 12381/13000 [19:43<36:33,  3.54s/it, lr=5.6e-7, step_loss=0.0146]Steps:  95%|█████████▌| 12381/13000 [19:43<36:33,  3.54s/it, lr=5.58e-7, step_loss=0.0273]Steps:  95%|█████████▌| 12381/13000 [19:43<36:33,  3.54s/it, lr=5.58e-7, step_loss=0.0205]Steps:  95%|█████████▌| 12381/13000 [19:43<36:33,  3.54s/it, lr=5.58e-7, step_loss=0.0461]Steps:  95%|█████████▌| 12381/13000 [19:44<36:33,  3.54s/it, lr=5.58e-7, step_loss=0.0242]Steps:  95%|█████████▌| 12382/13000 [19:44<30:08,  2.93s/it, lr=5.58e-7, step_loss=0.0242]Steps:  95%|█████████▌| 12382/13000 [19:45<30:08,  2.93s/it, lr=5.57e-7, step_loss=0.396] Steps:  95%|█████████▌| 12382/13000 [19:45<30:08,  2.93s/it, lr=5.57e-7, step_loss=0.239]Steps:  95%|█████████▌| 12382/13000 [19:46<30:08,  2.93s/it, lr=5.57e-7, step_loss=0.472]Steps:  95%|█████████▌| 12382/13000 [19:46<30:08,  2.93s/it, lr=5.57e-7, step_loss=0.153]Steps:  95%|█████████▌| 12383/13000 [19:46<28:25,  2.76s/it, lr=5.57e-7, step_loss=0.153]Steps:  95%|█████████▌| 12383/13000 [19:47<28:25,  2.76s/it, lr=5.55e-7, step_loss=0.117]Steps:  95%|█████████▌| 12383/13000 [19:47<28:25,  2.76s/it, lr=5.55e-7, step_loss=0.0174]Steps:  95%|█████████▌| 12383/13000 [19:47<28:25,  2.76s/it, lr=5.55e-7, step_loss=0.117] Steps:  95%|█████████▌| 12383/13000 [19:48<28:25,  2.76s/it, lr=5.55e-7, step_loss=0.13] Steps:  95%|█████████▌| 12384/13000 [19:48<24:27,  2.38s/it, lr=5.55e-7, step_loss=0.13]Steps:  95%|█████████▌| 12384/13000 [19:48<24:27,  2.38s/it, lr=5.53e-7, step_loss=0.0444]Steps:  95%|█████████▌| 12384/13000 [19:49<24:27,  2.38s/it, lr=5.53e-7, step_loss=0.184] Steps:  95%|█████████▌| 12384/13000 [19:49<24:27,  2.38s/it, lr=5.53e-7, step_loss=0.0135]Steps:  95%|█████████▌| 12384/13000 [19:49<24:27,  2.38s/it, lr=5.53e-7, step_loss=0.0265]Steps:  95%|█████████▌| 12385/13000 [19:50<22:23,  2.19s/it, lr=5.53e-7, step_loss=0.0265]Steps:  95%|█████████▌| 12385/13000 [19:50<22:23,  2.19s/it, lr=5.51e-7, step_loss=0.0245]Steps:  95%|█████████▌| 12385/13000 [19:50<22:23,  2.19s/it, lr=5.51e-7, step_loss=0.0662]Steps:  95%|█████████▌| 12385/13000 [19:50<22:23,  2.19s/it, lr=5.51e-7, step_loss=0.17]  Steps:  95%|█████████▌| 12385/13000 [19:51<22:23,  2.19s/it, lr=5.51e-7, step_loss=0.181]Steps:  95%|█████████▌| 12386/13000 [19:51<20:05,  1.96s/it, lr=5.51e-7, step_loss=0.181]Steps:  95%|█████████▌| 12386/13000 [19:51<20:05,  1.96s/it, lr=5.49e-7, step_loss=0.013]Steps:  95%|█████████▌| 12386/13000 [19:52<20:05,  1.96s/it, lr=5.49e-7, step_loss=0.508]Steps:  95%|█████████▌| 12387/13000 [19:52<16:07,  1.58s/it, lr=5.49e-7, step_loss=0.508]Steps:  95%|█████████▌| 12387/13000 [19:52<16:07,  1.58s/it, lr=5.48e-7, step_loss=0.0613]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.11it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.93it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.61it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.15it/s]
02/23/2025 16:03:18 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12387/13000 [20:06<16:07,  1.58s/it, lr=5.48e-7, step_loss=0.127] Steps:  95%|█████████▌| 12387/13000 [20:07<16:07,  1.58s/it, lr=5.48e-7, step_loss=0.0468]Steps:  95%|█████████▌| 12387/13000 [20:07<16:07,  1.58s/it, lr=5.48e-7, step_loss=0.0305]Steps:  95%|█████████▌| 12388/13000 [20:07<59:02,  5.79s/it, lr=5.48e-7, step_loss=0.0305]Steps:  95%|█████████▌| 12388/13000 [20:07<59:02,  5.79s/it, lr=5.46e-7, step_loss=0.125] Steps:  95%|█████████▌| 12388/13000 [20:08<59:02,  5.79s/it, lr=5.46e-7, step_loss=0.363]Steps:  95%|█████████▌| 12388/13000 [20:08<59:02,  5.79s/it, lr=5.46e-7, step_loss=0.0273]Steps:  95%|█████████▌| 12388/13000 [20:09<59:02,  5.79s/it, lr=5.46e-7, step_loss=0.189] Steps:  95%|█████████▌| 12389/13000 [20:09<45:41,  4.49s/it, lr=5.46e-7, step_loss=0.189]Steps:  95%|█████████▌| 12389/13000 [20:09<45:41,  4.49s/it, lr=5.44e-7, step_loss=0.0917]Steps:  95%|█████████▌| 12389/13000 [20:09<45:41,  4.49s/it, lr=5.44e-7, step_loss=0.00344]Steps:  95%|█████████▌| 12389/13000 [20:10<45:41,  4.49s/it, lr=5.44e-7, step_loss=0.0989] Steps:  95%|█████████▌| 12389/13000 [20:10<45:41,  4.49s/it, lr=5.44e-7, step_loss=0.177] Steps:  95%|█████████▌| 12390/13000 [20:10<36:28,  3.59s/it, lr=5.44e-7, step_loss=0.177]Steps:  95%|█████████▌| 12390/13000 [20:10<36:28,  3.59s/it, lr=5.42e-7, step_loss=0.00731]Steps:  95%|█████████▌| 12390/13000 [20:11<36:28,  3.59s/it, lr=5.42e-7, step_loss=0.00643]Steps:  95%|█████████▌| 12390/13000 [20:11<36:28,  3.59s/it, lr=5.42e-7, step_loss=0.0476] Steps:  95%|█████████▌| 12390/13000 [20:11<36:28,  3.59s/it, lr=5.42e-7, step_loss=0.00844]Steps:  95%|█████████▌| 12391/13000 [20:12<29:47,  2.94s/it, lr=5.42e-7, step_loss=0.00844]Steps:  95%|█████████▌| 12391/13000 [20:12<29:47,  2.94s/it, lr=5.41e-7, step_loss=0.102]  Steps:  95%|█████████▌| 12391/13000 [20:12<29:47,  2.94s/it, lr=5.41e-7, step_loss=0.0146]Steps:  95%|█████████▌| 12391/13000 [20:13<29:47,  2.94s/it, lr=5.41e-7, step_loss=0.0184]Steps:  95%|█████████▌| 12391/13000 [20:13<29:47,  2.94s/it, lr=5.41e-7, step_loss=0.0779]Steps:  95%|█████████▌| 12392/13000 [20:13<25:07,  2.48s/it, lr=5.41e-7, step_loss=0.0779]Steps:  95%|█████████▌| 12392/13000 [20:13<25:07,  2.48s/it, lr=5.39e-7, step_loss=0.134] Steps:  95%|█████████▌| 12392/13000 [20:14<25:07,  2.48s/it, lr=5.39e-7, step_loss=0.103]Steps:  95%|█████████▌| 12392/13000 [20:14<25:07,  2.48s/it, lr=5.39e-7, step_loss=0.104]Steps:  95%|█████████▌| 12392/13000 [20:14<25:07,  2.48s/it, lr=5.39e-7, step_loss=0.0277]Steps:  95%|█████████▌| 12393/13000 [20:15<21:59,  2.17s/it, lr=5.39e-7, step_loss=0.0277]Steps:  95%|█████████▌| 12393/13000 [20:15<21:59,  2.17s/it, lr=5.37e-7, step_loss=0.473] Steps:  95%|█████████▌| 12393/13000 [20:15<21:59,  2.17s/it, lr=5.37e-7, step_loss=0.042]Steps:  95%|█████████▌| 12393/13000 [20:15<21:59,  2.17s/it, lr=5.37e-7, step_loss=0.256]Steps:  95%|█████████▌| 12393/13000 [20:16<21:59,  2.17s/it, lr=5.37e-7, step_loss=0.0498]Steps:  95%|█████████▌| 12394/13000 [20:16<19:43,  1.95s/it, lr=5.37e-7, step_loss=0.0498]Steps:  95%|█████████▌| 12394/13000 [20:16<19:43,  1.95s/it, lr=5.35e-7, step_loss=0.0387]Steps:  95%|█████████▌| 12394/13000 [20:16<19:43,  1.95s/it, lr=5.35e-7, step_loss=0.118] Steps:  95%|█████████▌| 12394/13000 [20:17<19:43,  1.95s/it, lr=5.35e-7, step_loss=0.00242]Steps:  95%|█████████▌| 12394/13000 [20:17<19:43,  1.95s/it, lr=5.35e-7, step_loss=0.18]   Steps:  95%|█████████▌| 12395/13000 [20:18<18:11,  1.80s/it, lr=5.35e-7, step_loss=0.18]Steps:  95%|█████████▌| 12395/13000 [20:18<18:11,  1.80s/it, lr=5.33e-7, step_loss=0.0211]Steps:  95%|█████████▌| 12395/13000 [20:18<18:11,  1.80s/it, lr=5.33e-7, step_loss=0.0494]Steps:  95%|█████████▌| 12396/13000 [20:18<14:47,  1.47s/it, lr=5.33e-7, step_loss=0.0494]Steps:  95%|█████████▌| 12396/13000 [20:18<14:47,  1.47s/it, lr=5.32e-7, step_loss=0.00421]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.52it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.63it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.85it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.46it/s]
02/23/2025 16:03:45 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12396/13000 [20:33<14:47,  1.47s/it, lr=5.32e-7, step_loss=0.675]  Steps:  95%|█████████▌| 12396/13000 [20:33<14:47,  1.47s/it, lr=5.32e-7, step_loss=0.157]Steps:  95%|█████████▌| 12396/13000 [20:33<14:47,  1.47s/it, lr=5.32e-7, step_loss=0.00544]Steps:  95%|█████████▌| 12397/13000 [20:34<56:53,  5.66s/it, lr=5.32e-7, step_loss=0.00544]Steps:  95%|█████████▌| 12397/13000 [20:34<56:53,  5.66s/it, lr=5.3e-7, step_loss=0.0723]  Steps:  95%|█████████▌| 12397/13000 [20:34<56:53,  5.66s/it, lr=5.3e-7, step_loss=0.0124]Steps:  95%|█████████▌| 12397/13000 [20:34<56:53,  5.66s/it, lr=5.3e-7, step_loss=0.0876]Steps:  95%|█████████▌| 12397/13000 [20:35<56:53,  5.66s/it, lr=5.3e-7, step_loss=0.01]  Steps:  95%|█████████▌| 12398/13000 [20:35<44:07,  4.40s/it, lr=5.3e-7, step_loss=0.01]Steps:  95%|█████████▌| 12398/13000 [20:36<44:07,  4.40s/it, lr=5.28e-7, step_loss=0.139]Steps:  95%|█████████▌| 12398/13000 [20:36<44:07,  4.40s/it, lr=5.28e-7, step_loss=0.525]Steps:  95%|█████████▌| 12398/13000 [20:36<44:07,  4.40s/it, lr=5.28e-7, step_loss=0.00642]Steps:  95%|█████████▌| 12398/13000 [20:37<44:07,  4.40s/it, lr=5.28e-7, step_loss=0.0786] Steps:  95%|█████████▌| 12399/13000 [20:37<36:42,  3.66s/it, lr=5.28e-7, step_loss=0.0786]Steps:  95%|█████████▌| 12399/13000 [20:37<36:42,  3.66s/it, lr=5.26e-7, step_loss=0.00718]Steps:  95%|█████████▌| 12399/13000 [20:38<36:42,  3.66s/it, lr=5.26e-7, step_loss=0.0782] Steps:  95%|█████████▌| 12399/13000 [20:38<36:42,  3.66s/it, lr=5.26e-7, step_loss=0.128] Steps:  95%|█████████▌| 12399/13000 [20:38<36:42,  3.66s/it, lr=5.26e-7, step_loss=0.121]Steps:  95%|█████████▌| 12400/13000 [20:39<30:47,  3.08s/it, lr=5.26e-7, step_loss=0.121]Steps:  95%|█████████▌| 12400/13000 [20:39<30:47,  3.08s/it, lr=5.25e-7, step_loss=0.00592]Steps:  95%|█████████▌| 12400/13000 [20:39<30:47,  3.08s/it, lr=5.25e-7, step_loss=0.0478] Steps:  95%|█████████▌| 12400/13000 [20:40<30:47,  3.08s/it, lr=5.25e-7, step_loss=0.124] Steps:  95%|█████████▌| 12400/13000 [20:40<30:47,  3.08s/it, lr=5.25e-7, step_loss=0.186]Steps:  95%|█████████▌| 12401/13000 [20:40<25:46,  2.58s/it, lr=5.25e-7, step_loss=0.186]Steps:  95%|█████████▌| 12401/13000 [20:40<25:46,  2.58s/it, lr=5.23e-7, step_loss=0.0034]Steps:  95%|█████████▌| 12401/13000 [20:41<25:46,  2.58s/it, lr=5.23e-7, step_loss=0.253] Steps:  95%|█████████▌| 12401/13000 [20:41<25:46,  2.58s/it, lr=5.23e-7, step_loss=0.0728]Steps:  95%|█████████▌| 12401/13000 [20:41<25:46,  2.58s/it, lr=5.23e-7, step_loss=0.0849]Steps:  95%|█████████▌| 12402/13000 [20:42<22:18,  2.24s/it, lr=5.23e-7, step_loss=0.0849]Steps:  95%|█████████▌| 12402/13000 [20:43<22:18,  2.24s/it, lr=5.21e-7, step_loss=0.127] Steps:  95%|█████████▌| 12402/13000 [20:43<22:18,  2.24s/it, lr=5.21e-7, step_loss=0.0113]Steps:  95%|█████████▌| 12402/13000 [20:43<22:18,  2.24s/it, lr=5.21e-7, step_loss=0.103] Steps:  95%|█████████▌| 12402/13000 [20:44<22:18,  2.24s/it, lr=5.21e-7, step_loss=0.129]Steps:  95%|█████████▌| 12403/13000 [20:44<22:54,  2.30s/it, lr=5.21e-7, step_loss=0.129]Steps:  95%|█████████▌| 12403/13000 [20:44<22:54,  2.30s/it, lr=5.19e-7, step_loss=0.114]Steps:  95%|█████████▌| 12403/13000 [20:45<22:54,  2.30s/it, lr=5.19e-7, step_loss=0.0343]Steps:  95%|█████████▌| 12403/13000 [20:45<22:54,  2.30s/it, lr=5.19e-7, step_loss=0.262] Steps:  95%|█████████▌| 12403/13000 [20:45<22:54,  2.30s/it, lr=5.19e-7, step_loss=0.331]Steps:  95%|█████████▌| 12404/13000 [20:46<20:14,  2.04s/it, lr=5.19e-7, step_loss=0.331]Steps:  95%|█████████▌| 12404/13000 [20:46<20:14,  2.04s/it, lr=5.18e-7, step_loss=0.011]Steps:  95%|█████████▌| 12404/13000 [20:46<20:14,  2.04s/it, lr=5.18e-7, step_loss=0.0119]Steps:  95%|█████████▌| 12405/13000 [20:46<16:14,  1.64s/it, lr=5.18e-7, step_loss=0.0119]Steps:  95%|█████████▌| 12405/13000 [20:46<16:14,  1.64s/it, lr=5.16e-7, step_loss=0.021] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.20it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.67it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.48it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.01it/s]
02/23/2025 16:04:13 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12405/13000 [21:01<16:14,  1.64s/it, lr=5.16e-7, step_loss=0.0252]Steps:  95%|█████████▌| 12405/13000 [21:01<16:14,  1.64s/it, lr=5.16e-7, step_loss=0.00533]Steps:  95%|█████████▌| 12405/13000 [21:01<16:14,  1.64s/it, lr=5.16e-7, step_loss=0.0709] Steps:  95%|█████████▌| 12406/13000 [21:02<57:35,  5.82s/it, lr=5.16e-7, step_loss=0.0709]Steps:  95%|█████████▌| 12406/13000 [21:02<57:35,  5.82s/it, lr=5.14e-7, step_loss=0.532] Steps:  95%|█████████▌| 12406/13000 [21:02<57:35,  5.82s/it, lr=5.14e-7, step_loss=0.183]Steps:  95%|█████████▌| 12406/13000 [21:03<57:35,  5.82s/it, lr=5.14e-7, step_loss=0.121]Steps:  95%|█████████▌| 12406/13000 [21:03<57:35,  5.82s/it, lr=5.14e-7, step_loss=0.0271]Steps:  95%|█████████▌| 12407/13000 [21:03<44:27,  4.50s/it, lr=5.14e-7, step_loss=0.0271]Steps:  95%|█████████▌| 12407/13000 [21:03<44:27,  4.50s/it, lr=5.13e-7, step_loss=0.0163]Steps:  95%|█████████▌| 12407/13000 [21:04<44:27,  4.50s/it, lr=5.13e-7, step_loss=0.336] Steps:  95%|█████████▌| 12407/13000 [21:04<44:27,  4.50s/it, lr=5.13e-7, step_loss=0.00702]Steps:  95%|█████████▌| 12407/13000 [21:04<44:27,  4.50s/it, lr=5.13e-7, step_loss=0.0154] Steps:  95%|█████████▌| 12408/13000 [21:05<35:31,  3.60s/it, lr=5.13e-7, step_loss=0.0154]Steps:  95%|█████████▌| 12408/13000 [21:05<35:31,  3.60s/it, lr=5.11e-7, step_loss=0.0559]Steps:  95%|█████████▌| 12408/13000 [21:05<35:31,  3.60s/it, lr=5.11e-7, step_loss=0.0124]Steps:  95%|█████████▌| 12408/13000 [21:05<35:31,  3.60s/it, lr=5.11e-7, step_loss=0.0611]Steps:  95%|█████████▌| 12408/13000 [21:06<35:31,  3.60s/it, lr=5.11e-7, step_loss=0.0767]Steps:  95%|█████████▌| 12409/13000 [21:06<29:06,  2.95s/it, lr=5.11e-7, step_loss=0.0767]Steps:  95%|█████████▌| 12409/13000 [21:06<29:06,  2.95s/it, lr=5.09e-7, step_loss=0.551] Steps:  95%|█████████▌| 12409/13000 [21:07<29:06,  2.95s/it, lr=5.09e-7, step_loss=0.0172]Steps:  95%|█████████▌| 12409/13000 [21:07<29:06,  2.95s/it, lr=5.09e-7, step_loss=0.0265]Steps:  95%|█████████▌| 12409/13000 [21:07<29:06,  2.95s/it, lr=5.09e-7, step_loss=0.137] Steps:  95%|█████████▌| 12410/13000 [21:08<24:40,  2.51s/it, lr=5.09e-7, step_loss=0.137]Steps:  95%|█████████▌| 12410/13000 [21:08<24:40,  2.51s/it, lr=5.07e-7, step_loss=0.00689]Steps:  95%|█████████▌| 12410/13000 [21:08<24:40,  2.51s/it, lr=5.07e-7, step_loss=0.00584]Steps:  95%|█████████▌| 12410/13000 [21:08<24:40,  2.51s/it, lr=5.07e-7, step_loss=0.00964]Steps:  95%|█████████▌| 12410/13000 [21:09<24:40,  2.51s/it, lr=5.07e-7, step_loss=0.211]  Steps:  95%|█████████▌| 12411/13000 [21:09<21:32,  2.19s/it, lr=5.07e-7, step_loss=0.211]Steps:  95%|█████████▌| 12411/13000 [21:09<21:32,  2.19s/it, lr=5.06e-7, step_loss=0.0108]Steps:  95%|█████████▌| 12411/13000 [21:10<21:32,  2.19s/it, lr=5.06e-7, step_loss=0.34]  Steps:  95%|█████████▌| 12411/13000 [21:10<21:32,  2.19s/it, lr=5.06e-7, step_loss=0.133]Steps:  95%|█████████▌| 12411/13000 [21:10<21:32,  2.19s/it, lr=5.06e-7, step_loss=0.00787]Steps:  95%|█████████▌| 12412/13000 [21:11<19:29,  1.99s/it, lr=5.06e-7, step_loss=0.00787]Steps:  95%|█████████▌| 12412/13000 [21:12<19:29,  1.99s/it, lr=5.04e-7, step_loss=0.0506] Steps:  95%|█████████▌| 12412/13000 [21:12<19:29,  1.99s/it, lr=5.04e-7, step_loss=0.0136]Steps:  95%|█████████▌| 12412/13000 [21:13<19:29,  1.99s/it, lr=5.04e-7, step_loss=0.0284]Steps:  95%|█████████▌| 12412/13000 [21:13<19:29,  1.99s/it, lr=5.04e-7, step_loss=0.0153]Steps:  95%|█████████▌| 12413/13000 [21:13<22:06,  2.26s/it, lr=5.04e-7, step_loss=0.0153]Steps:  95%|█████████▌| 12413/13000 [21:14<22:06,  2.26s/it, lr=5.02e-7, step_loss=0.216] Steps:  95%|█████████▌| 12413/13000 [21:14<22:06,  2.26s/it, lr=5.02e-7, step_loss=0.00561]Steps:  95%|█████████▌| 12414/13000 [21:14<17:30,  1.79s/it, lr=5.02e-7, step_loss=0.00561]Steps:  95%|█████████▌| 12414/13000 [21:14<17:30,  1.79s/it, lr=5.01e-7, step_loss=0.0717] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.60it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.63it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.93it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.53it/s]
02/23/2025 16:04:41 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  95%|█████████▌| 12414/13000 [21:29<17:30,  1.79s/it, lr=5.01e-7, step_loss=0.00634]Steps:  95%|█████████▌| 12414/13000 [21:29<17:30,  1.79s/it, lr=5.01e-7, step_loss=0.298]  Steps:  95%|█████████▌| 12414/13000 [21:29<17:30,  1.79s/it, lr=5.01e-7, step_loss=0.00325]Steps:  96%|█████████▌| 12415/13000 [21:30<57:37,  5.91s/it, lr=5.01e-7, step_loss=0.00325]Steps:  96%|█████████▌| 12415/13000 [21:30<57:37,  5.91s/it, lr=4.99e-7, step_loss=0.248]  Steps:  96%|█████████▌| 12415/13000 [21:30<57:37,  5.91s/it, lr=4.99e-7, step_loss=0.12] Steps:  96%|█████████▌| 12415/13000 [21:31<57:37,  5.91s/it, lr=4.99e-7, step_loss=0.35]Steps:  96%|█████████▌| 12415/13000 [21:31<57:37,  5.91s/it, lr=4.99e-7, step_loss=0.0359]Steps:  96%|█████████▌| 12416/13000 [21:31<44:28,  4.57s/it, lr=4.99e-7, step_loss=0.0359]Steps:  96%|█████████▌| 12416/13000 [21:31<44:28,  4.57s/it, lr=4.97e-7, step_loss=0.0913]Steps:  96%|█████████▌| 12416/13000 [21:32<44:28,  4.57s/it, lr=4.97e-7, step_loss=0.0326]Steps:  96%|█████████▌| 12416/13000 [21:32<44:28,  4.57s/it, lr=4.97e-7, step_loss=0.0609]Steps:  96%|█████████▌| 12416/13000 [21:32<44:28,  4.57s/it, lr=4.97e-7, step_loss=0.116] Steps:  96%|█████████▌| 12417/13000 [21:33<35:23,  3.64s/it, lr=4.97e-7, step_loss=0.116]Steps:  96%|█████████▌| 12417/13000 [21:33<35:23,  3.64s/it, lr=4.95e-7, step_loss=0.0762]Steps:  96%|█████████▌| 12417/13000 [21:33<35:23,  3.64s/it, lr=4.95e-7, step_loss=0.00431]Steps:  96%|█████████▌| 12417/13000 [21:33<35:23,  3.64s/it, lr=4.95e-7, step_loss=0.546]  Steps:  96%|█████████▌| 12417/13000 [21:36<35:23,  3.64s/it, lr=4.95e-7, step_loss=0.113]Steps:  96%|█████████▌| 12418/13000 [21:37<36:29,  3.76s/it, lr=4.95e-7, step_loss=0.113]Steps:  96%|█████████▌| 12418/13000 [21:37<36:29,  3.76s/it, lr=4.94e-7, step_loss=0.0739]Steps:  96%|█████████▌| 12418/13000 [21:37<36:29,  3.76s/it, lr=4.94e-7, step_loss=0.0305]Steps:  96%|█████████▌| 12418/13000 [21:37<36:29,  3.76s/it, lr=4.94e-7, step_loss=0.131] Steps:  96%|█████████▌| 12418/13000 [21:38<36:29,  3.76s/it, lr=4.94e-7, step_loss=0.0349]Steps:  96%|█████████▌| 12419/13000 [21:38<29:42,  3.07s/it, lr=4.94e-7, step_loss=0.0349]Steps:  96%|█████████▌| 12419/13000 [21:38<29:42,  3.07s/it, lr=4.92e-7, step_loss=0.0476]Steps:  96%|█████████▌| 12419/13000 [21:39<29:42,  3.07s/it, lr=4.92e-7, step_loss=0.0434]Steps:  96%|█████████▌| 12419/13000 [21:39<29:42,  3.07s/it, lr=4.92e-7, step_loss=0.0622]Steps:  96%|█████████▌| 12419/13000 [21:39<29:42,  3.07s/it, lr=4.92e-7, step_loss=0.178] Steps:  96%|█████████▌| 12420/13000 [21:40<24:57,  2.58s/it, lr=4.92e-7, step_loss=0.178]Steps:  96%|█████████▌| 12420/13000 [21:40<24:57,  2.58s/it, lr=4.9e-7, step_loss=0.024] Steps:  96%|█████████▌| 12420/13000 [21:40<24:57,  2.58s/it, lr=4.9e-7, step_loss=0.0502]Steps:  96%|█████████▌| 12420/13000 [21:40<24:57,  2.58s/it, lr=4.9e-7, step_loss=0.033] Steps:  96%|█████████▌| 12420/13000 [21:41<24:57,  2.58s/it, lr=4.9e-7, step_loss=0.0598]Steps:  96%|█████████▌| 12421/13000 [21:41<21:36,  2.24s/it, lr=4.9e-7, step_loss=0.0598]Steps:  96%|█████████▌| 12421/13000 [21:41<21:36,  2.24s/it, lr=4.89e-7, step_loss=0.0212]Steps:  96%|█████████▌| 12421/13000 [21:41<21:36,  2.24s/it, lr=4.89e-7, step_loss=0.0176]Steps:  96%|█████████▌| 12421/13000 [21:42<21:36,  2.24s/it, lr=4.89e-7, step_loss=0.0165]Steps:  96%|█████████▌| 12421/13000 [21:42<21:36,  2.24s/it, lr=4.89e-7, step_loss=0.00457]Steps:  96%|█████████▌| 12422/13000 [21:42<19:15,  2.00s/it, lr=4.89e-7, step_loss=0.00457]Steps:  96%|█████████▌| 12422/13000 [21:43<19:15,  2.00s/it, lr=4.87e-7, step_loss=0.00577]Steps:  96%|█████████▌| 12422/13000 [21:43<19:15,  2.00s/it, lr=4.87e-7, step_loss=0.0772] Steps:  96%|█████████▌| 12423/13000 [21:43<15:27,  1.61s/it, lr=4.87e-7, step_loss=0.0772]Steps:  96%|█████████▌| 12423/13000 [21:43<15:27,  1.61s/it, lr=4.85e-7, step_loss=0.231] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.57it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.28it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.79it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.31it/s]
02/23/2025 16:05:10 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12423/13000 [21:58<15:27,  1.61s/it, lr=4.85e-7, step_loss=0.127]Steps:  96%|█████████▌| 12423/13000 [21:58<15:27,  1.61s/it, lr=4.85e-7, step_loss=0.0514]Steps:  96%|█████████▌| 12423/13000 [21:58<15:27,  1.61s/it, lr=4.85e-7, step_loss=0.177] Steps:  96%|█████████▌| 12424/13000 [21:59<55:34,  5.79s/it, lr=4.85e-7, step_loss=0.177]Steps:  96%|█████████▌| 12424/13000 [21:59<55:34,  5.79s/it, lr=4.84e-7, step_loss=0.0992]Steps:  96%|█████████▌| 12424/13000 [21:59<55:34,  5.79s/it, lr=4.84e-7, step_loss=0.0282]Steps:  96%|█████████▌| 12424/13000 [21:59<55:34,  5.79s/it, lr=4.84e-7, step_loss=0.0143]Steps:  96%|█████████▌| 12424/13000 [22:00<55:34,  5.79s/it, lr=4.84e-7, step_loss=0.0504]Steps:  96%|█████████▌| 12425/13000 [22:00<43:03,  4.49s/it, lr=4.84e-7, step_loss=0.0504]Steps:  96%|█████████▌| 12425/13000 [22:00<43:03,  4.49s/it, lr=4.82e-7, step_loss=0.0341]Steps:  96%|█████████▌| 12425/13000 [22:01<43:03,  4.49s/it, lr=4.82e-7, step_loss=0.00315]Steps:  96%|█████████▌| 12425/13000 [22:01<43:03,  4.49s/it, lr=4.82e-7, step_loss=0.0716] Steps:  96%|█████████▌| 12425/13000 [22:01<43:03,  4.49s/it, lr=4.82e-7, step_loss=0.0281]Steps:  96%|█████████▌| 12426/13000 [22:02<34:09,  3.57s/it, lr=4.82e-7, step_loss=0.0281]Steps:  96%|█████████▌| 12426/13000 [22:02<34:09,  3.57s/it, lr=4.8e-7, step_loss=0.00309]Steps:  96%|█████████▌| 12426/13000 [22:02<34:09,  3.57s/it, lr=4.8e-7, step_loss=0.167]  Steps:  96%|█████████▌| 12426/13000 [22:02<34:09,  3.57s/it, lr=4.8e-7, step_loss=0.00275]Steps:  96%|█████████▌| 12426/13000 [22:03<34:09,  3.57s/it, lr=4.8e-7, step_loss=0.125]  Steps:  96%|█████████▌| 12427/13000 [22:03<27:58,  2.93s/it, lr=4.8e-7, step_loss=0.125]Steps:  96%|█████████▌| 12427/13000 [22:03<27:58,  2.93s/it, lr=4.79e-7, step_loss=0.114]Steps:  96%|█████████▌| 12427/13000 [22:03<27:58,  2.93s/it, lr=4.79e-7, step_loss=0.179]Steps:  96%|█████████▌| 12427/13000 [22:04<27:58,  2.93s/it, lr=4.79e-7, step_loss=0.0123]Steps:  96%|█████████▌| 12427/13000 [22:04<27:58,  2.93s/it, lr=4.79e-7, step_loss=0.0075]Steps:  96%|█████████▌| 12428/13000 [22:04<23:36,  2.48s/it, lr=4.79e-7, step_loss=0.0075]Steps:  96%|█████████▌| 12428/13000 [22:04<23:36,  2.48s/it, lr=4.77e-7, step_loss=0.21]  Steps:  96%|█████████▌| 12428/13000 [22:05<23:36,  2.48s/it, lr=4.77e-7, step_loss=0.0546]Steps:  96%|█████████▌| 12428/13000 [22:05<23:36,  2.48s/it, lr=4.77e-7, step_loss=0.0664]Steps:  96%|█████████▌| 12428/13000 [22:06<23:36,  2.48s/it, lr=4.77e-7, step_loss=0.00894]Steps:  96%|█████████▌| 12429/13000 [22:06<20:44,  2.18s/it, lr=4.77e-7, step_loss=0.00894]Steps:  96%|█████████▌| 12429/13000 [22:06<20:44,  2.18s/it, lr=4.75e-7, step_loss=0.0455] Steps:  96%|█████████▌| 12429/13000 [22:06<20:44,  2.18s/it, lr=4.75e-7, step_loss=0.027] Steps:  96%|█████████▌| 12429/13000 [22:07<20:44,  2.18s/it, lr=4.75e-7, step_loss=0.0197]Steps:  96%|█████████▌| 12429/13000 [22:07<20:44,  2.18s/it, lr=4.75e-7, step_loss=0.305] Steps:  96%|█████████▌| 12430/13000 [22:07<18:38,  1.96s/it, lr=4.75e-7, step_loss=0.305]Steps:  96%|█████████▌| 12430/13000 [22:07<18:38,  1.96s/it, lr=4.74e-7, step_loss=0.0345]Steps:  96%|█████████▌| 12430/13000 [22:08<18:38,  1.96s/it, lr=4.74e-7, step_loss=0.02]  Steps:  96%|█████████▌| 12430/13000 [22:08<18:38,  1.96s/it, lr=4.74e-7, step_loss=0.196]Steps:  96%|█████████▌| 12430/13000 [22:09<18:38,  1.96s/it, lr=4.74e-7, step_loss=0.00289]Steps:  96%|█████████▌| 12431/13000 [22:09<17:11,  1.81s/it, lr=4.74e-7, step_loss=0.00289]Steps:  96%|█████████▌| 12431/13000 [22:09<17:11,  1.81s/it, lr=4.72e-7, step_loss=0.0203] Steps:  96%|█████████▌| 12431/13000 [22:09<17:11,  1.81s/it, lr=4.72e-7, step_loss=0.149] Steps:  96%|█████████▌| 12432/13000 [22:10<13:59,  1.48s/it, lr=4.72e-7, step_loss=0.149]Steps:  96%|█████████▌| 12432/13000 [22:10<13:59,  1.48s/it, lr=4.7e-7, step_loss=0.305] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.26it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.43it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.27it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s]
02/23/2025 16:05:36 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12432/13000 [22:24<13:59,  1.48s/it, lr=4.7e-7, step_loss=0.116]Steps:  96%|█████████▌| 12432/13000 [22:24<13:59,  1.48s/it, lr=4.7e-7, step_loss=0.0218]Steps:  96%|█████████▌| 12432/13000 [22:24<13:59,  1.48s/it, lr=4.7e-7, step_loss=0.0882]Steps:  96%|█████████▌| 12433/13000 [22:25<53:01,  5.61s/it, lr=4.7e-7, step_loss=0.0882]Steps:  96%|█████████▌| 12433/13000 [22:25<53:01,  5.61s/it, lr=4.69e-7, step_loss=0.0883]Steps:  96%|█████████▌| 12433/13000 [22:25<53:01,  5.61s/it, lr=4.69e-7, step_loss=0.0971]Steps:  96%|█████████▌| 12433/13000 [22:26<53:01,  5.61s/it, lr=4.69e-7, step_loss=0.00579]Steps:  96%|█████████▌| 12433/13000 [22:26<53:01,  5.61s/it, lr=4.69e-7, step_loss=0.429]  Steps:  96%|█████████▌| 12434/13000 [22:26<41:05,  4.36s/it, lr=4.69e-7, step_loss=0.429]Steps:  96%|█████████▌| 12434/13000 [22:26<41:05,  4.36s/it, lr=4.67e-7, step_loss=0.00661]Steps:  96%|█████████▌| 12434/13000 [22:27<41:05,  4.36s/it, lr=4.67e-7, step_loss=0.102]  Steps:  96%|█████████▌| 12434/13000 [22:27<41:05,  4.36s/it, lr=4.67e-7, step_loss=0.012]Steps:  96%|█████████▌| 12434/13000 [22:27<41:05,  4.36s/it, lr=4.67e-7, step_loss=0.147]Steps:  96%|█████████▌| 12435/13000 [22:28<32:52,  3.49s/it, lr=4.67e-7, step_loss=0.147]Steps:  96%|█████████▌| 12435/13000 [22:28<32:52,  3.49s/it, lr=4.65e-7, step_loss=0.00464]Steps:  96%|█████████▌| 12435/13000 [22:28<32:52,  3.49s/it, lr=4.65e-7, step_loss=0.567]  Steps:  96%|█████████▌| 12435/13000 [22:28<32:52,  3.49s/it, lr=4.65e-7, step_loss=0.245]Steps:  96%|█████████▌| 12435/13000 [22:29<32:52,  3.49s/it, lr=4.65e-7, step_loss=0.0265]Steps:  96%|█████████▌| 12436/13000 [22:29<27:04,  2.88s/it, lr=4.65e-7, step_loss=0.0265]Steps:  96%|█████████▌| 12436/13000 [22:29<27:04,  2.88s/it, lr=4.64e-7, step_loss=0.0664]Steps:  96%|█████████▌| 12436/13000 [22:30<27:04,  2.88s/it, lr=4.64e-7, step_loss=0.113] Steps:  96%|█████████▌| 12436/13000 [22:30<27:04,  2.88s/it, lr=4.64e-7, step_loss=0.142]Steps:  96%|█████████▌| 12436/13000 [22:30<27:04,  2.88s/it, lr=4.64e-7, step_loss=0.0622]Steps:  96%|█████████▌| 12437/13000 [22:31<23:04,  2.46s/it, lr=4.64e-7, step_loss=0.0622]Steps:  96%|█████████▌| 12437/13000 [22:32<23:04,  2.46s/it, lr=4.62e-7, step_loss=0.148] Steps:  96%|█████████▌| 12437/13000 [22:32<23:04,  2.46s/it, lr=4.62e-7, step_loss=0.0702]Steps:  96%|█████████▌| 12437/13000 [22:32<23:04,  2.46s/it, lr=4.62e-7, step_loss=0.194] Steps:  96%|█████████▌| 12437/13000 [22:33<23:04,  2.46s/it, lr=4.62e-7, step_loss=0.034]Steps:  96%|█████████▌| 12438/13000 [22:33<23:03,  2.46s/it, lr=4.62e-7, step_loss=0.034]Steps:  96%|█████████▌| 12438/13000 [22:33<23:03,  2.46s/it, lr=4.6e-7, step_loss=0.0657]Steps:  96%|█████████▌| 12438/13000 [22:34<23:03,  2.46s/it, lr=4.6e-7, step_loss=0.0069]Steps:  96%|█████████▌| 12438/13000 [22:34<23:03,  2.46s/it, lr=4.6e-7, step_loss=0.244] Steps:  96%|█████████▌| 12438/13000 [22:34<23:03,  2.46s/it, lr=4.6e-7, step_loss=0.222]Steps:  96%|█████████▌| 12439/13000 [22:35<20:10,  2.16s/it, lr=4.6e-7, step_loss=0.222]Steps:  96%|█████████▌| 12439/13000 [22:35<20:10,  2.16s/it, lr=4.59e-7, step_loss=0.407]Steps:  96%|█████████▌| 12439/13000 [22:35<20:10,  2.16s/it, lr=4.59e-7, step_loss=0.238]Steps:  96%|█████████▌| 12439/13000 [22:35<20:10,  2.16s/it, lr=4.59e-7, step_loss=0.0718]Steps:  96%|█████████▌| 12439/13000 [22:36<20:10,  2.16s/it, lr=4.59e-7, step_loss=0.076] Steps:  96%|█████████▌| 12440/13000 [22:36<18:03,  1.93s/it, lr=4.59e-7, step_loss=0.076]Steps:  96%|█████████▌| 12440/13000 [22:37<18:03,  1.93s/it, lr=4.57e-7, step_loss=0.0568]Steps:  96%|█████████▌| 12440/13000 [22:37<18:03,  1.93s/it, lr=4.57e-7, step_loss=0.0698]Steps:  96%|█████████▌| 12441/13000 [22:37<16:30,  1.77s/it, lr=4.57e-7, step_loss=0.0698]Steps:  96%|█████████▌| 12441/13000 [22:37<16:30,  1.77s/it, lr=4.56e-7, step_loss=0.548] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.20it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.70it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.89it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.49it/s]
02/23/2025 16:06:04 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12441/13000 [22:52<16:30,  1.77s/it, lr=4.56e-7, step_loss=0.254]Steps:  96%|█████████▌| 12441/13000 [22:52<16:30,  1.77s/it, lr=4.56e-7, step_loss=0.00446]Steps:  96%|█████████▌| 12441/13000 [22:53<16:30,  1.77s/it, lr=4.56e-7, step_loss=0.00516]Steps:  96%|█████████▌| 12442/13000 [22:53<54:57,  5.91s/it, lr=4.56e-7, step_loss=0.00516]Steps:  96%|█████████▌| 12442/13000 [22:53<54:57,  5.91s/it, lr=4.54e-7, step_loss=0.323]  Steps:  96%|█████████▌| 12442/13000 [22:53<54:57,  5.91s/it, lr=4.54e-7, step_loss=0.0515]Steps:  96%|█████████▌| 12442/13000 [22:55<54:57,  5.91s/it, lr=4.54e-7, step_loss=0.00564]Steps:  96%|█████████▌| 12442/13000 [22:55<54:57,  5.91s/it, lr=4.54e-7, step_loss=0.0706] Steps:  96%|█████████▌| 12443/13000 [22:55<44:57,  4.84s/it, lr=4.54e-7, step_loss=0.0706]Steps:  96%|█████████▌| 12443/13000 [22:55<44:57,  4.84s/it, lr=4.52e-7, step_loss=0.0095]Steps:  96%|█████████▌| 12443/13000 [22:56<44:57,  4.84s/it, lr=4.52e-7, step_loss=0.321] Steps:  96%|█████████▌| 12443/13000 [22:56<44:57,  4.84s/it, lr=4.52e-7, step_loss=0.0336]Steps:  96%|█████████▌| 12443/13000 [22:56<44:57,  4.84s/it, lr=4.52e-7, step_loss=0.0265]Steps:  96%|█████████▌| 12444/13000 [22:57<35:26,  3.82s/it, lr=4.52e-7, step_loss=0.0265]Steps:  96%|█████████▌| 12444/13000 [22:57<35:26,  3.82s/it, lr=4.51e-7, step_loss=0.0213]Steps:  96%|█████████▌| 12444/13000 [22:57<35:26,  3.82s/it, lr=4.51e-7, step_loss=0.0322]Steps:  96%|█████████▌| 12444/13000 [22:57<35:26,  3.82s/it, lr=4.51e-7, step_loss=0.108] Steps:  96%|█████████▌| 12444/13000 [22:58<35:26,  3.82s/it, lr=4.51e-7, step_loss=0.00277]Steps:  96%|█████████▌| 12445/13000 [22:58<28:49,  3.12s/it, lr=4.51e-7, step_loss=0.00277]Steps:  96%|█████████▌| 12445/13000 [22:58<28:49,  3.12s/it, lr=4.49e-7, step_loss=0.0706] Steps:  96%|█████████▌| 12445/13000 [22:59<28:49,  3.12s/it, lr=4.49e-7, step_loss=0.0684]Steps:  96%|█████████▌| 12445/13000 [22:59<28:49,  3.12s/it, lr=4.49e-7, step_loss=0.0779]Steps:  96%|█████████▌| 12445/13000 [22:59<28:49,  3.12s/it, lr=4.49e-7, step_loss=0.0733]Steps:  96%|█████████▌| 12446/13000 [23:00<24:37,  2.67s/it, lr=4.49e-7, step_loss=0.0733]Steps:  96%|█████████▌| 12446/13000 [23:00<24:37,  2.67s/it, lr=4.47e-7, step_loss=0.037] Steps:  96%|█████████▌| 12446/13000 [23:00<24:37,  2.67s/it, lr=4.47e-7, step_loss=0.115]Steps:  96%|█████████▌| 12446/13000 [23:01<24:37,  2.67s/it, lr=4.47e-7, step_loss=0.127]Steps:  96%|█████████▌| 12446/13000 [23:01<24:37,  2.67s/it, lr=4.47e-7, step_loss=0.16] Steps:  96%|█████████▌| 12447/13000 [23:01<21:17,  2.31s/it, lr=4.47e-7, step_loss=0.16]Steps:  96%|█████████▌| 12447/13000 [23:01<21:17,  2.31s/it, lr=4.46e-7, step_loss=0.00884]Steps:  96%|█████████▌| 12447/13000 [23:02<21:17,  2.31s/it, lr=4.46e-7, step_loss=0.058]  Steps:  96%|█████████▌| 12447/13000 [23:02<21:17,  2.31s/it, lr=4.46e-7, step_loss=0.0693]Steps:  96%|█████████▌| 12447/13000 [23:02<21:17,  2.31s/it, lr=4.46e-7, step_loss=0.0947]Steps:  96%|█████████▌| 12448/13000 [23:03<18:51,  2.05s/it, lr=4.46e-7, step_loss=0.0947]Steps:  96%|█████████▌| 12448/13000 [23:04<18:51,  2.05s/it, lr=4.44e-7, step_loss=0.0729]Steps:  96%|█████████▌| 12448/13000 [23:06<18:51,  2.05s/it, lr=4.44e-7, step_loss=0.0406]Steps:  96%|█████████▌| 12448/13000 [23:06<18:51,  2.05s/it, lr=4.44e-7, step_loss=0.0716]Steps:  96%|█████████▌| 12448/13000 [23:07<18:51,  2.05s/it, lr=4.44e-7, step_loss=0.558] Steps:  96%|█████████▌| 12449/13000 [23:07<25:05,  2.73s/it, lr=4.44e-7, step_loss=0.558]Steps:  96%|█████████▌| 12449/13000 [23:07<25:05,  2.73s/it, lr=4.43e-7, step_loss=0.0468]Steps:  96%|█████████▌| 12449/13000 [23:07<25:05,  2.73s/it, lr=4.43e-7, step_loss=0.24]  Steps:  96%|█████████▌| 12450/13000 [23:08<19:23,  2.12s/it, lr=4.43e-7, step_loss=0.24]Steps:  96%|█████████▌| 12450/13000 [23:08<19:23,  2.12s/it, lr=4.41e-7, step_loss=0.0224]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.19it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.46it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.73it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.12it/s]
02/23/2025 16:06:34 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12450/13000 [23:22<19:23,  2.12s/it, lr=4.41e-7, step_loss=0.00563]Steps:  96%|█████████▌| 12450/13000 [23:23<19:23,  2.12s/it, lr=4.41e-7, step_loss=0.0855] Steps:  96%|█████████▌| 12450/13000 [23:23<19:23,  2.12s/it, lr=4.41e-7, step_loss=0.0889]Steps:  96%|█████████▌| 12451/13000 [23:23<56:31,  6.18s/it, lr=4.41e-7, step_loss=0.0889]Steps:  96%|█████████▌| 12451/13000 [23:23<56:31,  6.18s/it, lr=4.39e-7, step_loss=0.00791]Steps:  96%|█████████▌| 12451/13000 [23:24<56:31,  6.18s/it, lr=4.39e-7, step_loss=0.00652]Steps:  96%|█████████▌| 12451/13000 [23:24<56:31,  6.18s/it, lr=4.39e-7, step_loss=0.372]  Steps:  96%|█████████▌| 12451/13000 [23:24<56:31,  6.18s/it, lr=4.39e-7, step_loss=0.0482]Steps:  96%|█████████▌| 12452/13000 [23:25<43:23,  4.75s/it, lr=4.39e-7, step_loss=0.0482]Steps:  96%|█████████▌| 12452/13000 [23:25<43:23,  4.75s/it, lr=4.38e-7, step_loss=0.0706]Steps:  96%|█████████▌| 12452/13000 [23:25<43:23,  4.75s/it, lr=4.38e-7, step_loss=0.031] Steps:  96%|█████████▌| 12452/13000 [23:26<43:23,  4.75s/it, lr=4.38e-7, step_loss=0.131]Steps:  96%|█████████▌| 12452/13000 [23:26<43:23,  4.75s/it, lr=4.38e-7, step_loss=0.133]Steps:  96%|█████████▌| 12453/13000 [23:26<34:22,  3.77s/it, lr=4.38e-7, step_loss=0.133]Steps:  96%|█████████▌| 12453/13000 [23:26<34:22,  3.77s/it, lr=4.36e-7, step_loss=0.0369]Steps:  96%|█████████▌| 12453/13000 [23:27<34:22,  3.77s/it, lr=4.36e-7, step_loss=0.0586]Steps:  96%|█████████▌| 12453/13000 [23:27<34:22,  3.77s/it, lr=4.36e-7, step_loss=0.137] Steps:  96%|█████████▌| 12453/13000 [23:27<34:22,  3.77s/it, lr=4.36e-7, step_loss=0.121]Steps:  96%|█████████▌| 12454/13000 [23:28<27:59,  3.08s/it, lr=4.36e-7, step_loss=0.121]Steps:  96%|█████████▌| 12454/13000 [23:28<27:59,  3.08s/it, lr=4.35e-7, step_loss=0.0251]Steps:  96%|█████████▌| 12454/13000 [23:28<27:59,  3.08s/it, lr=4.35e-7, step_loss=0.0829]Steps:  96%|█████████▌| 12454/13000 [23:29<27:59,  3.08s/it, lr=4.35e-7, step_loss=0.0689]Steps:  96%|█████████▌| 12454/13000 [23:29<27:59,  3.08s/it, lr=4.35e-7, step_loss=0.0914]Steps:  96%|█████████▌| 12455/13000 [23:29<23:34,  2.60s/it, lr=4.35e-7, step_loss=0.0914]Steps:  96%|█████████▌| 12455/13000 [23:29<23:34,  2.60s/it, lr=4.33e-7, step_loss=0.00413]Steps:  96%|█████████▌| 12455/13000 [23:30<23:34,  2.60s/it, lr=4.33e-7, step_loss=0.00391]Steps:  96%|█████████▌| 12455/13000 [23:30<23:34,  2.60s/it, lr=4.33e-7, step_loss=0.104]  Steps:  96%|█████████▌| 12455/13000 [23:30<23:34,  2.60s/it, lr=4.33e-7, step_loss=0.0449]Steps:  96%|█████████▌| 12456/13000 [23:31<20:28,  2.26s/it, lr=4.33e-7, step_loss=0.0449]Steps:  96%|█████████▌| 12456/13000 [23:31<20:28,  2.26s/it, lr=4.31e-7, step_loss=0.0505]Steps:  96%|█████████▌| 12456/13000 [23:31<20:28,  2.26s/it, lr=4.31e-7, step_loss=0.138] Steps:  96%|█████████▌| 12456/13000 [23:31<20:28,  2.26s/it, lr=4.31e-7, step_loss=0.0223]Steps:  96%|█████████▌| 12456/13000 [23:32<20:28,  2.26s/it, lr=4.31e-7, step_loss=0.119] Steps:  96%|█████████▌| 12457/13000 [23:32<18:16,  2.02s/it, lr=4.31e-7, step_loss=0.119]Steps:  96%|█████████▌| 12457/13000 [23:33<18:16,  2.02s/it, lr=4.3e-7, step_loss=0.0365]Steps:  96%|█████████▌| 12457/13000 [23:34<18:16,  2.02s/it, lr=4.3e-7, step_loss=0.0122]Steps:  96%|█████████▌| 12457/13000 [23:34<18:16,  2.02s/it, lr=4.3e-7, step_loss=0.00911]Steps:  96%|█████████▌| 12457/13000 [23:35<18:16,  2.02s/it, lr=4.3e-7, step_loss=0.0467] Steps:  96%|█████████▌| 12458/13000 [23:35<20:10,  2.23s/it, lr=4.3e-7, step_loss=0.0467]Steps:  96%|█████████▌| 12458/13000 [23:35<20:10,  2.23s/it, lr=4.28e-7, step_loss=0.034]Steps:  96%|█████████▌| 12458/13000 [23:35<20:10,  2.23s/it, lr=4.28e-7, step_loss=0.0548]Steps:  96%|█████████▌| 12459/13000 [23:36<15:59,  1.77s/it, lr=4.28e-7, step_loss=0.0548]Steps:  96%|█████████▌| 12459/13000 [23:36<15:59,  1.77s/it, lr=4.27e-7, step_loss=0.0195]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.51it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.97it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.20it/s]
02/23/2025 16:07:02 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12459/13000 [23:50<15:59,  1.77s/it, lr=4.27e-7, step_loss=0.0218]Steps:  96%|█████████▌| 12459/13000 [23:50<15:59,  1.77s/it, lr=4.27e-7, step_loss=0.103] Steps:  96%|█████████▌| 12459/13000 [23:51<15:59,  1.77s/it, lr=4.27e-7, step_loss=0.00347]Steps:  96%|█████████▌| 12460/13000 [23:51<53:15,  5.92s/it, lr=4.27e-7, step_loss=0.00347]Steps:  96%|█████████▌| 12460/13000 [23:51<53:15,  5.92s/it, lr=4.25e-7, step_loss=0.088]  Steps:  96%|█████████▌| 12460/13000 [23:52<53:15,  5.92s/it, lr=4.25e-7, step_loss=0.0871]Steps:  96%|█████████▌| 12460/13000 [23:52<53:15,  5.92s/it, lr=4.25e-7, step_loss=0.00531]Steps:  96%|█████████▌| 12460/13000 [23:52<53:15,  5.92s/it, lr=4.25e-7, step_loss=0.0249] Steps:  96%|█████████▌| 12461/13000 [23:53<41:06,  4.58s/it, lr=4.25e-7, step_loss=0.0249]Steps:  96%|█████████▌| 12461/13000 [23:53<41:06,  4.58s/it, lr=4.24e-7, step_loss=0.0154]Steps:  96%|█████████▌| 12461/13000 [23:53<41:06,  4.58s/it, lr=4.24e-7, step_loss=0.0914]Steps:  96%|█████████▌| 12461/13000 [23:53<41:06,  4.58s/it, lr=4.24e-7, step_loss=0.109] Steps:  96%|█████████▌| 12461/13000 [23:54<41:06,  4.58s/it, lr=4.24e-7, step_loss=0.0211]Steps:  96%|█████████▌| 12462/13000 [23:54<32:36,  3.64s/it, lr=4.24e-7, step_loss=0.0211]Steps:  96%|█████████▌| 12462/13000 [23:54<32:36,  3.64s/it, lr=4.22e-7, step_loss=0.00644]Steps:  96%|█████████▌| 12462/13000 [23:54<32:36,  3.64s/it, lr=4.22e-7, step_loss=0.0627] Steps:  96%|█████████▌| 12462/13000 [23:55<32:36,  3.64s/it, lr=4.22e-7, step_loss=0.17]  Steps:  96%|█████████▌| 12462/13000 [23:55<32:36,  3.64s/it, lr=4.22e-7, step_loss=0.463]Steps:  96%|█████████▌| 12463/13000 [23:56<26:43,  2.99s/it, lr=4.22e-7, step_loss=0.463]Steps:  96%|█████████▌| 12463/13000 [23:56<26:43,  2.99s/it, lr=4.2e-7, step_loss=0.0134]Steps:  96%|█████████▌| 12463/13000 [23:56<26:43,  2.99s/it, lr=4.2e-7, step_loss=0.0217]Steps:  96%|█████████▌| 12463/13000 [23:56<26:43,  2.99s/it, lr=4.2e-7, step_loss=0.0112]Steps:  96%|█████████▌| 12463/13000 [23:57<26:43,  2.99s/it, lr=4.2e-7, step_loss=0.00587]Steps:  96%|█████████▌| 12464/13000 [23:57<22:30,  2.52s/it, lr=4.2e-7, step_loss=0.00587]Steps:  96%|█████████▌| 12464/13000 [23:57<22:30,  2.52s/it, lr=4.19e-7, step_loss=0.0248]Steps:  96%|█████████▌| 12464/13000 [23:57<22:30,  2.52s/it, lr=4.19e-7, step_loss=0.019] Steps:  96%|█████████▌| 12464/13000 [23:58<22:30,  2.52s/it, lr=4.19e-7, step_loss=0.0911]Steps:  96%|█████████▌| 12464/13000 [23:58<22:30,  2.52s/it, lr=4.19e-7, step_loss=0.248] Steps:  96%|█████████▌| 12465/13000 [23:58<19:34,  2.19s/it, lr=4.19e-7, step_loss=0.248]Steps:  96%|█████████▌| 12465/13000 [23:58<19:34,  2.19s/it, lr=4.17e-7, step_loss=0.1]  Steps:  96%|█████████▌| 12465/13000 [23:59<19:34,  2.19s/it, lr=4.17e-7, step_loss=0.0142]Steps:  96%|█████████▌| 12465/13000 [23:59<19:34,  2.19s/it, lr=4.17e-7, step_loss=0.0161]Steps:  96%|█████████▌| 12465/13000 [24:00<19:34,  2.19s/it, lr=4.17e-7, step_loss=0.026] Steps:  96%|█████████▌| 12466/13000 [24:00<17:27,  1.96s/it, lr=4.17e-7, step_loss=0.026]Steps:  96%|█████████▌| 12466/13000 [24:00<17:27,  1.96s/it, lr=4.16e-7, step_loss=0.0473]Steps:  96%|█████████▌| 12466/13000 [24:00<17:27,  1.96s/it, lr=4.16e-7, step_loss=0.0783]Steps:  96%|█████████▌| 12466/13000 [24:01<17:27,  1.96s/it, lr=4.16e-7, step_loss=0.142] Steps:  96%|█████████▌| 12466/13000 [24:01<17:27,  1.96s/it, lr=4.16e-7, step_loss=0.251]Steps:  96%|█████████▌| 12467/13000 [24:01<16:08,  1.82s/it, lr=4.16e-7, step_loss=0.251]Steps:  96%|█████████▌| 12467/13000 [24:01<16:08,  1.82s/it, lr=4.14e-7, step_loss=0.00996]Steps:  96%|█████████▌| 12467/13000 [24:02<16:08,  1.82s/it, lr=4.14e-7, step_loss=0.139]  Steps:  96%|█████████▌| 12468/13000 [24:02<13:08,  1.48s/it, lr=4.14e-7, step_loss=0.139]Steps:  96%|█████████▌| 12468/13000 [24:02<13:08,  1.48s/it, lr=4.13e-7, step_loss=0.635]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.24it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.87it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.14it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.71it/s]
02/23/2025 16:07:28 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12468/13000 [24:17<13:08,  1.48s/it, lr=4.13e-7, step_loss=0.0795]Steps:  96%|█████████▌| 12468/13000 [24:18<13:08,  1.48s/it, lr=4.13e-7, step_loss=0.242] Steps:  96%|█████████▌| 12468/13000 [24:18<13:08,  1.48s/it, lr=4.13e-7, step_loss=0.0209]Steps:  96%|█████████▌| 12469/13000 [24:18<53:00,  5.99s/it, lr=4.13e-7, step_loss=0.0209]Steps:  96%|█████████▌| 12469/13000 [24:19<53:00,  5.99s/it, lr=4.11e-7, step_loss=0.131] Steps:  96%|█████████▌| 12469/13000 [24:19<53:00,  5.99s/it, lr=4.11e-7, step_loss=0.226]Steps:  96%|█████████▌| 12469/13000 [24:19<53:00,  5.99s/it, lr=4.11e-7, step_loss=0.00296]Steps:  96%|█████████▌| 12469/13000 [24:20<53:00,  5.99s/it, lr=4.11e-7, step_loss=0.0523] Steps:  96%|█████████▌| 12470/13000 [24:20<40:51,  4.63s/it, lr=4.11e-7, step_loss=0.0523]Steps:  96%|█████████▌| 12470/13000 [24:20<40:51,  4.63s/it, lr=4.1e-7, step_loss=0.0156] Steps:  96%|█████████▌| 12470/13000 [24:20<40:51,  4.63s/it, lr=4.1e-7, step_loss=0.0162]Steps:  96%|█████████▌| 12470/13000 [24:21<40:51,  4.63s/it, lr=4.1e-7, step_loss=0.185] Steps:  96%|█████████▌| 12470/13000 [24:21<40:51,  4.63s/it, lr=4.1e-7, step_loss=0.119]Steps:  96%|█████████▌| 12471/13000 [24:21<32:19,  3.67s/it, lr=4.1e-7, step_loss=0.119]Steps:  96%|█████████▌| 12471/13000 [24:21<32:19,  3.67s/it, lr=4.08e-7, step_loss=0.237]Steps:  96%|█████████▌| 12471/13000 [24:22<32:19,  3.67s/it, lr=4.08e-7, step_loss=0.027]Steps:  96%|█████████▌| 12471/13000 [24:22<32:19,  3.67s/it, lr=4.08e-7, step_loss=0.0845]Steps:  96%|█████████▌| 12471/13000 [24:23<32:19,  3.67s/it, lr=4.08e-7, step_loss=0.00389]Steps:  96%|█████████▌| 12472/13000 [24:23<26:25,  3.00s/it, lr=4.08e-7, step_loss=0.00389]Steps:  96%|█████████▌| 12472/13000 [24:23<26:25,  3.00s/it, lr=4.06e-7, step_loss=0.105]  Steps:  96%|█████████▌| 12472/13000 [24:23<26:25,  3.00s/it, lr=4.06e-7, step_loss=0.037]Steps:  96%|█████████▌| 12472/13000 [24:24<26:25,  3.00s/it, lr=4.06e-7, step_loss=0.0111]Steps:  96%|█████████▌| 12472/13000 [24:24<26:25,  3.00s/it, lr=4.06e-7, step_loss=0.154] Steps:  96%|█████████▌| 12473/13000 [24:29<34:29,  3.93s/it, lr=4.06e-7, step_loss=0.154]Steps:  96%|█████████▌| 12473/13000 [24:29<34:29,  3.93s/it, lr=4.05e-7, step_loss=0.386]Steps:  96%|█████████▌| 12473/13000 [24:29<34:29,  3.93s/it, lr=4.05e-7, step_loss=0.167]Steps:  96%|█████████▌| 12473/13000 [24:30<34:29,  3.93s/it, lr=4.05e-7, step_loss=0.0142]Steps:  96%|█████████▌| 12473/13000 [24:30<34:29,  3.93s/it, lr=4.05e-7, step_loss=0.00343]Steps:  96%|█████████▌| 12474/13000 [24:30<28:01,  3.20s/it, lr=4.05e-7, step_loss=0.00343]Steps:  96%|█████████▌| 12474/13000 [24:31<28:01,  3.20s/it, lr=4.03e-7, step_loss=0.0321] Steps:  96%|█████████▌| 12474/13000 [24:31<28:01,  3.20s/it, lr=4.03e-7, step_loss=0.0225]Steps:  96%|█████████▌| 12474/13000 [24:32<28:01,  3.20s/it, lr=4.03e-7, step_loss=0.373] Steps:  96%|█████████▌| 12474/13000 [24:32<28:01,  3.20s/it, lr=4.03e-7, step_loss=0.071]Steps:  96%|█████████▌| 12475/13000 [24:32<25:00,  2.86s/it, lr=4.03e-7, step_loss=0.071]Steps:  96%|█████████▌| 12475/13000 [24:33<25:00,  2.86s/it, lr=4.02e-7, step_loss=0.0782]Steps:  96%|█████████▌| 12475/13000 [24:33<25:00,  2.86s/it, lr=4.02e-7, step_loss=0.0254]Steps:  96%|█████████▌| 12475/13000 [24:33<25:00,  2.86s/it, lr=4.02e-7, step_loss=0.0465]Steps:  96%|█████████▌| 12475/13000 [24:34<25:00,  2.86s/it, lr=4.02e-7, step_loss=0.0771]Steps:  96%|█████████▌| 12476/13000 [24:34<21:13,  2.43s/it, lr=4.02e-7, step_loss=0.0771]Steps:  96%|█████████▌| 12476/13000 [24:34<21:13,  2.43s/it, lr=4e-7, step_loss=0.00326]  Steps:  96%|█████████▌| 12476/13000 [24:34<21:13,  2.43s/it, lr=4e-7, step_loss=0.0142] Steps:  96%|█████████▌| 12477/13000 [24:35<16:41,  1.91s/it, lr=4e-7, step_loss=0.0142]Steps:  96%|█████████▌| 12477/13000 [24:35<16:41,  1.91s/it, lr=3.99e-7, step_loss=0.0443]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.27it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.33it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.77it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.34it/s]
02/23/2025 16:08:01 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12477/13000 [24:50<16:41,  1.91s/it, lr=3.99e-7, step_loss=0.149] Steps:  96%|█████████▌| 12477/13000 [24:50<16:41,  1.91s/it, lr=3.99e-7, step_loss=0.00449]Steps:  96%|█████████▌| 12477/13000 [24:50<16:41,  1.91s/it, lr=3.99e-7, step_loss=0.178]  Steps:  96%|█████████▌| 12478/13000 [24:51<53:53,  6.19s/it, lr=3.99e-7, step_loss=0.178]Steps:  96%|█████████▌| 12478/13000 [24:51<53:53,  6.19s/it, lr=3.97e-7, step_loss=0.107]Steps:  96%|█████████▌| 12478/13000 [24:51<53:53,  6.19s/it, lr=3.97e-7, step_loss=0.232]Steps:  96%|█████████▌| 12478/13000 [24:54<53:53,  6.19s/it, lr=3.97e-7, step_loss=0.0855]Steps:  96%|█████████▌| 12478/13000 [24:54<53:53,  6.19s/it, lr=3.97e-7, step_loss=0.475] Steps:  96%|█████████▌| 12479/13000 [24:55<47:22,  5.45s/it, lr=3.97e-7, step_loss=0.475]Steps:  96%|█████████▌| 12479/13000 [24:55<47:22,  5.45s/it, lr=3.96e-7, step_loss=0.325]Steps:  96%|█████████▌| 12479/13000 [24:55<47:22,  5.45s/it, lr=3.96e-7, step_loss=0.0933]Steps:  96%|█████████▌| 12479/13000 [24:55<47:22,  5.45s/it, lr=3.96e-7, step_loss=0.0622]Steps:  96%|█████████▌| 12479/13000 [24:56<47:22,  5.45s/it, lr=3.96e-7, step_loss=0.209] Steps:  96%|█████████▌| 12480/13000 [24:56<36:49,  4.25s/it, lr=3.96e-7, step_loss=0.209]Steps:  96%|█████████▌| 12480/13000 [24:56<36:49,  4.25s/it, lr=3.94e-7, step_loss=0.111]Steps:  96%|█████████▌| 12480/13000 [24:56<36:49,  4.25s/it, lr=3.94e-7, step_loss=0.0468]Steps:  96%|█████████▌| 12480/13000 [24:57<36:49,  4.25s/it, lr=3.94e-7, step_loss=0.0055]Steps:  96%|█████████▌| 12480/13000 [24:57<36:49,  4.25s/it, lr=3.94e-7, step_loss=0.0447]Steps:  96%|█████████▌| 12481/13000 [24:57<29:21,  3.39s/it, lr=3.94e-7, step_loss=0.0447]Steps:  96%|█████████▌| 12481/13000 [24:57<29:21,  3.39s/it, lr=3.93e-7, step_loss=0.00544]Steps:  96%|█████████▌| 12481/13000 [24:58<29:21,  3.39s/it, lr=3.93e-7, step_loss=0.132]  Steps:  96%|█████████▌| 12481/13000 [24:58<29:21,  3.39s/it, lr=3.93e-7, step_loss=0.0367]Steps:  96%|█████████▌| 12481/13000 [24:58<29:21,  3.39s/it, lr=3.93e-7, step_loss=0.111] Steps:  96%|█████████▌| 12482/13000 [24:59<24:15,  2.81s/it, lr=3.93e-7, step_loss=0.111]Steps:  96%|█████████▌| 12482/13000 [24:59<24:15,  2.81s/it, lr=3.91e-7, step_loss=0.0132]Steps:  96%|█████████▌| 12482/13000 [24:59<24:15,  2.81s/it, lr=3.91e-7, step_loss=0.0427]Steps:  96%|█████████▌| 12482/13000 [25:00<24:15,  2.81s/it, lr=3.91e-7, step_loss=0.059] Steps:  96%|█████████▌| 12482/13000 [25:00<24:15,  2.81s/it, lr=3.91e-7, step_loss=0.0719]Steps:  96%|█████████▌| 12483/13000 [25:00<20:44,  2.41s/it, lr=3.91e-7, step_loss=0.0719]Steps:  96%|█████████▌| 12483/13000 [25:00<20:44,  2.41s/it, lr=3.9e-7, step_loss=0.088]  Steps:  96%|█████████▌| 12483/13000 [25:01<20:44,  2.41s/it, lr=3.9e-7, step_loss=0.0768]Steps:  96%|█████████▌| 12483/13000 [25:01<20:44,  2.41s/it, lr=3.9e-7, step_loss=0.0537]Steps:  96%|█████████▌| 12483/13000 [25:01<20:44,  2.41s/it, lr=3.9e-7, step_loss=0.0469]Steps:  96%|█████████▌| 12484/13000 [25:02<18:15,  2.12s/it, lr=3.9e-7, step_loss=0.0469]Steps:  96%|█████████▌| 12484/13000 [25:04<18:15,  2.12s/it, lr=3.88e-7, step_loss=0.0744]Steps:  96%|█████████▌| 12484/13000 [25:04<18:15,  2.12s/it, lr=3.88e-7, step_loss=0.259] Steps:  96%|█████████▌| 12484/13000 [25:05<18:15,  2.12s/it, lr=3.88e-7, step_loss=0.254]Steps:  96%|█████████▌| 12484/13000 [25:05<18:15,  2.12s/it, lr=3.88e-7, step_loss=0.0143]Steps:  96%|█████████▌| 12485/13000 [25:05<22:11,  2.59s/it, lr=3.88e-7, step_loss=0.0143]Steps:  96%|█████████▌| 12485/13000 [25:05<22:11,  2.59s/it, lr=3.87e-7, step_loss=0.0456]Steps:  96%|█████████▌| 12485/13000 [25:06<22:11,  2.59s/it, lr=3.87e-7, step_loss=0.0885]Steps:  96%|█████████▌| 12486/13000 [25:06<17:19,  2.02s/it, lr=3.87e-7, step_loss=0.0885]Steps:  96%|█████████▌| 12486/13000 [25:06<17:19,  2.02s/it, lr=3.85e-7, step_loss=0.0598]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.42it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.19it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.87it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.41it/s]
02/23/2025 16:08:33 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12486/13000 [25:21<17:19,  2.02s/it, lr=3.85e-7, step_loss=0.0762]Steps:  96%|█████████▌| 12486/13000 [25:22<17:19,  2.02s/it, lr=3.85e-7, step_loss=0.013] Steps:  96%|█████████▌| 12486/13000 [25:22<17:19,  2.02s/it, lr=3.85e-7, step_loss=0.36] Steps:  96%|█████████▌| 12487/13000 [25:22<53:33,  6.26s/it, lr=3.85e-7, step_loss=0.36]Steps:  96%|█████████▌| 12487/13000 [25:23<53:33,  6.26s/it, lr=3.84e-7, step_loss=0.0361]Steps:  96%|█████████▌| 12487/13000 [25:23<53:33,  6.26s/it, lr=3.84e-7, step_loss=0.00307]Steps:  96%|█████████▌| 12487/13000 [25:24<53:33,  6.26s/it, lr=3.84e-7, step_loss=0.4]    Steps:  96%|█████████▌| 12487/13000 [25:24<53:33,  6.26s/it, lr=3.84e-7, step_loss=0.00291]Steps:  96%|█████████▌| 12488/13000 [25:24<42:47,  5.01s/it, lr=3.84e-7, step_loss=0.00291]Steps:  96%|█████████▌| 12488/13000 [25:28<42:47,  5.01s/it, lr=3.82e-7, step_loss=0.0194] Steps:  96%|█████████▌| 12488/13000 [25:28<42:47,  5.01s/it, lr=3.82e-7, step_loss=0.0107]Steps:  96%|█████████▌| 12488/13000 [25:28<42:47,  5.01s/it, lr=3.82e-7, step_loss=0.145] Steps:  96%|█████████▌| 12488/13000 [25:29<42:47,  5.01s/it, lr=3.82e-7, step_loss=0.0604]Steps:  96%|█████████▌| 12489/13000 [25:29<42:16,  4.96s/it, lr=3.82e-7, step_loss=0.0604]Steps:  96%|█████████▌| 12489/13000 [25:29<42:16,  4.96s/it, lr=3.81e-7, step_loss=0.0582]Steps:  96%|█████████▌| 12489/13000 [25:30<42:16,  4.96s/it, lr=3.81e-7, step_loss=0.192] Steps:  96%|█████████▌| 12489/13000 [25:30<42:16,  4.96s/it, lr=3.81e-7, step_loss=0.027]Steps:  96%|█████████▌| 12489/13000 [25:30<42:16,  4.96s/it, lr=3.81e-7, step_loss=0.00353]Steps:  96%|█████████▌| 12490/13000 [25:31<33:10,  3.90s/it, lr=3.81e-7, step_loss=0.00353]Steps:  96%|█████████▌| 12490/13000 [25:31<33:10,  3.90s/it, lr=3.79e-7, step_loss=0.0401] Steps:  96%|█████████▌| 12490/13000 [25:31<33:10,  3.90s/it, lr=3.79e-7, step_loss=0.175] Steps:  96%|█████████▌| 12490/13000 [25:31<33:10,  3.90s/it, lr=3.79e-7, step_loss=0.0365]Steps:  96%|█████████▌| 12490/13000 [25:32<33:10,  3.90s/it, lr=3.79e-7, step_loss=0.104] Steps:  96%|█████████▌| 12491/13000 [25:32<26:51,  3.17s/it, lr=3.79e-7, step_loss=0.104]Steps:  96%|█████████▌| 12491/13000 [25:32<26:51,  3.17s/it, lr=3.78e-7, step_loss=0.223]Steps:  96%|█████████▌| 12491/13000 [25:32<26:51,  3.17s/it, lr=3.78e-7, step_loss=0.448]Steps:  96%|█████████▌| 12491/13000 [25:33<26:51,  3.17s/it, lr=3.78e-7, step_loss=0.135]Steps:  96%|█████████▌| 12491/13000 [25:33<26:51,  3.17s/it, lr=3.78e-7, step_loss=0.201]Steps:  96%|█████████▌| 12492/13000 [25:34<22:29,  2.66s/it, lr=3.78e-7, step_loss=0.201]Steps:  96%|█████████▌| 12492/13000 [25:34<22:29,  2.66s/it, lr=3.76e-7, step_loss=0.0305]Steps:  96%|█████████▌| 12492/13000 [25:34<22:29,  2.66s/it, lr=3.76e-7, step_loss=0.0797]Steps:  96%|█████████▌| 12492/13000 [25:34<22:29,  2.66s/it, lr=3.76e-7, step_loss=0.265] Steps:  96%|█████████▌| 12492/13000 [25:35<22:29,  2.66s/it, lr=3.76e-7, step_loss=0.045]Steps:  96%|█████████▌| 12493/13000 [25:35<19:29,  2.31s/it, lr=3.76e-7, step_loss=0.045]Steps:  96%|█████████▌| 12493/13000 [25:35<19:29,  2.31s/it, lr=3.75e-7, step_loss=0.302]Steps:  96%|█████████▌| 12493/13000 [25:35<19:29,  2.31s/it, lr=3.75e-7, step_loss=0.0137]Steps:  96%|█████████▌| 12493/13000 [25:36<19:29,  2.31s/it, lr=3.75e-7, step_loss=0.0474]Steps:  96%|█████████▌| 12493/13000 [25:36<19:29,  2.31s/it, lr=3.75e-7, step_loss=0.181] Steps:  96%|█████████▌| 12494/13000 [25:36<17:17,  2.05s/it, lr=3.75e-7, step_loss=0.181]Steps:  96%|█████████▌| 12494/13000 [25:37<17:17,  2.05s/it, lr=3.73e-7, step_loss=0.244]Steps:  96%|█████████▌| 12494/13000 [25:37<17:17,  2.05s/it, lr=3.73e-7, step_loss=0.00764]Steps:  96%|█████████▌| 12495/13000 [25:37<13:51,  1.65s/it, lr=3.73e-7, step_loss=0.00764]Steps:  96%|█████████▌| 12495/13000 [25:37<13:51,  1.65s/it, lr=3.72e-7, step_loss=0.00892]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.20it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:01<00:00,  2.53it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.22it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.25it/s]
02/23/2025 16:09:05 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12495/13000 [25:53<13:51,  1.65s/it, lr=3.72e-7, step_loss=0.0354] Steps:  96%|█████████▌| 12495/13000 [25:54<13:51,  1.65s/it, lr=3.72e-7, step_loss=0.0717]Steps:  96%|█████████▌| 12495/13000 [25:54<13:51,  1.65s/it, lr=3.72e-7, step_loss=0.007] Steps:  96%|█████████▌| 12496/13000 [25:54<53:04,  6.32s/it, lr=3.72e-7, step_loss=0.007]Steps:  96%|█████████▌| 12496/13000 [25:54<53:04,  6.32s/it, lr=3.7e-7, step_loss=0.0251]Steps:  96%|█████████▌| 12496/13000 [25:55<53:04,  6.32s/it, lr=3.7e-7, step_loss=0.041] Steps:  96%|█████████▌| 12496/13000 [25:55<53:04,  6.32s/it, lr=3.7e-7, step_loss=0.00327]Steps:  96%|█████████▌| 12496/13000 [25:56<53:04,  6.32s/it, lr=3.7e-7, step_loss=0.296]  Steps:  96%|█████████▌| 12497/13000 [25:56<41:00,  4.89s/it, lr=3.7e-7, step_loss=0.296]Steps:  96%|█████████▌| 12497/13000 [25:56<41:00,  4.89s/it, lr=3.69e-7, step_loss=0.00758]Steps:  96%|█████████▌| 12497/13000 [25:56<41:00,  4.89s/it, lr=3.69e-7, step_loss=0.0131] Steps:  96%|█████████▌| 12497/13000 [25:57<41:00,  4.89s/it, lr=3.69e-7, step_loss=0.0235]Steps:  96%|█████████▌| 12497/13000 [25:57<41:00,  4.89s/it, lr=3.69e-7, step_loss=0.0357]Steps:  96%|█████████▌| 12498/13000 [25:57<32:17,  3.86s/it, lr=3.69e-7, step_loss=0.0357]Steps:  96%|█████████▌| 12498/13000 [25:57<32:17,  3.86s/it, lr=3.67e-7, step_loss=0.569] Steps:  96%|█████████▌| 12498/13000 [25:58<32:17,  3.86s/it, lr=3.67e-7, step_loss=0.372]Steps:  96%|█████████▌| 12498/13000 [25:58<32:17,  3.86s/it, lr=3.67e-7, step_loss=0.00677]Steps:  96%|█████████▌| 12498/13000 [25:59<32:17,  3.86s/it, lr=3.67e-7, step_loss=0.00286]Steps:  96%|█████████▌| 12499/13000 [25:59<26:14,  3.14s/it, lr=3.67e-7, step_loss=0.00286]Steps:  96%|█████████▌| 12499/13000 [25:59<26:14,  3.14s/it, lr=3.66e-7, step_loss=0.0235] Steps:  96%|█████████▌| 12499/13000 [25:59<26:14,  3.14s/it, lr=3.66e-7, step_loss=0.403] Steps:  96%|█████████▌| 12499/13000 [26:00<26:14,  3.14s/it, lr=3.66e-7, step_loss=0.266]Steps:  96%|█████████▌| 12499/13000 [26:00<26:14,  3.14s/it, lr=3.66e-7, step_loss=0.123]Steps:  96%|█████████▌| 12500/13000 [26:00<22:06,  2.65s/it, lr=3.66e-7, step_loss=0.123]02/23/2025 16:09:26 - INFO - accelerate.accelerator - Saving current state to train/checkpoint-12500
02/23/2025 16:09:36 - INFO - accelerate.checkpointing - Model weights saved in train/checkpoint-12500/model.safetensors
02/23/2025 16:09:36 - INFO - accelerate.checkpointing - Optimizer state saved in train/checkpoint-12500/optimizer.bin
02/23/2025 16:09:36 - INFO - accelerate.checkpointing - Scheduler state saved in train/checkpoint-12500/scheduler.bin
02/23/2025 16:09:36 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in train/checkpoint-12500/sampler.bin
02/23/2025 16:09:36 - INFO - accelerate.checkpointing - Random states saved in train/checkpoint-12500/random_states_0.pkl
Model weights saved in train/checkpoint-12500/pytorch_lora_weights.safetensors
02/23/2025 16:09:36 - INFO - __main__ - Saved state to train/checkpoint-12500
Steps:  96%|█████████▌| 12500/13000 [26:10<22:06,  2.65s/it, lr=3.65e-7, step_loss=0.395]Steps:  96%|█████████▌| 12500/13000 [26:11<22:06,  2.65s/it, lr=3.65e-7, step_loss=0.0486]Steps:  96%|█████████▌| 12500/13000 [26:11<22:06,  2.65s/it, lr=3.65e-7, step_loss=0.0212]Steps:  96%|█████████▌| 12500/13000 [26:12<22:06,  2.65s/it, lr=3.65e-7, step_loss=0.174] Steps:  96%|█████████▌| 12501/13000 [26:12<43:57,  5.29s/it, lr=3.65e-7, step_loss=0.174]Steps:  96%|█████████▌| 12501/13000 [26:12<43:57,  5.29s/it, lr=3.63e-7, step_loss=0.00991]Steps:  96%|█████████▌| 12501/13000 [26:12<43:57,  5.29s/it, lr=3.63e-7, step_loss=0.105]  Steps:  96%|█████████▌| 12501/13000 [26:13<43:57,  5.29s/it, lr=3.63e-7, step_loss=0.21] Steps:  96%|█████████▌| 12501/13000 [26:13<43:57,  5.29s/it, lr=3.63e-7, step_loss=0.104]Steps:  96%|█████████▌| 12502/13000 [26:13<34:15,  4.13s/it, lr=3.63e-7, step_loss=0.104]Steps:  96%|█████████▌| 12502/13000 [26:13<34:15,  4.13s/it, lr=3.62e-7, step_loss=0.022]Steps:  96%|█████████▌| 12502/13000 [26:14<34:15,  4.13s/it, lr=3.62e-7, step_loss=0.00794]Steps:  96%|█████████▌| 12502/13000 [26:14<34:15,  4.13s/it, lr=3.62e-7, step_loss=0.233]  Steps:  96%|█████████▌| 12502/13000 [26:14<34:15,  4.13s/it, lr=3.62e-7, step_loss=0.021]Steps:  96%|█████████▌| 12503/13000 [26:15<27:38,  3.34s/it, lr=3.62e-7, step_loss=0.021]Steps:  96%|█████████▌| 12503/13000 [26:15<27:38,  3.34s/it, lr=3.6e-7, step_loss=0.13]  Steps:  96%|█████████▌| 12503/13000 [26:15<27:38,  3.34s/it, lr=3.6e-7, step_loss=0.0656]Steps:  96%|█████████▌| 12504/13000 [26:15<20:59,  2.54s/it, lr=3.6e-7, step_loss=0.0656]Steps:  96%|█████████▌| 12504/13000 [26:15<20:59,  2.54s/it, lr=3.59e-7, step_loss=0.098]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  14%|█▍        | 1/7 [00:02<00:16,  2.81s/it][ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:02<00:06,  1.23s/it][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:04<00:01,  1.22it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:05<00:00,  1.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]
02/23/2025 16:09:46 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▌| 12504/13000 [26:35<20:59,  2.54s/it, lr=3.59e-7, step_loss=0.0127]Steps:  96%|█████████▌| 12504/13000 [26:35<20:59,  2.54s/it, lr=3.59e-7, step_loss=0.0126]Steps:  96%|█████████▌| 12504/13000 [26:35<20:59,  2.54s/it, lr=3.59e-7, step_loss=0.0363]Steps:  96%|█████████▌| 12505/13000 [26:36<1:04:32,  7.82s/it, lr=3.59e-7, step_loss=0.0363]Steps:  96%|█████████▌| 12505/13000 [26:36<1:04:32,  7.82s/it, lr=3.57e-7, step_loss=0.0933]Steps:  96%|█████████▌| 12505/13000 [26:36<1:04:32,  7.82s/it, lr=3.57e-7, step_loss=0.299] Steps:  96%|█████████▌| 12505/13000 [26:36<1:04:32,  7.82s/it, lr=3.57e-7, step_loss=0.128]Steps:  96%|█████████▌| 12505/13000 [26:37<1:04:32,  7.82s/it, lr=3.57e-7, step_loss=0.0721]Steps:  96%|█████████▌| 12506/13000 [26:37<48:43,  5.92s/it, lr=3.57e-7, step_loss=0.0721]  Steps:  96%|█████████▌| 12506/13000 [26:37<48:43,  5.92s/it, lr=3.56e-7, step_loss=0.0561]Steps:  96%|█████████▌| 12506/13000 [26:37<48:43,  5.92s/it, lr=3.56e-7, step_loss=0.203] Steps:  96%|█████████▌| 12506/13000 [26:38<48:43,  5.92s/it, lr=3.56e-7, step_loss=0.24] Steps:  96%|█████████▌| 12506/13000 [26:38<48:43,  5.92s/it, lr=3.56e-7, step_loss=0.0277]Steps:  96%|█████████▌| 12507/13000 [26:38<37:36,  4.58s/it, lr=3.56e-7, step_loss=0.0277]Steps:  96%|█████████▌| 12507/13000 [26:39<37:36,  4.58s/it, lr=3.54e-7, step_loss=0.484] Steps:  96%|█████████▌| 12507/13000 [26:39<37:36,  4.58s/it, lr=3.54e-7, step_loss=0.013]Steps:  96%|█████████▌| 12507/13000 [26:39<37:36,  4.58s/it, lr=3.54e-7, step_loss=0.15] Steps:  96%|█████████▌| 12507/13000 [26:40<37:36,  4.58s/it, lr=3.54e-7, step_loss=0.197]Steps:  96%|█████████▌| 12508/13000 [26:40<29:52,  3.64s/it, lr=3.54e-7, step_loss=0.197]Steps:  96%|█████████▌| 12508/13000 [26:40<29:52,  3.64s/it, lr=3.53e-7, step_loss=0.00634]Steps:  96%|█████████▌| 12508/13000 [26:40<29:52,  3.64s/it, lr=3.53e-7, step_loss=0.00997]Steps:  96%|█████████▌| 12508/13000 [26:41<29:52,  3.64s/it, lr=3.53e-7, step_loss=0.0589] Steps:  96%|█████████▌| 12508/13000 [26:41<29:52,  3.64s/it, lr=3.53e-7, step_loss=0.102] Steps:  96%|█████████▌| 12509/13000 [26:41<24:26,  2.99s/it, lr=3.53e-7, step_loss=0.102]Steps:  96%|█████████▌| 12509/13000 [26:43<24:26,  2.99s/it, lr=3.52e-7, step_loss=0.00617]Steps:  96%|█████████▌| 12509/13000 [26:43<24:26,  2.99s/it, lr=3.52e-7, step_loss=0.157]  Steps:  96%|█████████▌| 12509/13000 [26:44<24:26,  2.99s/it, lr=3.52e-7, step_loss=0.154]Steps:  96%|█████████▌| 12509/13000 [26:44<24:26,  2.99s/it, lr=3.52e-7, step_loss=0.0947]Steps:  96%|█████████▌| 12510/13000 [26:44<24:32,  3.01s/it, lr=3.52e-7, step_loss=0.0947]Steps:  96%|█████████▌| 12510/13000 [26:45<24:32,  3.01s/it, lr=3.5e-7, step_loss=0.0858] Steps:  96%|█████████▌| 12510/13000 [26:45<24:32,  3.01s/it, lr=3.5e-7, step_loss=0.0148]Steps:  96%|█████████▌| 12510/13000 [26:45<24:32,  3.01s/it, lr=3.5e-7, step_loss=0.0378]Steps:  96%|█████████▌| 12510/13000 [26:46<24:32,  3.01s/it, lr=3.5e-7, step_loss=0.0511]Steps:  96%|█████████▌| 12511/13000 [26:46<20:51,  2.56s/it, lr=3.5e-7, step_loss=0.0511]Steps:  96%|█████████▌| 12511/13000 [26:46<20:51,  2.56s/it, lr=3.49e-7, step_loss=0.0433]Steps:  96%|█████████▌| 12511/13000 [26:46<20:51,  2.56s/it, lr=3.49e-7, step_loss=0.0995]Steps:  96%|█████████▌| 12511/13000 [26:47<20:51,  2.56s/it, lr=3.49e-7, step_loss=0.0758]Steps:  96%|█████████▌| 12511/13000 [26:47<20:51,  2.56s/it, lr=3.49e-7, step_loss=0.0252]Steps:  96%|█████████▌| 12512/13000 [26:47<18:08,  2.23s/it, lr=3.49e-7, step_loss=0.0252]Steps:  96%|█████████▌| 12512/13000 [26:47<18:08,  2.23s/it, lr=3.47e-7, step_loss=0.2]   Steps:  96%|█████████▌| 12512/13000 [26:48<18:08,  2.23s/it, lr=3.47e-7, step_loss=0.103]Steps:  96%|█████████▋| 12513/13000 [26:48<14:19,  1.77s/it, lr=3.47e-7, step_loss=0.103]Steps:  96%|█████████▋| 12513/13000 [26:48<14:19,  1.77s/it, lr=3.46e-7, step_loss=0.0396]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.41it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 12.17it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.50it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 10.06it/s]
02/23/2025 16:10:15 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▋| 12513/13000 [27:03<14:19,  1.77s/it, lr=3.46e-7, step_loss=0.0308]Steps:  96%|█████████▋| 12513/13000 [27:03<14:19,  1.77s/it, lr=3.46e-7, step_loss=0.123] Steps:  96%|█████████▋| 12513/13000 [27:04<14:19,  1.77s/it, lr=3.46e-7, step_loss=0.0204]Steps:  96%|█████████▋| 12514/13000 [27:04<48:25,  5.98s/it, lr=3.46e-7, step_loss=0.0204]Steps:  96%|█████████▋| 12514/13000 [27:04<48:25,  5.98s/it, lr=3.44e-7, step_loss=0.00473]Steps:  96%|█████████▋| 12514/13000 [27:04<48:25,  5.98s/it, lr=3.44e-7, step_loss=0.0638] Steps:  96%|█████████▋| 12514/13000 [27:05<48:25,  5.98s/it, lr=3.44e-7, step_loss=0.222] Steps:  96%|█████████▋| 12514/13000 [27:05<48:25,  5.98s/it, lr=3.44e-7, step_loss=0.0146]Steps:  96%|█████████▋| 12515/13000 [27:05<37:15,  4.61s/it, lr=3.44e-7, step_loss=0.0146]Steps:  96%|█████████▋| 12515/13000 [27:07<37:15,  4.61s/it, lr=3.43e-7, step_loss=0.31]  Steps:  96%|█████████▋| 12515/13000 [27:07<37:15,  4.61s/it, lr=3.43e-7, step_loss=0.114]Steps:  96%|█████████▋| 12515/13000 [27:08<37:15,  4.61s/it, lr=3.43e-7, step_loss=0.0463]Steps:  96%|█████████▋| 12515/13000 [27:08<37:15,  4.61s/it, lr=3.43e-7, step_loss=0.146] Steps:  96%|█████████▋| 12516/13000 [27:08<33:24,  4.14s/it, lr=3.43e-7, step_loss=0.146]Steps:  96%|█████████▋| 12516/13000 [27:08<33:24,  4.14s/it, lr=3.42e-7, step_loss=0.184]Steps:  96%|█████████▋| 12516/13000 [27:09<33:24,  4.14s/it, lr=3.42e-7, step_loss=0.127]Steps:  96%|█████████▋| 12516/13000 [27:09<33:24,  4.14s/it, lr=3.42e-7, step_loss=0.508]Steps:  96%|█████████▋| 12516/13000 [27:10<33:24,  4.14s/it, lr=3.42e-7, step_loss=0.0182]Steps:  96%|█████████▋| 12517/13000 [27:10<26:57,  3.35s/it, lr=3.42e-7, step_loss=0.0182]Steps:  96%|█████████▋| 12517/13000 [27:10<26:57,  3.35s/it, lr=3.4e-7, step_loss=0.101]  Steps:  96%|█████████▋| 12517/13000 [27:10<26:57,  3.35s/it, lr=3.4e-7, step_loss=0.0168]Steps:  96%|█████████▋| 12517/13000 [27:11<26:57,  3.35s/it, lr=3.4e-7, step_loss=0.285] Steps:  96%|█████████▋| 12517/13000 [27:11<26:57,  3.35s/it, lr=3.4e-7, step_loss=0.0242]Steps:  96%|█████████▋| 12518/13000 [27:11<22:26,  2.79s/it, lr=3.4e-7, step_loss=0.0242]Steps:  96%|█████████▋| 12518/13000 [27:11<22:26,  2.79s/it, lr=3.39e-7, step_loss=0.0481]Steps:  96%|█████████▋| 12518/13000 [27:12<22:26,  2.79s/it, lr=3.39e-7, step_loss=0.0449]Steps:  96%|█████████▋| 12518/13000 [27:12<22:26,  2.79s/it, lr=3.39e-7, step_loss=0.0607]Steps:  96%|█████████▋| 12518/13000 [27:13<22:26,  2.79s/it, lr=3.39e-7, step_loss=0.0168]Steps:  96%|█████████▋| 12519/13000 [27:13<19:06,  2.38s/it, lr=3.39e-7, step_loss=0.0168]Steps:  96%|█████████▋| 12519/13000 [27:16<19:06,  2.38s/it, lr=3.37e-7, step_loss=0.0131]Steps:  96%|█████████▋| 12519/13000 [27:16<19:06,  2.38s/it, lr=3.37e-7, step_loss=0.0392]Steps:  96%|█████████▋| 12519/13000 [27:17<19:06,  2.38s/it, lr=3.37e-7, step_loss=0.116] Steps:  96%|█████████▋| 12519/13000 [27:17<19:06,  2.38s/it, lr=3.37e-7, step_loss=0.0145]Steps:  96%|█████████▋| 12520/13000 [27:17<24:19,  3.04s/it, lr=3.37e-7, step_loss=0.0145]Steps:  96%|█████████▋| 12520/13000 [27:17<24:19,  3.04s/it, lr=3.36e-7, step_loss=0.0299]Steps:  96%|█████████▋| 12520/13000 [27:18<24:19,  3.04s/it, lr=3.36e-7, step_loss=0.0885]Steps:  96%|█████████▋| 12520/13000 [27:18<24:19,  3.04s/it, lr=3.36e-7, step_loss=0.113] Steps:  96%|█████████▋| 12520/13000 [27:19<24:19,  3.04s/it, lr=3.36e-7, step_loss=0.565]Steps:  96%|█████████▋| 12521/13000 [27:19<20:29,  2.57s/it, lr=3.36e-7, step_loss=0.565]Steps:  96%|█████████▋| 12521/13000 [27:19<20:29,  2.57s/it, lr=3.35e-7, step_loss=0.0236]Steps:  96%|█████████▋| 12521/13000 [27:19<20:29,  2.57s/it, lr=3.35e-7, step_loss=0.491] Steps:  96%|█████████▋| 12522/13000 [27:20<15:57,  2.00s/it, lr=3.35e-7, step_loss=0.491]Steps:  96%|█████████▋| 12522/13000 [27:20<15:57,  2.00s/it, lr=3.33e-7, step_loss=0.0234]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.94it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.18it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.68it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.28it/s]
02/23/2025 16:10:46 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▋| 12522/13000 [27:34<15:57,  2.00s/it, lr=3.33e-7, step_loss=0.0683]Steps:  96%|█████████▋| 12522/13000 [27:35<15:57,  2.00s/it, lr=3.33e-7, step_loss=0.04]  Steps:  96%|█████████▋| 12522/13000 [27:35<15:57,  2.00s/it, lr=3.33e-7, step_loss=0.094]Steps:  96%|█████████▋| 12523/13000 [27:36<49:24,  6.22s/it, lr=3.33e-7, step_loss=0.094]Steps:  96%|█████████▋| 12523/13000 [27:36<49:24,  6.22s/it, lr=3.32e-7, step_loss=0.0219]Steps:  96%|█████████▋| 12523/13000 [27:36<49:24,  6.22s/it, lr=3.32e-7, step_loss=0.0151]Steps:  96%|█████████▋| 12523/13000 [27:36<49:24,  6.22s/it, lr=3.32e-7, step_loss=0.0539]Steps:  96%|█████████▋| 12523/13000 [27:37<49:24,  6.22s/it, lr=3.32e-7, step_loss=0.414] Steps:  96%|█████████▋| 12524/13000 [27:37<37:55,  4.78s/it, lr=3.32e-7, step_loss=0.414]Steps:  96%|█████████▋| 12524/13000 [27:37<37:55,  4.78s/it, lr=3.3e-7, step_loss=0.0561]Steps:  96%|█████████▋| 12524/13000 [27:37<37:55,  4.78s/it, lr=3.3e-7, step_loss=0.0377]Steps:  96%|█████████▋| 12524/13000 [27:38<37:55,  4.78s/it, lr=3.3e-7, step_loss=0.0533]Steps:  96%|█████████▋| 12524/13000 [27:38<37:55,  4.78s/it, lr=3.3e-7, step_loss=0.0385]Steps:  96%|█████████▋| 12525/13000 [27:38<29:51,  3.77s/it, lr=3.3e-7, step_loss=0.0385]Steps:  96%|█████████▋| 12525/13000 [27:38<29:51,  3.77s/it, lr=3.29e-7, step_loss=0.00505]Steps:  96%|█████████▋| 12525/13000 [27:39<29:51,  3.77s/it, lr=3.29e-7, step_loss=0.0377] Steps:  96%|█████████▋| 12525/13000 [27:39<29:51,  3.77s/it, lr=3.29e-7, step_loss=0.119] Steps:  96%|█████████▋| 12525/13000 [27:40<29:51,  3.77s/it, lr=3.29e-7, step_loss=0.00418]Steps:  96%|█████████▋| 12526/13000 [27:40<24:21,  3.08s/it, lr=3.29e-7, step_loss=0.00418]Steps:  96%|█████████▋| 12526/13000 [27:40<24:21,  3.08s/it, lr=3.28e-7, step_loss=0.00351]Steps:  96%|█████████▋| 12526/13000 [27:40<24:21,  3.08s/it, lr=3.28e-7, step_loss=0.0407] Steps:  96%|█████████▋| 12526/13000 [27:41<24:21,  3.08s/it, lr=3.28e-7, step_loss=0.146] Steps:  96%|█████████▋| 12526/13000 [27:41<24:21,  3.08s/it, lr=3.28e-7, step_loss=0.109]Steps:  96%|█████████▋| 12527/13000 [27:41<20:27,  2.59s/it, lr=3.28e-7, step_loss=0.109]Steps:  96%|█████████▋| 12527/13000 [27:41<20:27,  2.59s/it, lr=3.26e-7, step_loss=0.173]Steps:  96%|█████████▋| 12527/13000 [27:42<20:27,  2.59s/it, lr=3.26e-7, step_loss=0.137]Steps:  96%|█████████▋| 12527/13000 [27:42<20:27,  2.59s/it, lr=3.26e-7, step_loss=0.033]Steps:  96%|█████████▋| 12527/13000 [27:42<20:27,  2.59s/it, lr=3.26e-7, step_loss=0.0307]Steps:  96%|█████████▋| 12528/13000 [27:43<17:39,  2.25s/it, lr=3.26e-7, step_loss=0.0307]Steps:  96%|█████████▋| 12528/13000 [27:43<17:39,  2.25s/it, lr=3.25e-7, step_loss=0.245] Steps:  96%|█████████▋| 12528/13000 [27:43<17:39,  2.25s/it, lr=3.25e-7, step_loss=0.039]Steps:  96%|█████████▋| 12528/13000 [27:44<17:39,  2.25s/it, lr=3.25e-7, step_loss=0.0145]Steps:  96%|█████████▋| 12528/13000 [27:44<17:39,  2.25s/it, lr=3.25e-7, step_loss=0.0189]Steps:  96%|█████████▋| 12529/13000 [27:44<15:49,  2.02s/it, lr=3.25e-7, step_loss=0.0189]Steps:  96%|█████████▋| 12529/13000 [27:44<15:49,  2.02s/it, lr=3.24e-7, step_loss=0.235] Steps:  96%|█████████▋| 12529/13000 [27:45<15:49,  2.02s/it, lr=3.24e-7, step_loss=0.0312]Steps:  96%|█████████▋| 12529/13000 [27:45<15:49,  2.02s/it, lr=3.24e-7, step_loss=0.0653]Steps:  96%|█████████▋| 12529/13000 [27:45<15:49,  2.02s/it, lr=3.24e-7, step_loss=0.0279]Steps:  96%|█████████▋| 12530/13000 [27:46<14:25,  1.84s/it, lr=3.24e-7, step_loss=0.0279]Steps:  96%|█████████▋| 12530/13000 [27:46<14:25,  1.84s/it, lr=3.22e-7, step_loss=0.0954]Steps:  96%|█████████▋| 12530/13000 [27:46<14:25,  1.84s/it, lr=3.22e-7, step_loss=0.0912]Steps:  96%|█████████▋| 12531/13000 [27:46<11:43,  1.50s/it, lr=3.22e-7, step_loss=0.0912]Steps:  96%|█████████▋| 12531/13000 [27:46<11:43,  1.50s/it, lr=3.21e-7, step_loss=0.0256]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.09it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.96it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.60it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.15it/s]
02/23/2025 16:11:13 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▋| 12531/13000 [28:01<11:43,  1.50s/it, lr=3.21e-7, step_loss=0.0353]Steps:  96%|█████████▋| 12531/13000 [28:01<11:43,  1.50s/it, lr=3.21e-7, step_loss=0.0627]Steps:  96%|█████████▋| 12531/13000 [28:02<11:43,  1.50s/it, lr=3.21e-7, step_loss=0.0636]Steps:  96%|█████████▋| 12532/13000 [28:02<44:43,  5.73s/it, lr=3.21e-7, step_loss=0.0636]Steps:  96%|█████████▋| 12532/13000 [28:02<44:43,  5.73s/it, lr=3.19e-7, step_loss=0.283] Steps:  96%|█████████▋| 12532/13000 [28:02<44:43,  5.73s/it, lr=3.19e-7, step_loss=0.0141]Steps:  96%|█████████▋| 12532/13000 [28:04<44:43,  5.73s/it, lr=3.19e-7, step_loss=0.0298]Steps:  96%|█████████▋| 12532/13000 [28:05<44:43,  5.73s/it, lr=3.19e-7, step_loss=0.0493]Steps:  96%|█████████▋| 12533/13000 [28:05<38:14,  4.91s/it, lr=3.19e-7, step_loss=0.0493]Steps:  96%|█████████▋| 12533/13000 [28:05<38:14,  4.91s/it, lr=3.18e-7, step_loss=0.0127]Steps:  96%|█████████▋| 12533/13000 [28:05<38:14,  4.91s/it, lr=3.18e-7, step_loss=0.0326]Steps:  96%|█████████▋| 12533/13000 [28:06<38:14,  4.91s/it, lr=3.18e-7, step_loss=0.125] Steps:  96%|█████████▋| 12533/13000 [28:06<38:14,  4.91s/it, lr=3.18e-7, step_loss=0.0871]Steps:  96%|█████████▋| 12534/13000 [28:06<30:04,  3.87s/it, lr=3.18e-7, step_loss=0.0871]Steps:  96%|█████████▋| 12534/13000 [28:07<30:04,  3.87s/it, lr=3.17e-7, step_loss=0.0917]Steps:  96%|█████████▋| 12534/13000 [28:07<30:04,  3.87s/it, lr=3.17e-7, step_loss=0.116] Steps:  96%|█████████▋| 12534/13000 [28:07<30:04,  3.87s/it, lr=3.17e-7, step_loss=0.0544]Steps:  96%|█████████▋| 12534/13000 [28:08<30:04,  3.87s/it, lr=3.17e-7, step_loss=0.00329]Steps:  96%|█████████▋| 12535/13000 [28:08<24:28,  3.16s/it, lr=3.17e-7, step_loss=0.00329]Steps:  96%|█████████▋| 12535/13000 [28:08<24:28,  3.16s/it, lr=3.15e-7, step_loss=0.038]  Steps:  96%|█████████▋| 12535/13000 [28:08<24:28,  3.16s/it, lr=3.15e-7, step_loss=0.0205]Steps:  96%|█████████▋| 12535/13000 [28:09<24:28,  3.16s/it, lr=3.15e-7, step_loss=0.655] Steps:  96%|█████████▋| 12535/13000 [28:09<24:28,  3.16s/it, lr=3.15e-7, step_loss=0.221]Steps:  96%|█████████▋| 12536/13000 [28:09<20:29,  2.65s/it, lr=3.15e-7, step_loss=0.221]Steps:  96%|█████████▋| 12536/13000 [28:09<20:29,  2.65s/it, lr=3.14e-7, step_loss=0.0276]Steps:  96%|█████████▋| 12536/13000 [28:10<20:29,  2.65s/it, lr=3.14e-7, step_loss=0.0268]Steps:  96%|█████████▋| 12536/13000 [28:10<20:29,  2.65s/it, lr=3.14e-7, step_loss=0.351] Steps:  96%|█████████▋| 12536/13000 [28:11<20:29,  2.65s/it, lr=3.14e-7, step_loss=0.0393]Steps:  96%|█████████▋| 12537/13000 [28:11<17:37,  2.28s/it, lr=3.14e-7, step_loss=0.0393]Steps:  96%|█████████▋| 12537/13000 [28:11<17:37,  2.28s/it, lr=3.13e-7, step_loss=0.441] Steps:  96%|█████████▋| 12537/13000 [28:11<17:37,  2.28s/it, lr=3.13e-7, step_loss=0.167]Steps:  96%|█████████▋| 12537/13000 [28:12<17:37,  2.28s/it, lr=3.13e-7, step_loss=0.0083]Steps:  96%|█████████▋| 12537/13000 [28:12<17:37,  2.28s/it, lr=3.13e-7, step_loss=0.0281]Steps:  96%|█████████▋| 12538/13000 [28:12<15:39,  2.03s/it, lr=3.13e-7, step_loss=0.0281]Steps:  96%|█████████▋| 12538/13000 [28:12<15:39,  2.03s/it, lr=3.11e-7, step_loss=0.0372]Steps:  96%|█████████▋| 12538/13000 [28:13<15:39,  2.03s/it, lr=3.11e-7, step_loss=0.0122]Steps:  96%|█████████▋| 12538/13000 [28:13<15:39,  2.03s/it, lr=3.11e-7, step_loss=0.0304]Steps:  96%|█████████▋| 12538/13000 [28:13<15:39,  2.03s/it, lr=3.11e-7, step_loss=0.363] Steps:  96%|█████████▋| 12539/13000 [28:14<14:17,  1.86s/it, lr=3.11e-7, step_loss=0.363]Steps:  96%|█████████▋| 12539/13000 [28:14<14:17,  1.86s/it, lr=3.1e-7, step_loss=0.0571]Steps:  96%|█████████▋| 12539/13000 [28:14<14:17,  1.86s/it, lr=3.1e-7, step_loss=0.0133]Steps:  96%|█████████▋| 12540/13000 [28:14<11:34,  1.51s/it, lr=3.1e-7, step_loss=0.0133]Steps:  96%|█████████▋| 12540/13000 [28:15<11:34,  1.51s/it, lr=3.09e-7, step_loss=0.024]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.18it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.47it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.75it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.34it/s]
02/23/2025 16:11:41 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  96%|█████████▋| 12540/13000 [28:29<11:34,  1.51s/it, lr=3.09e-7, step_loss=0.0212]Steps:  96%|█████████▋| 12540/13000 [28:29<11:34,  1.51s/it, lr=3.09e-7, step_loss=0.00516]Steps:  96%|█████████▋| 12540/13000 [28:30<11:34,  1.51s/it, lr=3.09e-7, step_loss=0.0224] Steps:  96%|█████████▋| 12541/13000 [28:30<43:39,  5.71s/it, lr=3.09e-7, step_loss=0.0224]Steps:  96%|█████████▋| 12541/13000 [28:30<43:39,  5.71s/it, lr=3.07e-7, step_loss=0.336] Steps:  96%|█████████▋| 12541/13000 [28:30<43:39,  5.71s/it, lr=3.07e-7, step_loss=0.00867]Steps:  96%|█████████▋| 12541/13000 [28:31<43:39,  5.71s/it, lr=3.07e-7, step_loss=0.0328] Steps:  96%|█████████▋| 12541/13000 [28:31<43:39,  5.71s/it, lr=3.07e-7, step_loss=0.0306]Steps:  96%|█████████▋| 12542/13000 [28:31<33:45,  4.42s/it, lr=3.07e-7, step_loss=0.0306]Steps:  96%|█████████▋| 12542/13000 [28:31<33:45,  4.42s/it, lr=3.06e-7, step_loss=0.467] Steps:  96%|█████████▋| 12542/13000 [28:32<33:45,  4.42s/it, lr=3.06e-7, step_loss=0.015]Steps:  96%|█████████▋| 12542/13000 [28:32<33:45,  4.42s/it, lr=3.06e-7, step_loss=0.00536]Steps:  96%|█████████▋| 12542/13000 [28:33<33:45,  4.42s/it, lr=3.06e-7, step_loss=0.0447] Steps:  96%|█████████▋| 12543/13000 [28:33<26:54,  3.53s/it, lr=3.06e-7, step_loss=0.0447]Steps:  96%|█████████▋| 12543/13000 [28:33<26:54,  3.53s/it, lr=3.05e-7, step_loss=0.035] Steps:  96%|█████████▋| 12543/13000 [28:33<26:54,  3.53s/it, lr=3.05e-7, step_loss=0.00966]Steps:  96%|█████████▋| 12543/13000 [28:34<26:54,  3.53s/it, lr=3.05e-7, step_loss=0.117]  Steps:  96%|█████████▋| 12543/13000 [28:34<26:54,  3.53s/it, lr=3.05e-7, step_loss=0.0379]Steps:  96%|█████████▋| 12544/13000 [28:34<22:05,  2.91s/it, lr=3.05e-7, step_loss=0.0379]Steps:  96%|█████████▋| 12544/13000 [28:34<22:05,  2.91s/it, lr=3.03e-7, step_loss=0.0035]Steps:  96%|█████████▋| 12544/13000 [28:35<22:05,  2.91s/it, lr=3.03e-7, step_loss=0.0208]Steps:  96%|█████████▋| 12544/13000 [28:35<22:05,  2.91s/it, lr=3.03e-7, step_loss=0.0922]Steps:  96%|█████████▋| 12544/13000 [28:35<22:05,  2.91s/it, lr=3.03e-7, step_loss=0.0379]Steps:  96%|█████████▋| 12545/13000 [28:36<18:48,  2.48s/it, lr=3.03e-7, step_loss=0.0379]Steps:  96%|█████████▋| 12545/13000 [28:38<18:48,  2.48s/it, lr=3.02e-7, step_loss=0.00367]Steps:  96%|█████████▋| 12545/13000 [28:38<18:48,  2.48s/it, lr=3.02e-7, step_loss=0.156]  Steps:  96%|█████████▋| 12545/13000 [28:38<18:48,  2.48s/it, lr=3.02e-7, step_loss=0.0104]Steps:  96%|█████████▋| 12545/13000 [28:39<18:48,  2.48s/it, lr=3.02e-7, step_loss=0.0057]Steps:  97%|█████████▋| 12546/13000 [28:39<20:28,  2.71s/it, lr=3.02e-7, step_loss=0.0057]Steps:  97%|█████████▋| 12546/13000 [28:39<20:28,  2.71s/it, lr=3.01e-7, step_loss=0.0188]Steps:  97%|█████████▋| 12546/13000 [28:39<20:28,  2.71s/it, lr=3.01e-7, step_loss=0.203] Steps:  97%|█████████▋| 12546/13000 [28:40<20:28,  2.71s/it, lr=3.01e-7, step_loss=0.00552]Steps:  97%|█████████▋| 12546/13000 [28:40<20:28,  2.71s/it, lr=3.01e-7, step_loss=0.0391] Steps:  97%|█████████▋| 12547/13000 [28:40<17:36,  2.33s/it, lr=3.01e-7, step_loss=0.0391]Steps:  97%|█████████▋| 12547/13000 [28:41<17:36,  2.33s/it, lr=2.99e-7, step_loss=0.00717]Steps:  97%|█████████▋| 12547/13000 [28:41<17:36,  2.33s/it, lr=2.99e-7, step_loss=0.0466] Steps:  97%|█████████▋| 12547/13000 [28:41<17:36,  2.33s/it, lr=2.99e-7, step_loss=0.0343]Steps:  97%|█████████▋| 12547/13000 [28:42<17:36,  2.33s/it, lr=2.99e-7, step_loss=0.0457]Steps:  97%|█████████▋| 12548/13000 [28:42<15:35,  2.07s/it, lr=2.99e-7, step_loss=0.0457]Steps:  97%|█████████▋| 12548/13000 [28:42<15:35,  2.07s/it, lr=2.98e-7, step_loss=0.018] Steps:  97%|█████████▋| 12548/13000 [28:42<15:35,  2.07s/it, lr=2.98e-7, step_loss=0.267]Steps:  97%|█████████▋| 12549/13000 [28:43<12:29,  1.66s/it, lr=2.98e-7, step_loss=0.267]Steps:  97%|█████████▋| 12549/13000 [28:43<12:29,  1.66s/it, lr=2.97e-7, step_loss=0.151]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.14it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.14it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.76it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.30it/s]
02/23/2025 16:12:09 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  97%|█████████▋| 12549/13000 [28:58<12:29,  1.66s/it, lr=2.97e-7, step_loss=0.211]Steps:  97%|█████████▋| 12549/13000 [28:58<12:29,  1.66s/it, lr=2.97e-7, step_loss=0.00919]Steps:  97%|█████████▋| 12549/13000 [28:58<12:29,  1.66s/it, lr=2.97e-7, step_loss=0.0669] Steps:  97%|█████████▋| 12550/13000 [28:59<44:49,  5.98s/it, lr=2.97e-7, step_loss=0.0669]Steps:  97%|█████████▋| 12550/13000 [28:59<44:49,  5.98s/it, lr=2.95e-7, step_loss=0.706] Steps:  97%|█████████▋| 12550/13000 [29:00<44:49,  5.98s/it, lr=2.95e-7, step_loss=0.026]Steps:  97%|█████████▋| 12550/13000 [29:00<44:49,  5.98s/it, lr=2.95e-7, step_loss=0.00866]Steps:  97%|█████████▋| 12550/13000 [29:00<44:49,  5.98s/it, lr=2.95e-7, step_loss=0.518]  Steps:  97%|█████████▋| 12551/13000 [29:01<35:35,  4.76s/it, lr=2.95e-7, step_loss=0.518]Steps:  97%|█████████▋| 12551/13000 [29:01<35:35,  4.76s/it, lr=2.94e-7, step_loss=0.027]Steps:  97%|█████████▋| 12551/13000 [29:01<35:35,  4.76s/it, lr=2.94e-7, step_loss=0.077]Steps:  97%|█████████▋| 12551/13000 [29:01<35:35,  4.76s/it, lr=2.94e-7, step_loss=0.0102]Steps:  97%|█████████▋| 12551/13000 [29:02<35:35,  4.76s/it, lr=2.94e-7, step_loss=0.125] Steps:  97%|█████████▋| 12552/13000 [29:02<28:03,  3.76s/it, lr=2.94e-7, step_loss=0.125]Steps:  97%|█████████▋| 12552/13000 [29:02<28:03,  3.76s/it, lr=2.93e-7, step_loss=0.329]Steps:  97%|█████████▋| 12552/13000 [29:02<28:03,  3.76s/it, lr=2.93e-7, step_loss=0.0288]Steps:  97%|█████████▋| 12552/13000 [29:03<28:03,  3.76s/it, lr=2.93e-7, step_loss=0.00928]Steps:  97%|█████████▋| 12552/13000 [29:03<28:03,  3.76s/it, lr=2.93e-7, step_loss=0.144]  Steps:  97%|█████████▋| 12553/13000 [29:03<22:48,  3.06s/it, lr=2.93e-7, step_loss=0.144]Steps:  97%|█████████▋| 12553/13000 [29:03<22:48,  3.06s/it, lr=2.91e-7, step_loss=0.155]Steps:  97%|█████████▋| 12553/13000 [29:04<22:48,  3.06s/it, lr=2.91e-7, step_loss=0.0637]Steps:  97%|█████████▋| 12553/13000 [29:04<22:48,  3.06s/it, lr=2.91e-7, step_loss=0.0217]Steps:  97%|█████████▋| 12553/13000 [29:05<22:48,  3.06s/it, lr=2.91e-7, step_loss=0.0491]Steps:  97%|█████████▋| 12554/13000 [29:05<19:06,  2.57s/it, lr=2.91e-7, step_loss=0.0491]Steps:  97%|█████████▋| 12554/13000 [29:05<19:06,  2.57s/it, lr=2.9e-7, step_loss=0.00407]Steps:  97%|█████████▋| 12554/13000 [29:05<19:06,  2.57s/it, lr=2.9e-7, step_loss=0.0136] Steps:  97%|█████████▋| 12554/13000 [29:06<19:06,  2.57s/it, lr=2.9e-7, step_loss=0.00519]Steps:  97%|█████████▋| 12554/13000 [29:06<19:06,  2.57s/it, lr=2.9e-7, step_loss=0.129]  Steps:  97%|█████████▋| 12555/13000 [29:06<16:41,  2.25s/it, lr=2.9e-7, step_loss=0.129]Steps:  97%|█████████▋| 12555/13000 [29:06<16:41,  2.25s/it, lr=2.89e-7, step_loss=0.117]Steps:  97%|█████████▋| 12555/13000 [29:07<16:41,  2.25s/it, lr=2.89e-7, step_loss=0.0215]Steps:  97%|█████████▋| 12555/13000 [29:07<16:41,  2.25s/it, lr=2.89e-7, step_loss=0.0185]Steps:  97%|█████████▋| 12555/13000 [29:08<16:41,  2.25s/it, lr=2.89e-7, step_loss=0.00591]Steps:  97%|█████████▋| 12556/13000 [29:08<14:52,  2.01s/it, lr=2.89e-7, step_loss=0.00591]Steps:  97%|█████████▋| 12556/13000 [29:08<14:52,  2.01s/it, lr=2.88e-7, step_loss=0.683]  Steps:  97%|█████████▋| 12556/13000 [29:08<14:52,  2.01s/it, lr=2.88e-7, step_loss=0.0831]Steps:  97%|█████████▋| 12556/13000 [29:09<14:52,  2.01s/it, lr=2.88e-7, step_loss=0.0147]Steps:  97%|█████████▋| 12556/13000 [29:09<14:52,  2.01s/it, lr=2.88e-7, step_loss=0.0125]Steps:  97%|█████████▋| 12557/13000 [29:09<13:42,  1.86s/it, lr=2.88e-7, step_loss=0.0125]Steps:  97%|█████████▋| 12557/13000 [29:09<13:42,  1.86s/it, lr=2.86e-7, step_loss=0.216] Steps:  97%|█████████▋| 12557/13000 [29:10<13:42,  1.86s/it, lr=2.86e-7, step_loss=0.0927]Steps:  97%|█████████▋| 12558/13000 [29:10<11:08,  1.51s/it, lr=2.86e-7, step_loss=0.0927]Steps:  97%|█████████▋| 12558/13000 [29:10<11:08,  1.51s/it, lr=2.85e-7, step_loss=0.0432]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.16it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.80it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.49it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.04it/s]
02/23/2025 16:12:37 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12558/13000 [29:24<11:08,  1.51s/it, lr=2.85e-7, step_loss=0.16]  Steps:  97%|█████████▋| 12558/13000 [29:25<11:08,  1.51s/it, lr=2.85e-7, step_loss=0.0281]Steps:  97%|█████████▋| 12558/13000 [29:25<11:08,  1.51s/it, lr=2.85e-7, step_loss=0.169] Steps:  97%|█████████▋| 12559/13000 [29:25<41:33,  5.65s/it, lr=2.85e-7, step_loss=0.169]Steps:  97%|█████████▋| 12559/13000 [29:25<41:33,  5.65s/it, lr=2.84e-7, step_loss=0.0927]Steps:  97%|█████████▋| 12559/13000 [29:26<41:33,  5.65s/it, lr=2.84e-7, step_loss=0.00549]Steps:  97%|█████████▋| 12559/13000 [29:26<41:33,  5.65s/it, lr=2.84e-7, step_loss=0.0213] Steps:  97%|█████████▋| 12559/13000 [29:27<41:33,  5.65s/it, lr=2.84e-7, step_loss=0.0263]Steps:  97%|█████████▋| 12560/13000 [29:27<32:17,  4.40s/it, lr=2.84e-7, step_loss=0.0263]Steps:  97%|█████████▋| 12560/13000 [29:27<32:17,  4.40s/it, lr=2.82e-7, step_loss=0.153] Steps:  97%|█████████▋| 12560/13000 [29:27<32:17,  4.40s/it, lr=2.82e-7, step_loss=0.0323]Steps:  97%|█████████▋| 12560/13000 [29:28<32:17,  4.40s/it, lr=2.82e-7, step_loss=0.0109]Steps:  97%|█████████▋| 12560/13000 [29:28<32:17,  4.40s/it, lr=2.82e-7, step_loss=0.104] Steps:  97%|█████████▋| 12561/13000 [29:28<25:43,  3.52s/it, lr=2.82e-7, step_loss=0.104]Steps:  97%|█████████▋| 12561/13000 [29:28<25:43,  3.52s/it, lr=2.81e-7, step_loss=0.0963]Steps:  97%|█████████▋| 12561/13000 [29:29<25:43,  3.52s/it, lr=2.81e-7, step_loss=0.0959]Steps:  97%|█████████▋| 12561/13000 [29:30<25:43,  3.52s/it, lr=2.81e-7, step_loss=0.0263]Steps:  97%|█████████▋| 12561/13000 [29:30<25:43,  3.52s/it, lr=2.81e-7, step_loss=0.00871]Steps:  97%|█████████▋| 12562/13000 [29:30<22:15,  3.05s/it, lr=2.81e-7, step_loss=0.00871]Steps:  97%|█████████▋| 12562/13000 [29:30<22:15,  3.05s/it, lr=2.8e-7, step_loss=0.5]     Steps:  97%|█████████▋| 12562/13000 [29:31<22:15,  3.05s/it, lr=2.8e-7, step_loss=0.134]Steps:  97%|█████████▋| 12562/13000 [29:31<22:15,  3.05s/it, lr=2.8e-7, step_loss=0.00629]Steps:  97%|█████████▋| 12562/13000 [29:31<22:15,  3.05s/it, lr=2.8e-7, step_loss=0.00728]Steps:  97%|█████████▋| 12563/13000 [29:32<18:38,  2.56s/it, lr=2.8e-7, step_loss=0.00728]Steps:  97%|█████████▋| 12563/13000 [29:32<18:38,  2.56s/it, lr=2.79e-7, step_loss=0.0562]Steps:  97%|█████████▋| 12563/13000 [29:32<18:38,  2.56s/it, lr=2.79e-7, step_loss=0.058] Steps:  97%|█████████▋| 12563/13000 [29:32<18:38,  2.56s/it, lr=2.79e-7, step_loss=0.112]Steps:  97%|█████████▋| 12563/13000 [29:33<18:38,  2.56s/it, lr=2.79e-7, step_loss=0.0211]Steps:  97%|█████████▋| 12564/13000 [29:33<16:11,  2.23s/it, lr=2.79e-7, step_loss=0.0211]Steps:  97%|█████████▋| 12564/13000 [29:33<16:11,  2.23s/it, lr=2.77e-7, step_loss=0.00841]Steps:  97%|█████████▋| 12564/13000 [29:34<16:11,  2.23s/it, lr=2.77e-7, step_loss=0.0807] Steps:  97%|█████████▋| 12564/13000 [29:34<16:11,  2.23s/it, lr=2.77e-7, step_loss=0.244] Steps:  97%|█████████▋| 12564/13000 [29:34<16:11,  2.23s/it, lr=2.77e-7, step_loss=0.0194]Steps:  97%|█████████▋| 12565/13000 [29:35<14:28,  2.00s/it, lr=2.77e-7, step_loss=0.0194]Steps:  97%|█████████▋| 12565/13000 [29:35<14:28,  2.00s/it, lr=2.76e-7, step_loss=0.321] Steps:  97%|█████████▋| 12565/13000 [29:35<14:28,  2.00s/it, lr=2.76e-7, step_loss=0.0234]Steps:  97%|█████████▋| 12565/13000 [29:35<14:28,  2.00s/it, lr=2.76e-7, step_loss=0.0074]Steps:  97%|█████████▋| 12565/13000 [29:36<14:28,  2.00s/it, lr=2.76e-7, step_loss=0.416] Steps:  97%|█████████▋| 12566/13000 [29:36<13:18,  1.84s/it, lr=2.76e-7, step_loss=0.416]Steps:  97%|█████████▋| 12566/13000 [29:36<13:18,  1.84s/it, lr=2.75e-7, step_loss=0.285]Steps:  97%|█████████▋| 12566/13000 [29:36<13:18,  1.84s/it, lr=2.75e-7, step_loss=0.00324]Steps:  97%|█████████▋| 12567/13000 [29:37<10:47,  1.50s/it, lr=2.75e-7, step_loss=0.00324]Steps:  97%|█████████▋| 12567/13000 [29:37<10:47,  1.50s/it, lr=2.73e-7, step_loss=0.00511]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.11it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.50it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.39it/s]
02/23/2025 16:13:03 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12567/13000 [29:51<10:47,  1.50s/it, lr=2.73e-7, step_loss=0.0732] Steps:  97%|█████████▋| 12567/13000 [29:52<10:47,  1.50s/it, lr=2.73e-7, step_loss=0.397] Steps:  97%|█████████▋| 12567/13000 [29:52<10:47,  1.50s/it, lr=2.73e-7, step_loss=0.0228]Steps:  97%|█████████▋| 12568/13000 [29:52<40:56,  5.69s/it, lr=2.73e-7, step_loss=0.0228]Steps:  97%|█████████▋| 12568/13000 [29:52<40:56,  5.69s/it, lr=2.72e-7, step_loss=0.132] Steps:  97%|█████████▋| 12568/13000 [29:53<40:56,  5.69s/it, lr=2.72e-7, step_loss=0.0153]Steps:  97%|█████████▋| 12568/13000 [29:53<40:56,  5.69s/it, lr=2.72e-7, step_loss=0.0126]Steps:  97%|█████████▋| 12568/13000 [29:53<40:56,  5.69s/it, lr=2.72e-7, step_loss=0.0316]Steps:  97%|█████████▋| 12569/13000 [29:54<31:41,  4.41s/it, lr=2.72e-7, step_loss=0.0316]Steps:  97%|█████████▋| 12569/13000 [29:54<31:41,  4.41s/it, lr=2.71e-7, step_loss=0.00371]Steps:  97%|█████████▋| 12569/13000 [29:54<31:41,  4.41s/it, lr=2.71e-7, step_loss=0.178]  Steps:  97%|█████████▋| 12569/13000 [29:54<31:41,  4.41s/it, lr=2.71e-7, step_loss=0.143]Steps:  97%|█████████▋| 12569/13000 [29:55<31:41,  4.41s/it, lr=2.71e-7, step_loss=0.0469]Steps:  97%|█████████▋| 12570/13000 [29:55<25:12,  3.52s/it, lr=2.71e-7, step_loss=0.0469]Steps:  97%|█████████▋| 12570/13000 [29:55<25:12,  3.52s/it, lr=2.7e-7, step_loss=0.339]  Steps:  97%|█████████▋| 12570/13000 [29:56<25:12,  3.52s/it, lr=2.7e-7, step_loss=0.00271]Steps:  97%|█████████▋| 12570/13000 [29:56<25:12,  3.52s/it, lr=2.7e-7, step_loss=0.201]  Steps:  97%|█████████▋| 12570/13000 [29:56<25:12,  3.52s/it, lr=2.7e-7, step_loss=0.027]Steps:  97%|█████████▋| 12571/13000 [29:57<20:46,  2.90s/it, lr=2.7e-7, step_loss=0.027]Steps:  97%|█████████▋| 12571/13000 [29:57<20:46,  2.90s/it, lr=2.68e-7, step_loss=0.0248]Steps:  97%|█████████▋| 12571/13000 [29:57<20:46,  2.90s/it, lr=2.68e-7, step_loss=0.0689]Steps:  97%|█████████▋| 12571/13000 [29:57<20:46,  2.90s/it, lr=2.68e-7, step_loss=0.0278]Steps:  97%|█████████▋| 12571/13000 [29:58<20:46,  2.90s/it, lr=2.68e-7, step_loss=0.199] Steps:  97%|█████████▋| 12572/13000 [30:00<21:45,  3.05s/it, lr=2.68e-7, step_loss=0.199]Steps:  97%|█████████▋| 12572/13000 [30:00<21:45,  3.05s/it, lr=2.67e-7, step_loss=0.0281]Steps:  97%|█████████▋| 12572/13000 [30:00<21:45,  3.05s/it, lr=2.67e-7, step_loss=0.0921]Steps:  97%|█████████▋| 12572/13000 [30:01<21:45,  3.05s/it, lr=2.67e-7, step_loss=0.00343]Steps:  97%|█████████▋| 12572/13000 [30:01<21:45,  3.05s/it, lr=2.67e-7, step_loss=0.0934] Steps:  97%|█████████▋| 12573/13000 [30:01<18:17,  2.57s/it, lr=2.67e-7, step_loss=0.0934]Steps:  97%|█████████▋| 12573/13000 [30:03<18:17,  2.57s/it, lr=2.66e-7, step_loss=0.00428]Steps:  97%|█████████▋| 12573/13000 [30:03<18:17,  2.57s/it, lr=2.66e-7, step_loss=0.0364] Steps:  97%|█████████▋| 12573/13000 [30:04<18:17,  2.57s/it, lr=2.66e-7, step_loss=0.115] Steps:  97%|█████████▋| 12573/13000 [30:04<18:17,  2.57s/it, lr=2.66e-7, step_loss=0.119]Steps:  97%|█████████▋| 12574/13000 [30:04<18:49,  2.65s/it, lr=2.66e-7, step_loss=0.119]Steps:  97%|█████████▋| 12574/13000 [30:04<18:49,  2.65s/it, lr=2.65e-7, step_loss=0.00535]Steps:  97%|█████████▋| 12574/13000 [30:05<18:49,  2.65s/it, lr=2.65e-7, step_loss=0.417]  Steps:  97%|█████████▋| 12574/13000 [30:05<18:49,  2.65s/it, lr=2.65e-7, step_loss=0.0236]Steps:  97%|█████████▋| 12574/13000 [30:05<18:49,  2.65s/it, lr=2.65e-7, step_loss=0.334] Steps:  97%|█████████▋| 12575/13000 [30:06<16:20,  2.31s/it, lr=2.65e-7, step_loss=0.334]Steps:  97%|█████████▋| 12575/13000 [30:06<16:20,  2.31s/it, lr=2.63e-7, step_loss=0.00525]Steps:  97%|█████████▋| 12575/13000 [30:06<16:20,  2.31s/it, lr=2.63e-7, step_loss=0.00445]Steps:  97%|█████████▋| 12576/13000 [30:06<12:52,  1.82s/it, lr=2.63e-7, step_loss=0.00445]Steps:  97%|█████████▋| 12576/13000 [30:06<12:52,  1.82s/it, lr=2.62e-7, step_loss=0.0639] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.18it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.96it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.58it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.13it/s]
02/23/2025 16:13:33 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12576/13000 [30:21<12:52,  1.82s/it, lr=2.62e-7, step_loss=0.218] Steps:  97%|█████████▋| 12576/13000 [30:21<12:52,  1.82s/it, lr=2.62e-7, step_loss=0.0121]Steps:  97%|█████████▋| 12576/13000 [30:22<12:52,  1.82s/it, lr=2.62e-7, step_loss=0.329] Steps:  97%|█████████▋| 12577/13000 [30:22<41:33,  5.89s/it, lr=2.62e-7, step_loss=0.329]Steps:  97%|█████████▋| 12577/13000 [30:22<41:33,  5.89s/it, lr=2.61e-7, step_loss=0.026]Steps:  97%|█████████▋| 12577/13000 [30:22<41:33,  5.89s/it, lr=2.61e-7, step_loss=0.09] Steps:  97%|█████████▋| 12577/13000 [30:23<41:33,  5.89s/it, lr=2.61e-7, step_loss=0.0238]Steps:  97%|█████████▋| 12577/13000 [30:23<41:33,  5.89s/it, lr=2.61e-7, step_loss=0.0589]Steps:  97%|█████████▋| 12578/13000 [30:23<32:01,  4.55s/it, lr=2.61e-7, step_loss=0.0589]Steps:  97%|█████████▋| 12578/13000 [30:23<32:01,  4.55s/it, lr=2.6e-7, step_loss=0.142]  Steps:  97%|█████████▋| 12578/13000 [30:24<32:01,  4.55s/it, lr=2.6e-7, step_loss=0.155]Steps:  97%|█████████▋| 12578/13000 [30:24<32:01,  4.55s/it, lr=2.6e-7, step_loss=0.0235]Steps:  97%|█████████▋| 12578/13000 [30:24<32:01,  4.55s/it, lr=2.6e-7, step_loss=0.178] Steps:  97%|█████████▋| 12579/13000 [30:25<25:31,  3.64s/it, lr=2.6e-7, step_loss=0.178]Steps:  97%|█████████▋| 12579/13000 [30:25<25:31,  3.64s/it, lr=2.59e-7, step_loss=0.0729]Steps:  97%|█████████▋| 12579/13000 [30:25<25:31,  3.64s/it, lr=2.59e-7, step_loss=0.00342]Steps:  97%|█████████▋| 12579/13000 [30:26<25:31,  3.64s/it, lr=2.59e-7, step_loss=0.145]  Steps:  97%|█████████▋| 12579/13000 [30:26<25:31,  3.64s/it, lr=2.59e-7, step_loss=0.00639]Steps:  97%|█████████▋| 12580/13000 [30:26<20:55,  2.99s/it, lr=2.59e-7, step_loss=0.00639]Steps:  97%|█████████▋| 12580/13000 [30:26<20:55,  2.99s/it, lr=2.57e-7, step_loss=0.0827] Steps:  97%|█████████▋| 12580/13000 [30:27<20:55,  2.99s/it, lr=2.57e-7, step_loss=0.168] Steps:  97%|█████████▋| 12580/13000 [30:27<20:55,  2.99s/it, lr=2.57e-7, step_loss=0.0288]Steps:  97%|█████████▋| 12580/13000 [30:27<20:55,  2.99s/it, lr=2.57e-7, step_loss=0.148] Steps:  97%|█████████▋| 12581/13000 [30:28<17:42,  2.54s/it, lr=2.57e-7, step_loss=0.148]Steps:  97%|█████████▋| 12581/13000 [30:28<17:42,  2.54s/it, lr=2.56e-7, step_loss=0.106]Steps:  97%|█████████▋| 12581/13000 [30:28<17:42,  2.54s/it, lr=2.56e-7, step_loss=0.0114]Steps:  97%|█████████▋| 12581/13000 [30:28<17:42,  2.54s/it, lr=2.56e-7, step_loss=0.0041]Steps:  97%|█████████▋| 12581/13000 [30:29<17:42,  2.54s/it, lr=2.56e-7, step_loss=0.0472]Steps:  97%|█████████▋| 12582/13000 [30:29<15:25,  2.21s/it, lr=2.56e-7, step_loss=0.0472]Steps:  97%|█████████▋| 12582/13000 [30:29<15:25,  2.21s/it, lr=2.55e-7, step_loss=0.162] Steps:  97%|█████████▋| 12582/13000 [30:30<15:25,  2.21s/it, lr=2.55e-7, step_loss=0.121]Steps:  97%|█████████▋| 12582/13000 [30:30<15:25,  2.21s/it, lr=2.55e-7, step_loss=0.364]Steps:  97%|█████████▋| 12582/13000 [30:30<15:25,  2.21s/it, lr=2.55e-7, step_loss=0.0745]Steps:  97%|█████████▋| 12583/13000 [30:31<13:43,  1.97s/it, lr=2.55e-7, step_loss=0.0745]Steps:  97%|█████████▋| 12583/13000 [30:31<13:43,  1.97s/it, lr=2.54e-7, step_loss=0.119] Steps:  97%|█████████▋| 12583/13000 [30:31<13:43,  1.97s/it, lr=2.54e-7, step_loss=0.0955]Steps:  97%|█████████▋| 12583/13000 [30:31<13:43,  1.97s/it, lr=2.54e-7, step_loss=0.0499]Steps:  97%|█████████▋| 12583/13000 [30:32<13:43,  1.97s/it, lr=2.54e-7, step_loss=0.0821]Steps:  97%|█████████▋| 12584/13000 [30:32<12:40,  1.83s/it, lr=2.54e-7, step_loss=0.0821]Steps:  97%|█████████▋| 12584/13000 [30:32<12:40,  1.83s/it, lr=2.52e-7, step_loss=0.0553]Steps:  97%|█████████▋| 12584/13000 [30:32<12:40,  1.83s/it, lr=2.52e-7, step_loss=0.024] Steps:  97%|█████████▋| 12585/13000 [30:33<10:18,  1.49s/it, lr=2.52e-7, step_loss=0.024]Steps:  97%|█████████▋| 12585/13000 [30:33<10:18,  1.49s/it, lr=2.51e-7, step_loss=0.07] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.21it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.29it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.01it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.53it/s]
02/23/2025 16:13:59 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12585/13000 [30:47<10:18,  1.49s/it, lr=2.51e-7, step_loss=0.0224]Steps:  97%|█████████▋| 12585/13000 [30:48<10:18,  1.49s/it, lr=2.51e-7, step_loss=0.0685]Steps:  97%|█████████▋| 12585/13000 [30:48<10:18,  1.49s/it, lr=2.51e-7, step_loss=0.0157]Steps:  97%|█████████▋| 12586/13000 [30:48<39:22,  5.71s/it, lr=2.51e-7, step_loss=0.0157]Steps:  97%|█████████▋| 12586/13000 [30:49<39:22,  5.71s/it, lr=2.5e-7, step_loss=0.101]  Steps:  97%|█████████▋| 12586/13000 [30:49<39:22,  5.71s/it, lr=2.5e-7, step_loss=0.0033]Steps:  97%|█████████▋| 12586/13000 [30:50<39:22,  5.71s/it, lr=2.5e-7, step_loss=0.0239]Steps:  97%|█████████▋| 12586/13000 [30:50<39:22,  5.71s/it, lr=2.5e-7, step_loss=0.0668]Steps:  97%|█████████▋| 12587/13000 [30:50<31:54,  4.63s/it, lr=2.5e-7, step_loss=0.0668]Steps:  97%|█████████▋| 12587/13000 [30:50<31:54,  4.63s/it, lr=2.49e-7, step_loss=0.223]Steps:  97%|█████████▋| 12587/13000 [30:51<31:54,  4.63s/it, lr=2.49e-7, step_loss=0.283]Steps:  97%|█████████▋| 12587/13000 [30:51<31:54,  4.63s/it, lr=2.49e-7, step_loss=0.00315]Steps:  97%|█████████▋| 12587/13000 [30:52<31:54,  4.63s/it, lr=2.49e-7, step_loss=0.0652] Steps:  97%|█████████▋| 12588/13000 [30:52<25:15,  3.68s/it, lr=2.49e-7, step_loss=0.0652]Steps:  97%|█████████▋| 12588/13000 [30:52<25:15,  3.68s/it, lr=2.48e-7, step_loss=0.141] Steps:  97%|█████████▋| 12588/13000 [30:52<25:15,  3.68s/it, lr=2.48e-7, step_loss=0.115]Steps:  97%|█████████▋| 12588/13000 [30:53<25:15,  3.68s/it, lr=2.48e-7, step_loss=0.0607]Steps:  97%|█████████▋| 12588/13000 [30:53<25:15,  3.68s/it, lr=2.48e-7, step_loss=0.216] Steps:  97%|█████████▋| 12589/13000 [30:53<20:37,  3.01s/it, lr=2.48e-7, step_loss=0.216]Steps:  97%|█████████▋| 12589/13000 [30:53<20:37,  3.01s/it, lr=2.46e-7, step_loss=0.495]Steps:  97%|█████████▋| 12589/13000 [30:54<20:37,  3.01s/it, lr=2.46e-7, step_loss=0.101]Steps:  97%|█████████▋| 12589/13000 [30:54<20:37,  3.01s/it, lr=2.46e-7, step_loss=0.237]Steps:  97%|█████████▋| 12589/13000 [30:55<20:37,  3.01s/it, lr=2.46e-7, step_loss=0.168]Steps:  97%|█████████▋| 12590/13000 [30:55<17:25,  2.55s/it, lr=2.46e-7, step_loss=0.168]Steps:  97%|█████████▋| 12590/13000 [30:55<17:25,  2.55s/it, lr=2.45e-7, step_loss=0.102]Steps:  97%|█████████▋| 12590/13000 [30:55<17:25,  2.55s/it, lr=2.45e-7, step_loss=0.19] Steps:  97%|█████████▋| 12590/13000 [30:56<17:25,  2.55s/it, lr=2.45e-7, step_loss=0.505]Steps:  97%|█████████▋| 12590/13000 [30:56<17:25,  2.55s/it, lr=2.45e-7, step_loss=0.0927]Steps:  97%|█████████▋| 12591/13000 [30:56<15:09,  2.22s/it, lr=2.45e-7, step_loss=0.0927]Steps:  97%|█████████▋| 12591/13000 [30:56<15:09,  2.22s/it, lr=2.44e-7, step_loss=0.00988]Steps:  97%|█████████▋| 12591/13000 [30:57<15:09,  2.22s/it, lr=2.44e-7, step_loss=0.0192] Steps:  97%|█████████▋| 12591/13000 [30:57<15:09,  2.22s/it, lr=2.44e-7, step_loss=0.146] Steps:  97%|█████████▋| 12591/13000 [30:59<15:09,  2.22s/it, lr=2.44e-7, step_loss=0.15] Steps:  97%|█████████▋| 12592/13000 [30:59<16:36,  2.44s/it, lr=2.44e-7, step_loss=0.15]Steps:  97%|█████████▋| 12592/13000 [30:59<16:36,  2.44s/it, lr=2.43e-7, step_loss=0.2] Steps:  97%|█████████▋| 12592/13000 [31:00<16:36,  2.44s/it, lr=2.43e-7, step_loss=0.136]Steps:  97%|█████████▋| 12592/13000 [31:00<16:36,  2.44s/it, lr=2.43e-7, step_loss=0.0104]Steps:  97%|█████████▋| 12592/13000 [31:00<16:36,  2.44s/it, lr=2.43e-7, step_loss=0.174] Steps:  97%|█████████▋| 12593/13000 [31:01<14:32,  2.14s/it, lr=2.43e-7, step_loss=0.174]Steps:  97%|█████████▋| 12593/13000 [31:01<14:32,  2.14s/it, lr=2.42e-7, step_loss=0.00852]Steps:  97%|█████████▋| 12593/13000 [31:01<14:32,  2.14s/it, lr=2.42e-7, step_loss=0.095]  Steps:  97%|█████████▋| 12594/13000 [31:01<11:33,  1.71s/it, lr=2.42e-7, step_loss=0.095]Steps:  97%|█████████▋| 12594/13000 [31:01<11:33,  1.71s/it, lr=2.4e-7, step_loss=0.0482]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.49it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.60it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.84it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.45it/s]
02/23/2025 16:14:28 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12594/13000 [31:16<11:33,  1.71s/it, lr=2.4e-7, step_loss=0.153] Steps:  97%|█████████▋| 12594/13000 [31:16<11:33,  1.71s/it, lr=2.4e-7, step_loss=0.0231]Steps:  97%|█████████▋| 12594/13000 [31:16<11:33,  1.71s/it, lr=2.4e-7, step_loss=0.0286]Steps:  97%|█████████▋| 12595/13000 [31:17<39:07,  5.80s/it, lr=2.4e-7, step_loss=0.0286]Steps:  97%|█████████▋| 12595/13000 [31:17<39:07,  5.80s/it, lr=2.39e-7, step_loss=0.0257]Steps:  97%|█████████▋| 12595/13000 [31:17<39:07,  5.80s/it, lr=2.39e-7, step_loss=0.0167]Steps:  97%|█████████▋| 12595/13000 [31:18<39:07,  5.80s/it, lr=2.39e-7, step_loss=0.0604]Steps:  97%|█████████▋| 12595/13000 [31:18<39:07,  5.80s/it, lr=2.39e-7, step_loss=0.118] Steps:  97%|█████████▋| 12596/13000 [31:18<30:17,  4.50s/it, lr=2.39e-7, step_loss=0.118]Steps:  97%|█████████▋| 12596/13000 [31:18<30:17,  4.50s/it, lr=2.38e-7, step_loss=0.358]Steps:  97%|█████████▋| 12596/13000 [31:19<30:17,  4.50s/it, lr=2.38e-7, step_loss=0.106]Steps:  97%|█████████▋| 12596/13000 [31:19<30:17,  4.50s/it, lr=2.38e-7, step_loss=0.403]Steps:  97%|█████████▋| 12596/13000 [31:19<30:17,  4.50s/it, lr=2.38e-7, step_loss=0.0487]Steps:  97%|█████████▋| 12597/13000 [31:20<24:04,  3.58s/it, lr=2.38e-7, step_loss=0.0487]Steps:  97%|█████████▋| 12597/13000 [31:20<24:04,  3.58s/it, lr=2.37e-7, step_loss=0.0119]Steps:  97%|█████████▋| 12597/13000 [31:20<24:04,  3.58s/it, lr=2.37e-7, step_loss=0.0317]Steps:  97%|█████████▋| 12597/13000 [31:20<24:04,  3.58s/it, lr=2.37e-7, step_loss=0.187] Steps:  97%|█████████▋| 12597/13000 [31:22<24:04,  3.58s/it, lr=2.37e-7, step_loss=0.0507]Steps:  97%|█████████▋| 12598/13000 [31:22<21:25,  3.20s/it, lr=2.37e-7, step_loss=0.0507]Steps:  97%|█████████▋| 12598/13000 [31:22<21:25,  3.20s/it, lr=2.36e-7, step_loss=0.014] Steps:  97%|█████████▋| 12598/13000 [31:22<21:25,  3.20s/it, lr=2.36e-7, step_loss=0.00326]Steps:  97%|█████████▋| 12598/13000 [31:23<21:25,  3.20s/it, lr=2.36e-7, step_loss=0.00576]Steps:  97%|█████████▋| 12598/13000 [31:23<21:25,  3.20s/it, lr=2.36e-7, step_loss=0.12]   Steps:  97%|█████████▋| 12599/13000 [31:23<17:52,  2.67s/it, lr=2.36e-7, step_loss=0.12]Steps:  97%|█████████▋| 12599/13000 [31:23<17:52,  2.67s/it, lr=2.35e-7, step_loss=0.0648]Steps:  97%|█████████▋| 12599/13000 [31:24<17:52,  2.67s/it, lr=2.35e-7, step_loss=0.0275]Steps:  97%|█████████▋| 12599/13000 [31:24<17:52,  2.67s/it, lr=2.35e-7, step_loss=0.0911]Steps:  97%|█████████▋| 12599/13000 [31:25<17:52,  2.67s/it, lr=2.35e-7, step_loss=0.0135]Steps:  97%|█████████▋| 12600/13000 [31:25<15:24,  2.31s/it, lr=2.35e-7, step_loss=0.0135]Steps:  97%|█████████▋| 12600/13000 [31:25<15:24,  2.31s/it, lr=2.33e-7, step_loss=0.00382]Steps:  97%|█████████▋| 12600/13000 [31:25<15:24,  2.31s/it, lr=2.33e-7, step_loss=0.364]  Steps:  97%|█████████▋| 12600/13000 [31:26<15:24,  2.31s/it, lr=2.33e-7, step_loss=0.00484]Steps:  97%|█████████▋| 12600/13000 [31:26<15:24,  2.31s/it, lr=2.33e-7, step_loss=0.151]  Steps:  97%|█████████▋| 12601/13000 [31:26<14:01,  2.11s/it, lr=2.33e-7, step_loss=0.151]Steps:  97%|█████████▋| 12601/13000 [31:27<14:01,  2.11s/it, lr=2.32e-7, step_loss=0.0301]Steps:  97%|█████████▋| 12601/13000 [31:27<14:01,  2.11s/it, lr=2.32e-7, step_loss=0.0439]Steps:  97%|█████████▋| 12601/13000 [31:27<14:01,  2.11s/it, lr=2.32e-7, step_loss=0.316] Steps:  97%|█████████▋| 12601/13000 [31:28<14:01,  2.11s/it, lr=2.32e-7, step_loss=0.128]Steps:  97%|█████████▋| 12602/13000 [31:28<12:38,  1.90s/it, lr=2.32e-7, step_loss=0.128]Steps:  97%|█████████▋| 12602/13000 [31:28<12:38,  1.90s/it, lr=2.31e-7, step_loss=0.0299]Steps:  97%|█████████▋| 12602/13000 [31:28<12:38,  1.90s/it, lr=2.31e-7, step_loss=0.0208]Steps:  97%|█████████▋| 12603/13000 [31:29<10:13,  1.55s/it, lr=2.31e-7, step_loss=0.0208]Steps:  97%|█████████▋| 12603/13000 [31:29<10:13,  1.55s/it, lr=2.3e-7, step_loss=0.00406]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.15it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.90it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.55it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.10it/s]
02/23/2025 16:14:55 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12603/13000 [31:43<10:13,  1.55s/it, lr=2.3e-7, step_loss=0.0249] Steps:  97%|█████████▋| 12603/13000 [31:43<10:13,  1.55s/it, lr=2.3e-7, step_loss=0.0702]Steps:  97%|█████████▋| 12603/13000 [31:44<10:13,  1.55s/it, lr=2.3e-7, step_loss=0.0586]Steps:  97%|█████████▋| 12604/13000 [31:44<37:40,  5.71s/it, lr=2.3e-7, step_loss=0.0586]Steps:  97%|█████████▋| 12604/13000 [31:44<37:40,  5.71s/it, lr=2.29e-7, step_loss=0.0683]Steps:  97%|█████████▋| 12604/13000 [31:44<37:40,  5.71s/it, lr=2.29e-7, step_loss=0.0656]Steps:  97%|█████████▋| 12604/13000 [31:45<37:40,  5.71s/it, lr=2.29e-7, step_loss=0.0154]Steps:  97%|█████████▋| 12604/13000 [31:45<37:40,  5.71s/it, lr=2.29e-7, step_loss=0.124] Steps:  97%|█████████▋| 12605/13000 [31:45<29:07,  4.42s/it, lr=2.29e-7, step_loss=0.124]Steps:  97%|█████████▋| 12605/13000 [31:46<29:07,  4.42s/it, lr=2.28e-7, step_loss=0.0484]Steps:  97%|█████████▋| 12605/13000 [31:46<29:07,  4.42s/it, lr=2.28e-7, step_loss=0.0167]Steps:  97%|█████████▋| 12605/13000 [31:46<29:07,  4.42s/it, lr=2.28e-7, step_loss=0.00375]Steps:  97%|█████████▋| 12605/13000 [31:47<29:07,  4.42s/it, lr=2.28e-7, step_loss=0.15]   Steps:  97%|█████████▋| 12606/13000 [31:47<23:14,  3.54s/it, lr=2.28e-7, step_loss=0.15]Steps:  97%|█████████▋| 12606/13000 [31:47<23:14,  3.54s/it, lr=2.26e-7, step_loss=0.00384]Steps:  97%|█████████▋| 12606/13000 [31:47<23:14,  3.54s/it, lr=2.26e-7, step_loss=0.126]  Steps:  97%|█████████▋| 12606/13000 [31:48<23:14,  3.54s/it, lr=2.26e-7, step_loss=0.0966]Steps:  97%|█████████▋| 12606/13000 [31:48<23:14,  3.54s/it, lr=2.26e-7, step_loss=0.00617]Steps:  97%|█████████▋| 12607/13000 [31:48<19:07,  2.92s/it, lr=2.26e-7, step_loss=0.00617]Steps:  97%|█████████▋| 12607/13000 [31:48<19:07,  2.92s/it, lr=2.25e-7, step_loss=0.141]  Steps:  97%|█████████▋| 12607/13000 [31:49<19:07,  2.92s/it, lr=2.25e-7, step_loss=0.0699]Steps:  97%|█████████▋| 12607/13000 [31:49<19:07,  2.92s/it, lr=2.25e-7, step_loss=0.316] Steps:  97%|█████████▋| 12607/13000 [31:50<19:07,  2.92s/it, lr=2.25e-7, step_loss=0.126]Steps:  97%|█████████▋| 12608/13000 [31:50<16:11,  2.48s/it, lr=2.25e-7, step_loss=0.126]Steps:  97%|█████████▋| 12608/13000 [31:50<16:11,  2.48s/it, lr=2.24e-7, step_loss=0.0885]Steps:  97%|█████████▋| 12608/13000 [31:50<16:11,  2.48s/it, lr=2.24e-7, step_loss=0.217] Steps:  97%|█████████▋| 12608/13000 [31:51<16:11,  2.48s/it, lr=2.24e-7, step_loss=0.203]Steps:  97%|█████████▋| 12608/13000 [31:51<16:11,  2.48s/it, lr=2.24e-7, step_loss=0.166]Steps:  97%|█████████▋| 12609/13000 [31:51<14:03,  2.16s/it, lr=2.24e-7, step_loss=0.166]Steps:  97%|█████████▋| 12609/13000 [31:51<14:03,  2.16s/it, lr=2.23e-7, step_loss=0.0202]Steps:  97%|█████████▋| 12609/13000 [31:52<14:03,  2.16s/it, lr=2.23e-7, step_loss=0.01]  Steps:  97%|█████████▋| 12609/13000 [31:52<14:03,  2.16s/it, lr=2.23e-7, step_loss=0.0532]Steps:  97%|█████████▋| 12609/13000 [31:52<14:03,  2.16s/it, lr=2.23e-7, step_loss=0.0048]Steps:  97%|█████████▋| 12610/13000 [31:53<12:35,  1.94s/it, lr=2.23e-7, step_loss=0.0048]Steps:  97%|█████████▋| 12610/13000 [31:53<12:35,  1.94s/it, lr=2.22e-7, step_loss=0.0678]Steps:  97%|█████████▋| 12610/13000 [31:53<12:35,  1.94s/it, lr=2.22e-7, step_loss=0.145] Steps:  97%|█████████▋| 12610/13000 [31:53<12:35,  1.94s/it, lr=2.22e-7, step_loss=0.0832]Steps:  97%|█████████▋| 12610/13000 [31:54<12:35,  1.94s/it, lr=2.22e-7, step_loss=0.0102]Steps:  97%|█████████▋| 12611/13000 [31:54<11:40,  1.80s/it, lr=2.22e-7, step_loss=0.0102]Steps:  97%|█████████▋| 12611/13000 [31:54<11:40,  1.80s/it, lr=2.21e-7, step_loss=0.0497]Steps:  97%|█████████▋| 12611/13000 [31:55<11:40,  1.80s/it, lr=2.21e-7, step_loss=0.0216]Steps:  97%|█████████▋| 12612/13000 [31:55<09:30,  1.47s/it, lr=2.21e-7, step_loss=0.0216]Steps:  97%|█████████▋| 12612/13000 [31:55<09:30,  1.47s/it, lr=2.2e-7, step_loss=0.0889] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.22it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.94it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.54it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.10it/s]
02/23/2025 16:15:21 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12612/13000 [32:09<09:30,  1.47s/it, lr=2.2e-7, step_loss=0.0775]Steps:  97%|█████████▋| 12612/13000 [32:10<09:30,  1.47s/it, lr=2.2e-7, step_loss=0.12]  Steps:  97%|█████████▋| 12612/13000 [32:10<09:30,  1.47s/it, lr=2.2e-7, step_loss=0.0589]Steps:  97%|█████████▋| 12613/13000 [32:10<36:38,  5.68s/it, lr=2.2e-7, step_loss=0.0589]Steps:  97%|█████████▋| 12613/13000 [32:10<36:38,  5.68s/it, lr=2.19e-7, step_loss=0.0095]Steps:  97%|█████████▋| 12613/13000 [32:11<36:38,  5.68s/it, lr=2.19e-7, step_loss=0.0879]Steps:  97%|█████████▋| 12613/13000 [32:11<36:38,  5.68s/it, lr=2.19e-7, step_loss=0.0461]Steps:  97%|█████████▋| 12613/13000 [32:11<36:38,  5.68s/it, lr=2.19e-7, step_loss=0.0131]Steps:  97%|█████████▋| 12614/13000 [32:12<28:23,  4.41s/it, lr=2.19e-7, step_loss=0.0131]Steps:  97%|█████████▋| 12614/13000 [32:12<28:23,  4.41s/it, lr=2.17e-7, step_loss=0.0105]Steps:  97%|█████████▋| 12614/13000 [32:12<28:23,  4.41s/it, lr=2.17e-7, step_loss=0.115] Steps:  97%|█████████▋| 12614/13000 [32:13<28:23,  4.41s/it, lr=2.17e-7, step_loss=0.0345]Steps:  97%|█████████▋| 12614/13000 [32:13<28:23,  4.41s/it, lr=2.17e-7, step_loss=0.208] Steps:  97%|█████████▋| 12615/13000 [32:13<22:32,  3.51s/it, lr=2.17e-7, step_loss=0.208]Steps:  97%|█████████▋| 12615/13000 [32:13<22:32,  3.51s/it, lr=2.16e-7, step_loss=0.0851]Steps:  97%|█████████▋| 12615/13000 [32:14<22:32,  3.51s/it, lr=2.16e-7, step_loss=0.382] Steps:  97%|█████████▋| 12615/13000 [32:14<22:32,  3.51s/it, lr=2.16e-7, step_loss=0.0614]Steps:  97%|█████████▋| 12615/13000 [32:14<22:32,  3.51s/it, lr=2.16e-7, step_loss=0.1]   Steps:  97%|█████████▋| 12616/13000 [32:15<18:34,  2.90s/it, lr=2.16e-7, step_loss=0.1]Steps:  97%|█████████▋| 12616/13000 [32:15<18:34,  2.90s/it, lr=2.15e-7, step_loss=0.0471]Steps:  97%|█████████▋| 12616/13000 [32:15<18:34,  2.90s/it, lr=2.15e-7, step_loss=0.0239]Steps:  97%|█████████▋| 12616/13000 [32:16<18:34,  2.90s/it, lr=2.15e-7, step_loss=0.0887]Steps:  97%|█████████▋| 12616/13000 [32:16<18:34,  2.90s/it, lr=2.15e-7, step_loss=0.141] Steps:  97%|█████████▋| 12617/13000 [32:16<15:46,  2.47s/it, lr=2.15e-7, step_loss=0.141]Steps:  97%|█████████▋| 12617/13000 [32:16<15:46,  2.47s/it, lr=2.14e-7, step_loss=0.0402]Steps:  97%|█████████▋| 12617/13000 [32:17<15:46,  2.47s/it, lr=2.14e-7, step_loss=0.327] Steps:  97%|█████████▋| 12617/13000 [32:17<15:46,  2.47s/it, lr=2.14e-7, step_loss=0.23] Steps:  97%|█████████▋| 12617/13000 [32:17<15:46,  2.47s/it, lr=2.14e-7, step_loss=0.0183]Steps:  97%|█████████▋| 12618/13000 [32:18<13:50,  2.17s/it, lr=2.14e-7, step_loss=0.0183]Steps:  97%|█████████▋| 12618/13000 [32:18<13:50,  2.17s/it, lr=2.13e-7, step_loss=0.227] Steps:  97%|█████████▋| 12618/13000 [32:18<13:50,  2.17s/it, lr=2.13e-7, step_loss=0.269]Steps:  97%|█████████▋| 12618/13000 [32:18<13:50,  2.17s/it, lr=2.13e-7, step_loss=0.00492]Steps:  97%|█████████▋| 12618/13000 [32:19<13:50,  2.17s/it, lr=2.13e-7, step_loss=0.102]  Steps:  97%|█████████▋| 12619/13000 [32:19<12:28,  1.96s/it, lr=2.13e-7, step_loss=0.102]Steps:  97%|█████████▋| 12619/13000 [32:20<12:28,  1.96s/it, lr=2.12e-7, step_loss=0.0407]Steps:  97%|█████████▋| 12619/13000 [32:20<12:28,  1.96s/it, lr=2.12e-7, step_loss=0.11]  Steps:  97%|█████████▋| 12619/13000 [32:21<12:28,  1.96s/it, lr=2.12e-7, step_loss=0.056]Steps:  97%|█████████▋| 12619/13000 [32:21<12:28,  1.96s/it, lr=2.12e-7, step_loss=0.397]Steps:  97%|█████████▋| 12620/13000 [32:21<12:51,  2.03s/it, lr=2.12e-7, step_loss=0.397]Steps:  97%|█████████▋| 12620/13000 [32:21<12:51,  2.03s/it, lr=2.11e-7, step_loss=0.132]Steps:  97%|█████████▋| 12620/13000 [32:22<12:51,  2.03s/it, lr=2.11e-7, step_loss=0.026]Steps:  97%|█████████▋| 12621/13000 [32:22<10:17,  1.63s/it, lr=2.11e-7, step_loss=0.026]Steps:  97%|█████████▋| 12621/13000 [32:22<10:17,  1.63s/it, lr=2.1e-7, step_loss=0.0286]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.04it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.40it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.84it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.40it/s]
02/23/2025 16:15:49 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12621/13000 [32:37<10:17,  1.63s/it, lr=2.1e-7, step_loss=0.0412]Steps:  97%|█████████▋| 12621/13000 [32:37<10:17,  1.63s/it, lr=2.1e-7, step_loss=0.165] Steps:  97%|█████████▋| 12621/13000 [32:37<10:17,  1.63s/it, lr=2.1e-7, step_loss=0.0478]Steps:  97%|█████████▋| 12622/13000 [32:38<36:53,  5.86s/it, lr=2.1e-7, step_loss=0.0478]Steps:  97%|█████████▋| 12622/13000 [32:41<36:53,  5.86s/it, lr=2.08e-7, step_loss=0.0106]Steps:  97%|█████████▋| 12622/13000 [32:41<36:53,  5.86s/it, lr=2.08e-7, step_loss=0.237] Steps:  97%|█████████▋| 12622/13000 [32:41<36:53,  5.86s/it, lr=2.08e-7, step_loss=0.0125]Steps:  97%|█████████▋| 12622/13000 [32:42<36:53,  5.86s/it, lr=2.08e-7, step_loss=0.00553]Steps:  97%|█████████▋| 12623/13000 [32:42<33:39,  5.36s/it, lr=2.08e-7, step_loss=0.00553]Steps:  97%|█████████▋| 12623/13000 [32:45<33:39,  5.36s/it, lr=2.07e-7, step_loss=0.281]  Steps:  97%|█████████▋| 12623/13000 [32:45<33:39,  5.36s/it, lr=2.07e-7, step_loss=0.0256]Steps:  97%|█████████▋| 12623/13000 [32:46<33:39,  5.36s/it, lr=2.07e-7, step_loss=0.00867]Steps:  97%|█████████▋| 12623/13000 [32:46<33:39,  5.36s/it, lr=2.07e-7, step_loss=0.0817] Steps:  97%|█████████▋| 12624/13000 [32:48<35:00,  5.59s/it, lr=2.07e-7, step_loss=0.0817]Steps:  97%|█████████▋| 12624/13000 [32:48<35:00,  5.59s/it, lr=2.06e-7, step_loss=0.0534]Steps:  97%|█████████▋| 12624/13000 [32:48<35:00,  5.59s/it, lr=2.06e-7, step_loss=0.0049]Steps:  97%|█████████▋| 12624/13000 [32:49<35:00,  5.59s/it, lr=2.06e-7, step_loss=0.0124]Steps:  97%|█████████▋| 12624/13000 [32:49<35:00,  5.59s/it, lr=2.06e-7, step_loss=0.0102]Steps:  97%|█████████▋| 12625/13000 [32:50<27:13,  4.36s/it, lr=2.06e-7, step_loss=0.0102]Steps:  97%|█████████▋| 12625/13000 [32:50<27:13,  4.36s/it, lr=2.05e-7, step_loss=0.0527]Steps:  97%|█████████▋| 12625/13000 [32:50<27:13,  4.36s/it, lr=2.05e-7, step_loss=0.0489]Steps:  97%|█████████▋| 12625/13000 [32:50<27:13,  4.36s/it, lr=2.05e-7, step_loss=0.00509]Steps:  97%|█████████▋| 12625/13000 [32:51<27:13,  4.36s/it, lr=2.05e-7, step_loss=0.00339]Steps:  97%|█████████▋| 12626/13000 [32:51<21:43,  3.48s/it, lr=2.05e-7, step_loss=0.00339]Steps:  97%|█████████▋| 12626/13000 [32:51<21:43,  3.48s/it, lr=2.04e-7, step_loss=0.139]  Steps:  97%|█████████▋| 12626/13000 [32:51<21:43,  3.48s/it, lr=2.04e-7, step_loss=0.136]Steps:  97%|█████████▋| 12626/13000 [32:52<21:43,  3.48s/it, lr=2.04e-7, step_loss=0.382]Steps:  97%|█████████▋| 12626/13000 [32:52<21:43,  3.48s/it, lr=2.04e-7, step_loss=0.158]Steps:  97%|█████████▋| 12627/13000 [32:52<17:52,  2.87s/it, lr=2.04e-7, step_loss=0.158]Steps:  97%|█████████▋| 12627/13000 [32:52<17:52,  2.87s/it, lr=2.03e-7, step_loss=0.21] Steps:  97%|█████████▋| 12627/13000 [32:53<17:52,  2.87s/it, lr=2.03e-7, step_loss=0.0233]Steps:  97%|█████████▋| 12627/13000 [32:53<17:52,  2.87s/it, lr=2.03e-7, step_loss=0.0106]Steps:  97%|█████████▋| 12627/13000 [32:54<17:52,  2.87s/it, lr=2.03e-7, step_loss=0.267] Steps:  97%|█████████▋| 12628/13000 [32:54<15:16,  2.46s/it, lr=2.03e-7, step_loss=0.267]Steps:  97%|█████████▋| 12628/13000 [32:54<15:16,  2.46s/it, lr=2.02e-7, step_loss=0.00566]Steps:  97%|█████████▋| 12628/13000 [32:54<15:16,  2.46s/it, lr=2.02e-7, step_loss=0.0406] Steps:  97%|█████████▋| 12628/13000 [32:55<15:16,  2.46s/it, lr=2.02e-7, step_loss=0.0828]Steps:  97%|█████████▋| 12628/13000 [32:55<15:16,  2.46s/it, lr=2.02e-7, step_loss=0.139] Steps:  97%|█████████▋| 12629/13000 [32:55<13:20,  2.16s/it, lr=2.02e-7, step_loss=0.139]Steps:  97%|█████████▋| 12629/13000 [32:55<13:20,  2.16s/it, lr=2.01e-7, step_loss=0.121]Steps:  97%|█████████▋| 12629/13000 [32:56<13:20,  2.16s/it, lr=2.01e-7, step_loss=0.619]Steps:  97%|█████████▋| 12630/13000 [32:56<10:36,  1.72s/it, lr=2.01e-7, step_loss=0.619]Steps:  97%|█████████▋| 12630/13000 [32:56<10:36,  1.72s/it, lr=2e-7, step_loss=0.025]   {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00,  9.91it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.81it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.86it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.26it/s]
02/23/2025 16:16:23 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12630/13000 [33:11<10:36,  1.72s/it, lr=2e-7, step_loss=0.0196]Steps:  97%|█████████▋| 12630/13000 [33:11<10:36,  1.72s/it, lr=2e-7, step_loss=0.0218]Steps:  97%|█████████▋| 12630/13000 [33:12<10:36,  1.72s/it, lr=2e-7, step_loss=0.0392]Steps:  97%|█████████▋| 12631/13000 [33:12<36:26,  5.92s/it, lr=2e-7, step_loss=0.0392]Steps:  97%|█████████▋| 12631/13000 [33:12<36:26,  5.92s/it, lr=1.99e-7, step_loss=0.00354]Steps:  97%|█████████▋| 12631/13000 [33:12<36:26,  5.92s/it, lr=1.99e-7, step_loss=0.0507] Steps:  97%|█████████▋| 12631/13000 [33:13<36:26,  5.92s/it, lr=1.99e-7, step_loss=0.00856]Steps:  97%|█████████▋| 12631/13000 [33:14<36:26,  5.92s/it, lr=1.99e-7, step_loss=0.261]  Steps:  97%|█████████▋| 12632/13000 [33:14<29:34,  4.82s/it, lr=1.99e-7, step_loss=0.261]Steps:  97%|█████████▋| 12632/13000 [33:14<29:34,  4.82s/it, lr=1.98e-7, step_loss=0.553]Steps:  97%|█████████▋| 12632/13000 [33:14<29:34,  4.82s/it, lr=1.98e-7, step_loss=0.00456]Steps:  97%|█████████▋| 12632/13000 [33:15<29:34,  4.82s/it, lr=1.98e-7, step_loss=0.296]  Steps:  97%|█████████▋| 12632/13000 [33:15<29:34,  4.82s/it, lr=1.98e-7, step_loss=0.176]Steps:  97%|█████████▋| 12633/13000 [33:16<23:19,  3.81s/it, lr=1.98e-7, step_loss=0.176]Steps:  97%|█████████▋| 12633/13000 [33:17<23:19,  3.81s/it, lr=1.97e-7, step_loss=0.218]Steps:  97%|█████████▋| 12633/13000 [33:18<23:19,  3.81s/it, lr=1.97e-7, step_loss=0.198]Steps:  97%|█████████▋| 12633/13000 [33:18<23:19,  3.81s/it, lr=1.97e-7, step_loss=0.0118]Steps:  97%|█████████▋| 12633/13000 [33:19<23:19,  3.81s/it, lr=1.97e-7, step_loss=0.0399]Steps:  97%|█████████▋| 12634/13000 [33:19<22:30,  3.69s/it, lr=1.97e-7, step_loss=0.0399]Steps:  97%|█████████▋| 12634/13000 [33:19<22:30,  3.69s/it, lr=1.95e-7, step_loss=0.0587]Steps:  97%|█████████▋| 12634/13000 [33:19<22:30,  3.69s/it, lr=1.95e-7, step_loss=0.178] Steps:  97%|█████████▋| 12634/13000 [33:20<22:30,  3.69s/it, lr=1.95e-7, step_loss=0.0188]Steps:  97%|█████████▋| 12634/13000 [33:20<22:30,  3.69s/it, lr=1.95e-7, step_loss=0.178] Steps:  97%|█████████▋| 12635/13000 [33:20<18:15,  3.00s/it, lr=1.95e-7, step_loss=0.178]Steps:  97%|█████████▋| 12635/13000 [33:20<18:15,  3.00s/it, lr=1.94e-7, step_loss=0.0315]Steps:  97%|█████████▋| 12635/13000 [33:21<18:15,  3.00s/it, lr=1.94e-7, step_loss=0.0198]Steps:  97%|█████████▋| 12635/13000 [33:21<18:15,  3.00s/it, lr=1.94e-7, step_loss=0.0934]Steps:  97%|█████████▋| 12635/13000 [33:21<18:15,  3.00s/it, lr=1.94e-7, step_loss=0.00333]Steps:  97%|█████████▋| 12636/13000 [33:22<15:24,  2.54s/it, lr=1.94e-7, step_loss=0.00333]Steps:  97%|█████████▋| 12636/13000 [33:22<15:24,  2.54s/it, lr=1.93e-7, step_loss=0.143]  Steps:  97%|█████████▋| 12636/13000 [33:22<15:24,  2.54s/it, lr=1.93e-7, step_loss=0.0621]Steps:  97%|█████████▋| 12636/13000 [33:23<15:24,  2.54s/it, lr=1.93e-7, step_loss=0.456] Steps:  97%|█████████▋| 12636/13000 [33:24<15:24,  2.54s/it, lr=1.93e-7, step_loss=0.0241]Steps:  97%|█████████▋| 12637/13000 [33:24<15:24,  2.55s/it, lr=1.93e-7, step_loss=0.0241]Steps:  97%|█████████▋| 12637/13000 [33:24<15:24,  2.55s/it, lr=1.92e-7, step_loss=0.0494]Steps:  97%|█████████▋| 12637/13000 [33:25<15:24,  2.55s/it, lr=1.92e-7, step_loss=0.00312]Steps:  97%|█████████▋| 12637/13000 [33:25<15:24,  2.55s/it, lr=1.92e-7, step_loss=0.138]  Steps:  97%|█████████▋| 12637/13000 [33:26<15:24,  2.55s/it, lr=1.92e-7, step_loss=0.273]Steps:  97%|█████████▋| 12638/13000 [33:26<13:24,  2.22s/it, lr=1.92e-7, step_loss=0.273]Steps:  97%|█████████▋| 12638/13000 [33:26<13:24,  2.22s/it, lr=1.91e-7, step_loss=0.0319]Steps:  97%|█████████▋| 12638/13000 [33:26<13:24,  2.22s/it, lr=1.91e-7, step_loss=0.0373]Steps:  97%|█████████▋| 12639/13000 [33:27<10:39,  1.77s/it, lr=1.91e-7, step_loss=0.0373]Steps:  97%|█████████▋| 12639/13000 [33:27<10:39,  1.77s/it, lr=1.9e-7, step_loss=0.105]  {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.29it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.20it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.71it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.28it/s]
02/23/2025 16:16:53 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12639/13000 [33:41<10:39,  1.77s/it, lr=1.9e-7, step_loss=0.183]Steps:  97%|█████████▋| 12639/13000 [33:41<10:39,  1.77s/it, lr=1.9e-7, step_loss=0.283]Steps:  97%|█████████▋| 12639/13000 [33:42<10:39,  1.77s/it, lr=1.9e-7, step_loss=0.0366]Steps:  97%|█████████▋| 12640/13000 [33:42<35:16,  5.88s/it, lr=1.9e-7, step_loss=0.0366]Steps:  97%|█████████▋| 12640/13000 [33:42<35:16,  5.88s/it, lr=1.89e-7, step_loss=0.0722]Steps:  97%|█████████▋| 12640/13000 [33:42<35:16,  5.88s/it, lr=1.89e-7, step_loss=0.0611]Steps:  97%|█████████▋| 12640/13000 [33:43<35:16,  5.88s/it, lr=1.89e-7, step_loss=0.0685]Steps:  97%|█████████▋| 12640/13000 [33:43<35:16,  5.88s/it, lr=1.89e-7, step_loss=0.0474]Steps:  97%|█████████▋| 12641/13000 [33:43<27:14,  4.55s/it, lr=1.89e-7, step_loss=0.0474]Steps:  97%|█████████▋| 12641/13000 [33:44<27:14,  4.55s/it, lr=1.88e-7, step_loss=0.0794]Steps:  97%|█████████▋| 12641/13000 [33:44<27:14,  4.55s/it, lr=1.88e-7, step_loss=0.172] Steps:  97%|█████████▋| 12641/13000 [33:44<27:14,  4.55s/it, lr=1.88e-7, step_loss=0.163]Steps:  97%|█████████▋| 12641/13000 [33:45<27:14,  4.55s/it, lr=1.88e-7, step_loss=0.213]Steps:  97%|█████████▋| 12642/13000 [33:45<21:39,  3.63s/it, lr=1.88e-7, step_loss=0.213]Steps:  97%|█████████▋| 12642/13000 [33:45<21:39,  3.63s/it, lr=1.87e-7, step_loss=0.0338]Steps:  97%|█████████▋| 12642/13000 [33:45<21:39,  3.63s/it, lr=1.87e-7, step_loss=0.0641]Steps:  97%|█████████▋| 12642/13000 [33:46<21:39,  3.63s/it, lr=1.87e-7, step_loss=0.383] Steps:  97%|█████████▋| 12642/13000 [33:46<21:39,  3.63s/it, lr=1.87e-7, step_loss=0.0729]Steps:  97%|█████████▋| 12643/13000 [33:46<17:40,  2.97s/it, lr=1.87e-7, step_loss=0.0729]Steps:  97%|█████████▋| 12643/13000 [33:47<17:40,  2.97s/it, lr=1.86e-7, step_loss=0.018] Steps:  97%|█████████▋| 12643/13000 [33:48<17:40,  2.97s/it, lr=1.86e-7, step_loss=0.00452]Steps:  97%|█████████▋| 12643/13000 [33:48<17:40,  2.97s/it, lr=1.86e-7, step_loss=0.00468]Steps:  97%|█████████▋| 12643/13000 [33:49<17:40,  2.97s/it, lr=1.86e-7, step_loss=0.0522] Steps:  97%|█████████▋| 12644/13000 [33:49<16:39,  2.81s/it, lr=1.86e-7, step_loss=0.0522]Steps:  97%|█████████▋| 12644/13000 [33:49<16:39,  2.81s/it, lr=1.85e-7, step_loss=0.219] Steps:  97%|█████████▋| 12644/13000 [33:49<16:39,  2.81s/it, lr=1.85e-7, step_loss=0.198]Steps:  97%|█████████▋| 12644/13000 [33:50<16:39,  2.81s/it, lr=1.85e-7, step_loss=0.117]Steps:  97%|█████████▋| 12644/13000 [33:50<16:39,  2.81s/it, lr=1.85e-7, step_loss=0.0945]Steps:  97%|█████████▋| 12645/13000 [33:50<14:13,  2.40s/it, lr=1.85e-7, step_loss=0.0945]Steps:  97%|█████████▋| 12645/13000 [33:50<14:13,  2.40s/it, lr=1.84e-7, step_loss=0.0943]Steps:  97%|█████████▋| 12645/13000 [33:51<14:13,  2.40s/it, lr=1.84e-7, step_loss=0.0467]Steps:  97%|█████████▋| 12645/13000 [33:51<14:13,  2.40s/it, lr=1.84e-7, step_loss=0.0658]Steps:  97%|█████████▋| 12645/13000 [33:51<14:13,  2.40s/it, lr=1.84e-7, step_loss=0.0195]Steps:  97%|█████████▋| 12646/13000 [33:52<12:30,  2.12s/it, lr=1.84e-7, step_loss=0.0195]Steps:  97%|█████████▋| 12646/13000 [33:52<12:30,  2.12s/it, lr=1.83e-7, step_loss=0.0195]Steps:  97%|█████████▋| 12646/13000 [33:52<12:30,  2.12s/it, lr=1.83e-7, step_loss=0.00433]Steps:  97%|█████████▋| 12646/13000 [33:52<12:30,  2.12s/it, lr=1.83e-7, step_loss=0.0176] Steps:  97%|█████████▋| 12646/13000 [33:53<12:30,  2.12s/it, lr=1.83e-7, step_loss=0.126] Steps:  97%|█████████▋| 12647/13000 [33:53<11:17,  1.92s/it, lr=1.83e-7, step_loss=0.126]Steps:  97%|█████████▋| 12647/13000 [33:53<11:17,  1.92s/it, lr=1.82e-7, step_loss=0.0343]Steps:  97%|█████████▋| 12647/13000 [33:54<11:17,  1.92s/it, lr=1.82e-7, step_loss=0.217] Steps:  97%|█████████▋| 12648/13000 [33:54<09:06,  1.55s/it, lr=1.82e-7, step_loss=0.217]Steps:  97%|█████████▋| 12648/13000 [33:54<09:06,  1.55s/it, lr=1.81e-7, step_loss=0.0743]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.06it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.40it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.76it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.33it/s]
02/23/2025 16:17:20 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12648/13000 [34:08<09:06,  1.55s/it, lr=1.81e-7, step_loss=0.00627]Steps:  97%|█████████▋| 12648/13000 [34:09<09:06,  1.55s/it, lr=1.81e-7, step_loss=0.354]  Steps:  97%|█████████▋| 12648/13000 [34:09<09:06,  1.55s/it, lr=1.81e-7, step_loss=0.154]Steps:  97%|█████████▋| 12649/13000 [34:10<33:53,  5.79s/it, lr=1.81e-7, step_loss=0.154]Steps:  97%|█████████▋| 12649/13000 [34:10<33:53,  5.79s/it, lr=1.8e-7, step_loss=0.0386]Steps:  97%|█████████▋| 12649/13000 [34:10<33:53,  5.79s/it, lr=1.8e-7, step_loss=0.113] Steps:  97%|█████████▋| 12649/13000 [34:10<33:53,  5.79s/it, lr=1.8e-7, step_loss=0.0754]Steps:  97%|█████████▋| 12649/13000 [34:11<33:53,  5.79s/it, lr=1.8e-7, step_loss=0.216] Steps:  97%|█████████▋| 12650/13000 [34:11<26:10,  4.49s/it, lr=1.8e-7, step_loss=0.216]Steps:  97%|█████████▋| 12650/13000 [34:11<26:10,  4.49s/it, lr=1.79e-7, step_loss=0.331]Steps:  97%|█████████▋| 12650/13000 [34:11<26:10,  4.49s/it, lr=1.79e-7, step_loss=0.0929]Steps:  97%|█████████▋| 12650/13000 [34:12<26:10,  4.49s/it, lr=1.79e-7, step_loss=0.121] Steps:  97%|█████████▋| 12650/13000 [34:12<26:10,  4.49s/it, lr=1.79e-7, step_loss=0.0082]Steps:  97%|█████████▋| 12651/13000 [34:12<20:48,  3.58s/it, lr=1.79e-7, step_loss=0.0082]Steps:  97%|█████████▋| 12651/13000 [34:12<20:48,  3.58s/it, lr=1.78e-7, step_loss=0.0655]Steps:  97%|█████████▋| 12651/13000 [34:13<20:48,  3.58s/it, lr=1.78e-7, step_loss=0.133] Steps:  97%|█████████▋| 12651/13000 [34:13<20:48,  3.58s/it, lr=1.78e-7, step_loss=0.019]Steps:  97%|█████████▋| 12651/13000 [34:14<20:48,  3.58s/it, lr=1.78e-7, step_loss=0.107]Steps:  97%|█████████▋| 12652/13000 [34:14<17:06,  2.95s/it, lr=1.78e-7, step_loss=0.107]Steps:  97%|█████████▋| 12652/13000 [34:14<17:06,  2.95s/it, lr=1.77e-7, step_loss=0.00647]Steps:  97%|█████████▋| 12652/13000 [34:14<17:06,  2.95s/it, lr=1.77e-7, step_loss=0.354]  Steps:  97%|█████████▋| 12652/13000 [34:15<17:06,  2.95s/it, lr=1.77e-7, step_loss=0.00321]Steps:  97%|█████████▋| 12652/13000 [34:15<17:06,  2.95s/it, lr=1.77e-7, step_loss=0.0362] Steps:  97%|█████████▋| 12653/13000 [34:15<14:27,  2.50s/it, lr=1.77e-7, step_loss=0.0362]Steps:  97%|█████████▋| 12653/13000 [34:15<14:27,  2.50s/it, lr=1.76e-7, step_loss=0.142] Steps:  97%|█████████▋| 12653/13000 [34:16<14:27,  2.50s/it, lr=1.76e-7, step_loss=0.0571]Steps:  97%|█████████▋| 12653/13000 [34:16<14:27,  2.50s/it, lr=1.76e-7, step_loss=0.0285]Steps:  97%|█████████▋| 12653/13000 [34:17<14:27,  2.50s/it, lr=1.76e-7, step_loss=0.0575]Steps:  97%|█████████▋| 12654/13000 [34:17<12:35,  2.18s/it, lr=1.76e-7, step_loss=0.0575]Steps:  97%|█████████▋| 12654/13000 [34:17<12:35,  2.18s/it, lr=1.75e-7, step_loss=0.0707]Steps:  97%|█████████▋| 12654/13000 [34:17<12:35,  2.18s/it, lr=1.75e-7, step_loss=0.00579]Steps:  97%|█████████▋| 12654/13000 [34:18<12:35,  2.18s/it, lr=1.75e-7, step_loss=0.0324] Steps:  97%|█████████▋| 12654/13000 [34:18<12:35,  2.18s/it, lr=1.75e-7, step_loss=0.0207]Steps:  97%|█████████▋| 12655/13000 [34:18<11:15,  1.96s/it, lr=1.75e-7, step_loss=0.0207]Steps:  97%|█████████▋| 12655/13000 [34:18<11:15,  1.96s/it, lr=1.74e-7, step_loss=0.883] Steps:  97%|█████████▋| 12655/13000 [34:19<11:15,  1.96s/it, lr=1.74e-7, step_loss=0.366]Steps:  97%|█████████▋| 12655/13000 [34:19<11:15,  1.96s/it, lr=1.74e-7, step_loss=0.184]Steps:  97%|█████████▋| 12655/13000 [34:19<11:15,  1.96s/it, lr=1.74e-7, step_loss=0.00563]Steps:  97%|█████████▋| 12656/13000 [34:20<10:22,  1.81s/it, lr=1.74e-7, step_loss=0.00563]Steps:  97%|█████████▋| 12656/13000 [34:20<10:22,  1.81s/it, lr=1.73e-7, step_loss=0.0724] Steps:  97%|█████████▋| 12656/13000 [34:20<10:22,  1.81s/it, lr=1.73e-7, step_loss=0.42]  Steps:  97%|█████████▋| 12657/13000 [34:20<08:26,  1.48s/it, lr=1.73e-7, step_loss=0.42]Steps:  97%|█████████▋| 12657/13000 [34:20<08:26,  1.48s/it, lr=1.72e-7, step_loss=0.00587]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.25it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.43it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.76it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.35it/s]
02/23/2025 16:17:47 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12657/13000 [34:35<08:26,  1.48s/it, lr=1.72e-7, step_loss=0.0718] Steps:  97%|█████████▋| 12657/13000 [34:35<08:26,  1.48s/it, lr=1.72e-7, step_loss=0.379] Steps:  97%|█████████▋| 12657/13000 [34:36<08:26,  1.48s/it, lr=1.72e-7, step_loss=0.0211]Steps:  97%|█████████▋| 12658/13000 [34:36<32:17,  5.67s/it, lr=1.72e-7, step_loss=0.0211]Steps:  97%|█████████▋| 12658/13000 [34:36<32:17,  5.67s/it, lr=1.71e-7, step_loss=0.0498]Steps:  97%|█████████▋| 12658/13000 [34:36<32:17,  5.67s/it, lr=1.71e-7, step_loss=0.192] Steps:  97%|█████████▋| 12658/13000 [34:37<32:17,  5.67s/it, lr=1.71e-7, step_loss=0.0237]Steps:  97%|█████████▋| 12658/13000 [34:37<32:17,  5.67s/it, lr=1.71e-7, step_loss=0.0222]Steps:  97%|█████████▋| 12659/13000 [34:37<24:59,  4.40s/it, lr=1.71e-7, step_loss=0.0222]Steps:  97%|█████████▋| 12659/13000 [34:37<24:59,  4.40s/it, lr=1.7e-7, step_loss=0.0126] Steps:  97%|█████████▋| 12659/13000 [34:38<24:59,  4.40s/it, lr=1.7e-7, step_loss=0.0996]Steps:  97%|█████████▋| 12659/13000 [34:38<24:59,  4.40s/it, lr=1.7e-7, step_loss=0.0265]Steps:  97%|█████████▋| 12659/13000 [34:38<24:59,  4.40s/it, lr=1.7e-7, step_loss=0.00797]Steps:  97%|█████████▋| 12660/13000 [34:39<19:52,  3.51s/it, lr=1.7e-7, step_loss=0.00797]Steps:  97%|█████████▋| 12660/13000 [34:39<19:52,  3.51s/it, lr=1.69e-7, step_loss=0.00671]Steps:  97%|█████████▋| 12660/13000 [34:39<19:52,  3.51s/it, lr=1.69e-7, step_loss=0.0412] Steps:  97%|█████████▋| 12660/13000 [34:40<19:52,  3.51s/it, lr=1.69e-7, step_loss=0.0674]Steps:  97%|█████████▋| 12660/13000 [34:40<19:52,  3.51s/it, lr=1.69e-7, step_loss=0.00568]Steps:  97%|█████████▋| 12661/13000 [34:40<16:20,  2.89s/it, lr=1.69e-7, step_loss=0.00568]Steps:  97%|█████████▋| 12661/13000 [34:40<16:20,  2.89s/it, lr=1.68e-7, step_loss=0.0626] Steps:  97%|█████████▋| 12661/13000 [34:41<16:20,  2.89s/it, lr=1.68e-7, step_loss=0.0414]Steps:  97%|█████████▋| 12661/13000 [34:41<16:20,  2.89s/it, lr=1.68e-7, step_loss=0.243] Steps:  97%|█████████▋| 12661/13000 [34:41<16:20,  2.89s/it, lr=1.68e-7, step_loss=0.0111]Steps:  97%|█████████▋| 12662/13000 [34:42<13:52,  2.46s/it, lr=1.68e-7, step_loss=0.0111]Steps:  97%|█████████▋| 12662/13000 [34:42<13:52,  2.46s/it, lr=1.67e-7, step_loss=0.0606]Steps:  97%|█████████▋| 12662/13000 [34:42<13:52,  2.46s/it, lr=1.67e-7, step_loss=0.22]  Steps:  97%|█████████▋| 12662/13000 [34:42<13:52,  2.46s/it, lr=1.67e-7, step_loss=0.0576]Steps:  97%|█████████▋| 12662/13000 [34:43<13:52,  2.46s/it, lr=1.67e-7, step_loss=0.0379]Steps:  97%|█████████▋| 12663/13000 [34:43<12:09,  2.17s/it, lr=1.67e-7, step_loss=0.0379]Steps:  97%|█████████▋| 12663/13000 [34:43<12:09,  2.17s/it, lr=1.66e-7, step_loss=0.00445]Steps:  97%|█████████▋| 12663/13000 [34:44<12:09,  2.17s/it, lr=1.66e-7, step_loss=0.0392] Steps:  97%|█████████▋| 12663/13000 [34:44<12:09,  2.17s/it, lr=1.66e-7, step_loss=0.0178]Steps:  97%|█████████▋| 12663/13000 [34:44<12:09,  2.17s/it, lr=1.66e-7, step_loss=0.115] Steps:  97%|█████████▋| 12664/13000 [34:45<10:52,  1.94s/it, lr=1.66e-7, step_loss=0.115]Steps:  97%|█████████▋| 12664/13000 [34:45<10:52,  1.94s/it, lr=1.65e-7, step_loss=0.0826]Steps:  97%|█████████▋| 12664/13000 [34:45<10:52,  1.94s/it, lr=1.65e-7, step_loss=0.0527]Steps:  97%|█████████▋| 12664/13000 [34:45<10:52,  1.94s/it, lr=1.65e-7, step_loss=0.0873]Steps:  97%|█████████▋| 12664/13000 [34:46<10:52,  1.94s/it, lr=1.65e-7, step_loss=0.196] Steps:  97%|█████████▋| 12665/13000 [34:46<10:05,  1.81s/it, lr=1.65e-7, step_loss=0.196]Steps:  97%|█████████▋| 12665/13000 [34:46<10:05,  1.81s/it, lr=1.64e-7, step_loss=0.0598]Steps:  97%|█████████▋| 12665/13000 [34:46<10:05,  1.81s/it, lr=1.64e-7, step_loss=0.104] Steps:  97%|█████████▋| 12666/13000 [34:47<08:12,  1.47s/it, lr=1.64e-7, step_loss=0.104]Steps:  97%|█████████▋| 12666/13000 [34:47<08:12,  1.47s/it, lr=1.63e-7, step_loss=0.153]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.35it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.91it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.59it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.15it/s]
02/23/2025 16:18:13 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  97%|█████████▋| 12666/13000 [35:01<08:12,  1.47s/it, lr=1.63e-7, step_loss=0.308]Steps:  97%|█████████▋| 12666/13000 [35:02<08:12,  1.47s/it, lr=1.63e-7, step_loss=0.0921]Steps:  97%|█████████▋| 12666/13000 [35:02<08:12,  1.47s/it, lr=1.63e-7, step_loss=0.305] Steps:  97%|█████████▋| 12667/13000 [35:02<31:38,  5.70s/it, lr=1.63e-7, step_loss=0.305]Steps:  97%|█████████▋| 12667/13000 [35:02<31:38,  5.70s/it, lr=1.62e-7, step_loss=0.00396]Steps:  97%|█████████▋| 12667/13000 [35:03<31:38,  5.70s/it, lr=1.62e-7, step_loss=0.0764] Steps:  97%|█████████▋| 12667/13000 [35:05<31:38,  5.70s/it, lr=1.62e-7, step_loss=0.133] Steps:  97%|█████████▋| 12667/13000 [35:05<31:38,  5.70s/it, lr=1.62e-7, step_loss=0.048]Steps:  97%|█████████▋| 12668/13000 [35:06<27:44,  5.01s/it, lr=1.62e-7, step_loss=0.048]Steps:  97%|█████████▋| 12668/13000 [35:06<27:44,  5.01s/it, lr=1.61e-7, step_loss=0.0707]Steps:  97%|█████████▋| 12668/13000 [35:06<27:44,  5.01s/it, lr=1.61e-7, step_loss=0.0337]Steps:  97%|█████████▋| 12668/13000 [35:06<27:44,  5.01s/it, lr=1.61e-7, step_loss=0.0896]Steps:  97%|█████████▋| 12668/13000 [35:07<27:44,  5.01s/it, lr=1.61e-7, step_loss=0.072] Steps:  97%|█████████▋| 12669/13000 [35:07<21:43,  3.94s/it, lr=1.61e-7, step_loss=0.072]Steps:  97%|█████████▋| 12669/13000 [35:07<21:43,  3.94s/it, lr=1.6e-7, step_loss=0.126] Steps:  97%|█████████▋| 12669/13000 [35:08<21:43,  3.94s/it, lr=1.6e-7, step_loss=0.215]Steps:  97%|█████████▋| 12669/13000 [35:08<21:43,  3.94s/it, lr=1.6e-7, step_loss=0.112]Steps:  97%|█████████▋| 12669/13000 [35:08<21:43,  3.94s/it, lr=1.6e-7, step_loss=0.31] Steps:  97%|█████████▋| 12670/13000 [35:09<17:34,  3.19s/it, lr=1.6e-7, step_loss=0.31]Steps:  97%|█████████▋| 12670/13000 [35:09<17:34,  3.19s/it, lr=1.59e-7, step_loss=0.00923]Steps:  97%|█████████▋| 12670/13000 [35:09<17:34,  3.19s/it, lr=1.59e-7, step_loss=0.127]  Steps:  97%|█████████▋| 12670/13000 [35:09<17:34,  3.19s/it, lr=1.59e-7, step_loss=0.0124]Steps:  97%|█████████▋| 12670/13000 [35:10<17:34,  3.19s/it, lr=1.59e-7, step_loss=0.087] Steps:  97%|█████████▋| 12671/13000 [35:11<15:56,  2.91s/it, lr=1.59e-7, step_loss=0.087]Steps:  97%|█████████▋| 12671/13000 [35:11<15:56,  2.91s/it, lr=1.58e-7, step_loss=0.129]Steps:  97%|█████████▋| 12671/13000 [35:11<15:56,  2.91s/it, lr=1.58e-7, step_loss=0.0195]Steps:  97%|█████████▋| 12671/13000 [35:12<15:56,  2.91s/it, lr=1.58e-7, step_loss=0.0465]Steps:  97%|█████████▋| 12671/13000 [35:12<15:56,  2.91s/it, lr=1.58e-7, step_loss=0.588] Steps:  97%|█████████▋| 12672/13000 [35:12<13:35,  2.48s/it, lr=1.58e-7, step_loss=0.588]Steps:  97%|█████████▋| 12672/13000 [35:12<13:35,  2.48s/it, lr=1.57e-7, step_loss=0.0508]Steps:  97%|█████████▋| 12672/13000 [35:13<13:35,  2.48s/it, lr=1.57e-7, step_loss=0.165] Steps:  97%|█████████▋| 12672/13000 [35:13<13:35,  2.48s/it, lr=1.57e-7, step_loss=0.00593]Steps:  97%|█████████▋| 12672/13000 [35:14<13:35,  2.48s/it, lr=1.57e-7, step_loss=0.249]  Steps:  97%|█████████▋| 12673/13000 [35:14<11:56,  2.19s/it, lr=1.57e-7, step_loss=0.249]Steps:  97%|█████████▋| 12673/13000 [35:14<11:56,  2.19s/it, lr=1.56e-7, step_loss=0.0467]Steps:  97%|█████████▋| 12673/13000 [35:14<11:56,  2.19s/it, lr=1.56e-7, step_loss=0.397] Steps:  97%|█████████▋| 12673/13000 [35:15<11:56,  2.19s/it, lr=1.56e-7, step_loss=0.032]Steps:  97%|█████████▋| 12673/13000 [35:15<11:56,  2.19s/it, lr=1.56e-7, step_loss=0.0176]Steps:  97%|█████████▋| 12674/13000 [35:15<10:41,  1.97s/it, lr=1.56e-7, step_loss=0.0176]Steps:  97%|█████████▋| 12674/13000 [35:15<10:41,  1.97s/it, lr=1.55e-7, step_loss=0.0718]Steps:  97%|█████████▋| 12674/13000 [35:16<10:41,  1.97s/it, lr=1.55e-7, step_loss=0.214] Steps:  98%|█████████▊| 12675/13000 [35:16<08:34,  1.58s/it, lr=1.55e-7, step_loss=0.214]Steps:  98%|█████████▊| 12675/13000 [35:16<08:34,  1.58s/it, lr=1.54e-7, step_loss=0.0251]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.36it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.04it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.19it/s]
02/23/2025 16:18:43 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12675/13000 [35:30<08:34,  1.58s/it, lr=1.54e-7, step_loss=0.202] Steps:  98%|█████████▊| 12675/13000 [35:31<08:34,  1.58s/it, lr=1.54e-7, step_loss=0.457]Steps:  98%|█████████▊| 12675/13000 [35:31<08:34,  1.58s/it, lr=1.54e-7, step_loss=0.0391]Steps:  98%|█████████▊| 12676/13000 [35:31<30:59,  5.74s/it, lr=1.54e-7, step_loss=0.0391]Steps:  98%|█████████▊| 12676/13000 [35:34<30:59,  5.74s/it, lr=1.53e-7, step_loss=0.0626]Steps:  98%|█████████▊| 12676/13000 [35:34<30:59,  5.74s/it, lr=1.53e-7, step_loss=0.285] Steps:  98%|█████████▊| 12676/13000 [35:34<30:59,  5.74s/it, lr=1.53e-7, step_loss=0.0503]Steps:  98%|█████████▊| 12676/13000 [35:35<30:59,  5.74s/it, lr=1.53e-7, step_loss=0.158] Steps:  98%|█████████▊| 12677/13000 [35:35<27:34,  5.12s/it, lr=1.53e-7, step_loss=0.158]Steps:  98%|█████████▊| 12677/13000 [35:35<27:34,  5.12s/it, lr=1.52e-7, step_loss=0.0765]Steps:  98%|█████████▊| 12677/13000 [35:35<27:34,  5.12s/it, lr=1.52e-7, step_loss=0.0145]Steps:  98%|█████████▊| 12677/13000 [35:36<27:34,  5.12s/it, lr=1.52e-7, step_loss=0.00631]Steps:  98%|█████████▊| 12677/13000 [35:36<27:34,  5.12s/it, lr=1.52e-7, step_loss=0.266]  Steps:  98%|█████████▊| 12678/13000 [35:37<21:36,  4.03s/it, lr=1.52e-7, step_loss=0.266]Steps:  98%|█████████▊| 12678/13000 [35:37<21:36,  4.03s/it, lr=1.51e-7, step_loss=0.0384]Steps:  98%|█████████▊| 12678/13000 [35:37<21:36,  4.03s/it, lr=1.51e-7, step_loss=0.0194]Steps:  98%|█████████▊| 12678/13000 [35:37<21:36,  4.03s/it, lr=1.51e-7, step_loss=0.0472]Steps:  98%|█████████▊| 12678/13000 [35:38<21:36,  4.03s/it, lr=1.51e-7, step_loss=0.182] Steps:  98%|█████████▊| 12679/13000 [35:38<17:25,  3.26s/it, lr=1.51e-7, step_loss=0.182]Steps:  98%|█████████▊| 12679/13000 [35:38<17:25,  3.26s/it, lr=1.5e-7, step_loss=0.0904]Steps:  98%|█████████▊| 12679/13000 [35:38<17:25,  3.26s/it, lr=1.5e-7, step_loss=0.00284]Steps:  98%|█████████▊| 12679/13000 [35:39<17:25,  3.26s/it, lr=1.5e-7, step_loss=0.00392]Steps:  98%|█████████▊| 12679/13000 [35:39<17:25,  3.26s/it, lr=1.5e-7, step_loss=0.0353] Steps:  98%|█████████▊| 12680/13000 [35:39<14:25,  2.70s/it, lr=1.5e-7, step_loss=0.0353]Steps:  98%|█████████▊| 12680/13000 [35:39<14:25,  2.70s/it, lr=1.49e-7, step_loss=0.00452]Steps:  98%|█████████▊| 12680/13000 [35:40<14:25,  2.70s/it, lr=1.49e-7, step_loss=0.0464] Steps:  98%|█████████▊| 12680/13000 [35:40<14:25,  2.70s/it, lr=1.49e-7, step_loss=0.0215]Steps:  98%|█████████▊| 12680/13000 [35:41<14:25,  2.70s/it, lr=1.49e-7, step_loss=0.028] Steps:  98%|█████████▊| 12681/13000 [35:41<12:42,  2.39s/it, lr=1.49e-7, step_loss=0.028]Steps:  98%|█████████▊| 12681/13000 [35:41<12:42,  2.39s/it, lr=1.48e-7, step_loss=0.0114]Steps:  98%|█████████▊| 12681/13000 [35:41<12:42,  2.39s/it, lr=1.48e-7, step_loss=0.0457]Steps:  98%|█████████▊| 12681/13000 [35:42<12:42,  2.39s/it, lr=1.48e-7, step_loss=0.0138]Steps:  98%|█████████▊| 12681/13000 [35:42<12:42,  2.39s/it, lr=1.48e-7, step_loss=0.0215]Steps:  98%|█████████▊| 12682/13000 [35:43<11:10,  2.11s/it, lr=1.48e-7, step_loss=0.0215]Steps:  98%|█████████▊| 12682/13000 [35:43<11:10,  2.11s/it, lr=1.48e-7, step_loss=0.0673]Steps:  98%|█████████▊| 12682/13000 [35:43<11:10,  2.11s/it, lr=1.48e-7, step_loss=0.0514]Steps:  98%|█████████▊| 12682/13000 [35:43<11:10,  2.11s/it, lr=1.48e-7, step_loss=0.0301]Steps:  98%|█████████▊| 12682/13000 [35:44<11:10,  2.11s/it, lr=1.48e-7, step_loss=0.00877]Steps:  98%|█████████▊| 12683/13000 [35:44<10:09,  1.92s/it, lr=1.48e-7, step_loss=0.00877]Steps:  98%|█████████▊| 12683/13000 [35:44<10:09,  1.92s/it, lr=1.47e-7, step_loss=0.0267] Steps:  98%|█████████▊| 12683/13000 [35:45<10:09,  1.92s/it, lr=1.47e-7, step_loss=0.133] Steps:  98%|█████████▊| 12684/13000 [35:45<08:21,  1.59s/it, lr=1.47e-7, step_loss=0.133]Steps:  98%|█████████▊| 12684/13000 [35:45<08:21,  1.59s/it, lr=1.46e-7, step_loss=0.157]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.49it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.23it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.71it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.23it/s]
02/23/2025 16:19:11 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12684/13000 [35:59<08:21,  1.59s/it, lr=1.46e-7, step_loss=0.148]Steps:  98%|█████████▊| 12684/13000 [36:01<08:21,  1.59s/it, lr=1.46e-7, step_loss=0.00668]Steps:  98%|█████████▊| 12684/13000 [36:02<08:21,  1.59s/it, lr=1.46e-7, step_loss=0.144]  Steps:  98%|█████████▊| 12685/13000 [36:02<32:45,  6.24s/it, lr=1.46e-7, step_loss=0.144]Steps:  98%|█████████▊| 12685/13000 [36:02<32:45,  6.24s/it, lr=1.45e-7, step_loss=0.466]Steps:  98%|█████████▊| 12685/13000 [36:02<32:45,  6.24s/it, lr=1.45e-7, step_loss=0.0309]Steps:  98%|█████████▊| 12685/13000 [36:03<32:45,  6.24s/it, lr=1.45e-7, step_loss=0.00598]Steps:  98%|█████████▊| 12685/13000 [36:03<32:45,  6.24s/it, lr=1.45e-7, step_loss=0.0465] Steps:  98%|█████████▊| 12686/13000 [36:03<25:07,  4.80s/it, lr=1.45e-7, step_loss=0.0465]Steps:  98%|█████████▊| 12686/13000 [36:03<25:07,  4.80s/it, lr=1.44e-7, step_loss=0.0813]Steps:  98%|█████████▊| 12686/13000 [36:04<25:07,  4.80s/it, lr=1.44e-7, step_loss=0.0334]Steps:  98%|█████████▊| 12686/13000 [36:04<25:07,  4.80s/it, lr=1.44e-7, step_loss=0.0101]Steps:  98%|█████████▊| 12686/13000 [36:05<25:07,  4.80s/it, lr=1.44e-7, step_loss=0.00725]Steps:  98%|█████████▊| 12687/13000 [36:05<19:48,  3.80s/it, lr=1.44e-7, step_loss=0.00725]Steps:  98%|█████████▊| 12687/13000 [36:06<19:48,  3.80s/it, lr=1.43e-7, step_loss=0.335]  Steps:  98%|█████████▊| 12687/13000 [36:07<19:48,  3.80s/it, lr=1.43e-7, step_loss=0.147]Steps:  98%|█████████▊| 12687/13000 [36:07<19:48,  3.80s/it, lr=1.43e-7, step_loss=0.0197]Steps:  98%|█████████▊| 12687/13000 [36:08<19:48,  3.80s/it, lr=1.43e-7, step_loss=0.113] Steps:  98%|█████████▊| 12688/13000 [36:08<18:34,  3.57s/it, lr=1.43e-7, step_loss=0.113]Steps:  98%|█████████▊| 12688/13000 [36:08<18:34,  3.57s/it, lr=1.42e-7, step_loss=0.0317]Steps:  98%|█████████▊| 12688/13000 [36:08<18:34,  3.57s/it, lr=1.42e-7, step_loss=0.142] Steps:  98%|█████████▊| 12688/13000 [36:09<18:34,  3.57s/it, lr=1.42e-7, step_loss=0.0266]Steps:  98%|█████████▊| 12688/13000 [36:09<18:34,  3.57s/it, lr=1.42e-7, step_loss=0.019] Steps:  98%|█████████▊| 12689/13000 [36:09<15:12,  2.93s/it, lr=1.42e-7, step_loss=0.019]Steps:  98%|█████████▊| 12689/13000 [36:09<15:12,  2.93s/it, lr=1.41e-7, step_loss=0.063]Steps:  98%|█████████▊| 12689/13000 [36:10<15:12,  2.93s/it, lr=1.41e-7, step_loss=0.0749]Steps:  98%|█████████▊| 12689/13000 [36:10<15:12,  2.93s/it, lr=1.41e-7, step_loss=0.00473]Steps:  98%|█████████▊| 12689/13000 [36:10<15:12,  2.93s/it, lr=1.41e-7, step_loss=0.177]  Steps:  98%|█████████▊| 12690/13000 [36:11<12:50,  2.48s/it, lr=1.41e-7, step_loss=0.177]Steps:  98%|█████████▊| 12690/13000 [36:11<12:50,  2.48s/it, lr=1.4e-7, step_loss=0.103] Steps:  98%|█████████▊| 12690/13000 [36:11<12:50,  2.48s/it, lr=1.4e-7, step_loss=0.0324]Steps:  98%|█████████▊| 12690/13000 [36:12<12:50,  2.48s/it, lr=1.4e-7, step_loss=0.0194]Steps:  98%|█████████▊| 12690/13000 [36:12<12:50,  2.48s/it, lr=1.4e-7, step_loss=0.0505]Steps:  98%|█████████▊| 12691/13000 [36:12<11:12,  2.18s/it, lr=1.4e-7, step_loss=0.0505]Steps:  98%|█████████▊| 12691/13000 [36:12<11:12,  2.18s/it, lr=1.39e-7, step_loss=0.0345]Steps:  98%|█████████▊| 12691/13000 [36:13<11:12,  2.18s/it, lr=1.39e-7, step_loss=0.165] Steps:  98%|█████████▊| 12691/13000 [36:13<11:12,  2.18s/it, lr=1.39e-7, step_loss=0.00326]Steps:  98%|█████████▊| 12691/13000 [36:13<11:12,  2.18s/it, lr=1.39e-7, step_loss=0.444]  Steps:  98%|█████████▊| 12692/13000 [36:14<09:59,  1.95s/it, lr=1.39e-7, step_loss=0.444]Steps:  98%|█████████▊| 12692/13000 [36:14<09:59,  1.95s/it, lr=1.38e-7, step_loss=0.0126]Steps:  98%|█████████▊| 12692/13000 [36:14<09:59,  1.95s/it, lr=1.38e-7, step_loss=0.00271]Steps:  98%|█████████▊| 12693/13000 [36:14<08:03,  1.57s/it, lr=1.38e-7, step_loss=0.00271]Steps:  98%|█████████▊| 12693/13000 [36:16<08:03,  1.57s/it, lr=1.38e-7, step_loss=0.0126] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.74it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.60it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.53it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.02it/s]
02/23/2025 16:19:42 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12693/13000 [36:30<08:03,  1.57s/it, lr=1.38e-7, step_loss=0.0141]Steps:  98%|█████████▊| 12693/13000 [36:33<08:03,  1.57s/it, lr=1.38e-7, step_loss=0.116] Steps:  98%|█████████▊| 12693/13000 [36:33<08:03,  1.57s/it, lr=1.38e-7, step_loss=0.0529]Steps:  98%|█████████▊| 12694/13000 [36:33<34:42,  6.80s/it, lr=1.38e-7, step_loss=0.0529]Steps:  98%|█████████▊| 12694/13000 [36:33<34:42,  6.80s/it, lr=1.37e-7, step_loss=0.0475]Steps:  98%|█████████▊| 12694/13000 [36:34<34:42,  6.80s/it, lr=1.37e-7, step_loss=0.0335]Steps:  98%|█████████▊| 12694/13000 [36:34<34:42,  6.80s/it, lr=1.37e-7, step_loss=0.808] Steps:  98%|█████████▊| 12694/13000 [36:34<34:42,  6.80s/it, lr=1.37e-7, step_loss=0.204]Steps:  98%|█████████▊| 12695/13000 [36:35<26:25,  5.20s/it, lr=1.37e-7, step_loss=0.204]Steps:  98%|█████████▊| 12695/13000 [36:36<26:25,  5.20s/it, lr=1.36e-7, step_loss=0.0318]Steps:  98%|█████████▊| 12695/13000 [36:37<26:25,  5.20s/it, lr=1.36e-7, step_loss=0.0172]Steps:  98%|█████████▊| 12695/13000 [36:37<26:25,  5.20s/it, lr=1.36e-7, step_loss=0.26]  Steps:  98%|█████████▊| 12695/13000 [36:38<26:25,  5.20s/it, lr=1.36e-7, step_loss=0.00285]Steps:  98%|█████████▊| 12696/13000 [36:38<23:11,  4.58s/it, lr=1.36e-7, step_loss=0.00285]Steps:  98%|█████████▊| 12696/13000 [36:38<23:11,  4.58s/it, lr=1.35e-7, step_loss=0.0358] Steps:  98%|█████████▊| 12696/13000 [36:38<23:11,  4.58s/it, lr=1.35e-7, step_loss=0.0697]Steps:  98%|█████████▊| 12696/13000 [36:39<23:11,  4.58s/it, lr=1.35e-7, step_loss=0.397] Steps:  98%|█████████▊| 12696/13000 [36:39<23:11,  4.58s/it, lr=1.35e-7, step_loss=0.0211]Steps:  98%|█████████▊| 12697/13000 [36:39<18:25,  3.65s/it, lr=1.35e-7, step_loss=0.0211]Steps:  98%|█████████▊| 12697/13000 [36:40<18:25,  3.65s/it, lr=1.34e-7, step_loss=0.0145]Steps:  98%|█████████▊| 12697/13000 [36:41<18:25,  3.65s/it, lr=1.34e-7, step_loss=0.0228]Steps:  98%|█████████▊| 12697/13000 [36:41<18:25,  3.65s/it, lr=1.34e-7, step_loss=0.0646]Steps:  98%|█████████▊| 12697/13000 [36:41<18:25,  3.65s/it, lr=1.34e-7, step_loss=0.0516]Steps:  98%|█████████▊| 12698/13000 [36:42<17:11,  3.42s/it, lr=1.34e-7, step_loss=0.0516]Steps:  98%|█████████▊| 12698/13000 [36:42<17:11,  3.42s/it, lr=1.33e-7, step_loss=0.223] Steps:  98%|█████████▊| 12698/13000 [36:43<17:11,  3.42s/it, lr=1.33e-7, step_loss=0.0716]Steps:  98%|█████████▊| 12698/13000 [36:43<17:11,  3.42s/it, lr=1.33e-7, step_loss=0.0092]Steps:  98%|█████████▊| 12698/13000 [36:43<17:11,  3.42s/it, lr=1.33e-7, step_loss=0.255] Steps:  98%|█████████▊| 12699/13000 [36:44<14:11,  2.83s/it, lr=1.33e-7, step_loss=0.255]Steps:  98%|█████████▊| 12699/13000 [36:44<14:11,  2.83s/it, lr=1.32e-7, step_loss=0.00441]Steps:  98%|█████████▊| 12699/13000 [36:44<14:11,  2.83s/it, lr=1.32e-7, step_loss=0.106]  Steps:  98%|█████████▊| 12699/13000 [36:44<14:11,  2.83s/it, lr=1.32e-7, step_loss=0.0857]Steps:  98%|█████████▊| 12699/13000 [36:45<14:11,  2.83s/it, lr=1.32e-7, step_loss=0.139] Steps:  98%|█████████▊| 12700/13000 [36:45<12:01,  2.40s/it, lr=1.32e-7, step_loss=0.139]Steps:  98%|█████████▊| 12700/13000 [36:45<12:01,  2.40s/it, lr=1.31e-7, step_loss=0.00886]Steps:  98%|█████████▊| 12700/13000 [36:46<12:01,  2.40s/it, lr=1.31e-7, step_loss=0.05]   Steps:  98%|█████████▊| 12700/13000 [36:46<12:01,  2.40s/it, lr=1.31e-7, step_loss=0.036]Steps:  98%|█████████▊| 12700/13000 [36:46<12:01,  2.40s/it, lr=1.31e-7, step_loss=0.11] Steps:  98%|█████████▊| 12701/13000 [36:47<10:37,  2.13s/it, lr=1.31e-7, step_loss=0.11]Steps:  98%|█████████▊| 12701/13000 [36:48<10:37,  2.13s/it, lr=1.3e-7, step_loss=0.0475]Steps:  98%|█████████▊| 12701/13000 [36:48<10:37,  2.13s/it, lr=1.3e-7, step_loss=0.141] Steps:  98%|█████████▊| 12702/13000 [36:49<10:29,  2.11s/it, lr=1.3e-7, step_loss=0.141]Steps:  98%|█████████▊| 12702/13000 [36:49<10:29,  2.11s/it, lr=1.3e-7, step_loss=0.0578]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.26it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.11it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.61it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.18it/s]
02/23/2025 16:20:15 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12702/13000 [37:03<10:29,  2.11s/it, lr=1.3e-7, step_loss=0.457] Steps:  98%|█████████▊| 12702/13000 [37:04<10:29,  2.11s/it, lr=1.3e-7, step_loss=0.308]Steps:  98%|█████████▊| 12702/13000 [37:04<10:29,  2.11s/it, lr=1.3e-7, step_loss=0.0796]Steps:  98%|█████████▊| 12703/13000 [37:04<30:28,  6.16s/it, lr=1.3e-7, step_loss=0.0796]Steps:  98%|█████████▊| 12703/13000 [37:04<30:28,  6.16s/it, lr=1.29e-7, step_loss=0.00606]Steps:  98%|█████████▊| 12703/13000 [37:05<30:28,  6.16s/it, lr=1.29e-7, step_loss=0.0535] Steps:  98%|█████████▊| 12703/13000 [37:05<30:28,  6.16s/it, lr=1.29e-7, step_loss=0.079] Steps:  98%|█████████▊| 12703/13000 [37:05<30:28,  6.16s/it, lr=1.29e-7, step_loss=0.0652]Steps:  98%|█████████▊| 12704/13000 [37:06<23:24,  4.75s/it, lr=1.29e-7, step_loss=0.0652]Steps:  98%|█████████▊| 12704/13000 [37:06<23:24,  4.75s/it, lr=1.28e-7, step_loss=0.0841]Steps:  98%|█████████▊| 12704/13000 [37:06<23:24,  4.75s/it, lr=1.28e-7, step_loss=0.0125]Steps:  98%|█████████▊| 12704/13000 [37:06<23:24,  4.75s/it, lr=1.28e-7, step_loss=0.0067]Steps:  98%|█████████▊| 12704/13000 [37:07<23:24,  4.75s/it, lr=1.28e-7, step_loss=0.0253]Steps:  98%|█████████▊| 12705/13000 [37:07<18:25,  3.75s/it, lr=1.28e-7, step_loss=0.0253]Steps:  98%|█████████▊| 12705/13000 [37:07<18:25,  3.75s/it, lr=1.27e-7, step_loss=0.0155]Steps:  98%|█████████▊| 12705/13000 [37:08<18:25,  3.75s/it, lr=1.27e-7, step_loss=0.00685]Steps:  98%|█████████▊| 12705/13000 [37:08<18:25,  3.75s/it, lr=1.27e-7, step_loss=0.0175] Steps:  98%|█████████▊| 12705/13000 [37:08<18:25,  3.75s/it, lr=1.27e-7, step_loss=0.0138]Steps:  98%|█████████▊| 12706/13000 [37:09<15:02,  3.07s/it, lr=1.27e-7, step_loss=0.0138]Steps:  98%|█████████▊| 12706/13000 [37:09<15:02,  3.07s/it, lr=1.26e-7, step_loss=0.075] Steps:  98%|█████████▊| 12706/13000 [37:09<15:02,  3.07s/it, lr=1.26e-7, step_loss=0.0484]Steps:  98%|█████████▊| 12706/13000 [37:09<15:02,  3.07s/it, lr=1.26e-7, step_loss=0.0443]Steps:  98%|█████████▊| 12706/13000 [37:10<15:02,  3.07s/it, lr=1.26e-7, step_loss=0.0612]Steps:  98%|█████████▊| 12707/13000 [37:10<12:37,  2.58s/it, lr=1.26e-7, step_loss=0.0612]Steps:  98%|█████████▊| 12707/13000 [37:10<12:37,  2.58s/it, lr=1.25e-7, step_loss=0.131] Steps:  98%|█████████▊| 12707/13000 [37:11<12:37,  2.58s/it, lr=1.25e-7, step_loss=0.0579]Steps:  98%|█████████▊| 12707/13000 [37:11<12:37,  2.58s/it, lr=1.25e-7, step_loss=0.136] Steps:  98%|█████████▊| 12707/13000 [37:11<12:37,  2.58s/it, lr=1.25e-7, step_loss=0.00525]Steps:  98%|█████████▊| 12708/13000 [37:12<10:51,  2.23s/it, lr=1.25e-7, step_loss=0.00525]Steps:  98%|█████████▊| 12708/13000 [37:12<10:51,  2.23s/it, lr=1.24e-7, step_loss=0.0977] Steps:  98%|█████████▊| 12708/13000 [37:12<10:51,  2.23s/it, lr=1.24e-7, step_loss=0.0425]Steps:  98%|█████████▊| 12708/13000 [37:12<10:51,  2.23s/it, lr=1.24e-7, step_loss=0.231] Steps:  98%|█████████▊| 12708/13000 [37:13<10:51,  2.23s/it, lr=1.24e-7, step_loss=0.0709]Steps:  98%|█████████▊| 12709/13000 [37:13<09:43,  2.01s/it, lr=1.24e-7, step_loss=0.0709]Steps:  98%|█████████▊| 12709/13000 [37:13<09:43,  2.01s/it, lr=1.24e-7, step_loss=0.12]  Steps:  98%|█████████▊| 12709/13000 [37:13<09:43,  2.01s/it, lr=1.24e-7, step_loss=0.0556]Steps:  98%|█████████▊| 12709/13000 [37:14<09:43,  2.01s/it, lr=1.24e-7, step_loss=0.0102]Steps:  98%|█████████▊| 12709/13000 [37:14<09:43,  2.01s/it, lr=1.24e-7, step_loss=0.00453]Steps:  98%|█████████▊| 12710/13000 [37:15<08:59,  1.86s/it, lr=1.24e-7, step_loss=0.00453]Steps:  98%|█████████▊| 12710/13000 [37:15<08:59,  1.86s/it, lr=1.23e-7, step_loss=0.0163] Steps:  98%|█████████▊| 12710/13000 [37:15<08:59,  1.86s/it, lr=1.23e-7, step_loss=0.0554]Steps:  98%|█████████▊| 12711/13000 [37:15<07:17,  1.51s/it, lr=1.23e-7, step_loss=0.0554]Steps:  98%|█████████▊| 12711/13000 [37:15<07:17,  1.51s/it, lr=1.22e-7, step_loss=0.0669]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.17it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.75it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.04it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.61it/s]
02/23/2025 16:20:42 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12711/13000 [37:30<07:17,  1.51s/it, lr=1.22e-7, step_loss=0.0142]Steps:  98%|█████████▊| 12711/13000 [37:30<07:17,  1.51s/it, lr=1.22e-7, step_loss=0.125] Steps:  98%|█████████▊| 12711/13000 [37:30<07:17,  1.51s/it, lr=1.22e-7, step_loss=0.00442]Steps:  98%|█████████▊| 12712/13000 [37:31<27:14,  5.67s/it, lr=1.22e-7, step_loss=0.00442]Steps:  98%|█████████▊| 12712/13000 [37:31<27:14,  5.67s/it, lr=1.21e-7, step_loss=0.0122] Steps:  98%|█████████▊| 12712/13000 [37:31<27:14,  5.67s/it, lr=1.21e-7, step_loss=0.117] Steps:  98%|█████████▊| 12712/13000 [37:31<27:14,  5.67s/it, lr=1.21e-7, step_loss=0.254]Steps:  98%|█████████▊| 12712/13000 [37:32<27:14,  5.67s/it, lr=1.21e-7, step_loss=0.00528]Steps:  98%|█████████▊| 12713/13000 [37:32<21:07,  4.42s/it, lr=1.21e-7, step_loss=0.00528]Steps:  98%|█████████▊| 12713/13000 [37:33<21:07,  4.42s/it, lr=1.2e-7, step_loss=0.114]   Steps:  98%|█████████▊| 12713/13000 [37:33<21:07,  4.42s/it, lr=1.2e-7, step_loss=0.0109]Steps:  98%|█████████▊| 12713/13000 [37:34<21:07,  4.42s/it, lr=1.2e-7, step_loss=0.0561]Steps:  98%|█████████▊| 12713/13000 [37:34<21:07,  4.42s/it, lr=1.2e-7, step_loss=0.00354]Steps:  98%|█████████▊| 12714/13000 [37:37<22:18,  4.68s/it, lr=1.2e-7, step_loss=0.00354]Steps:  98%|█████████▊| 12714/13000 [37:37<22:18,  4.68s/it, lr=1.19e-7, step_loss=0.00876]Steps:  98%|█████████▊| 12714/13000 [37:38<22:18,  4.68s/it, lr=1.19e-7, step_loss=0.129]  Steps:  98%|█████████▊| 12714/13000 [37:38<22:18,  4.68s/it, lr=1.19e-7, step_loss=0.0399]Steps:  98%|█████████▊| 12714/13000 [37:39<22:18,  4.68s/it, lr=1.19e-7, step_loss=0.0826]Steps:  98%|█████████▊| 12715/13000 [37:39<17:38,  3.71s/it, lr=1.19e-7, step_loss=0.0826]Steps:  98%|█████████▊| 12715/13000 [37:39<17:38,  3.71s/it, lr=1.19e-7, step_loss=0.0108]Steps:  98%|█████████▊| 12715/13000 [37:39<17:38,  3.71s/it, lr=1.19e-7, step_loss=0.0627]Steps:  98%|█████████▊| 12715/13000 [37:40<17:38,  3.71s/it, lr=1.19e-7, step_loss=0.0423]Steps:  98%|█████████▊| 12715/13000 [37:41<17:38,  3.71s/it, lr=1.19e-7, step_loss=0.103] Steps:  98%|█████████▊| 12716/13000 [37:41<15:27,  3.27s/it, lr=1.19e-7, step_loss=0.103]Steps:  98%|█████████▊| 12716/13000 [37:41<15:27,  3.27s/it, lr=1.18e-7, step_loss=0.0453]Steps:  98%|█████████▊| 12716/13000 [37:41<15:27,  3.27s/it, lr=1.18e-7, step_loss=0.119] Steps:  98%|█████████▊| 12716/13000 [37:42<15:27,  3.27s/it, lr=1.18e-7, step_loss=0.232]Steps:  98%|█████████▊| 12716/13000 [37:42<15:27,  3.27s/it, lr=1.18e-7, step_loss=0.134]Steps:  98%|█████████▊| 12717/13000 [37:43<12:54,  2.74s/it, lr=1.18e-7, step_loss=0.134]Steps:  98%|█████████▊| 12717/13000 [37:43<12:54,  2.74s/it, lr=1.17e-7, step_loss=0.0797]Steps:  98%|█████████▊| 12717/13000 [37:43<12:54,  2.74s/it, lr=1.17e-7, step_loss=0.313] Steps:  98%|█████████▊| 12717/13000 [37:43<12:54,  2.74s/it, lr=1.17e-7, step_loss=0.033]Steps:  98%|█████████▊| 12717/13000 [37:44<12:54,  2.74s/it, lr=1.17e-7, step_loss=0.00436]Steps:  98%|█████████▊| 12718/13000 [37:44<11:00,  2.34s/it, lr=1.17e-7, step_loss=0.00436]Steps:  98%|█████████▊| 12718/13000 [37:45<11:00,  2.34s/it, lr=1.16e-7, step_loss=0.0158] Steps:  98%|█████████▊| 12718/13000 [37:45<11:00,  2.34s/it, lr=1.16e-7, step_loss=0.0587]Steps:  98%|█████████▊| 12718/13000 [37:45<11:00,  2.34s/it, lr=1.16e-7, step_loss=0.135] Steps:  98%|█████████▊| 12718/13000 [37:46<11:00,  2.34s/it, lr=1.16e-7, step_loss=0.00917]Steps:  98%|█████████▊| 12719/13000 [37:46<10:44,  2.29s/it, lr=1.16e-7, step_loss=0.00917]Steps:  98%|█████████▊| 12719/13000 [37:46<10:44,  2.29s/it, lr=1.15e-7, step_loss=0.116]  Steps:  98%|█████████▊| 12719/13000 [37:47<10:44,  2.29s/it, lr=1.15e-7, step_loss=0.0849]Steps:  98%|█████████▊| 12720/13000 [37:47<08:29,  1.82s/it, lr=1.15e-7, step_loss=0.0849]Steps:  98%|█████████▊| 12720/13000 [37:47<08:29,  1.82s/it, lr=1.14e-7, step_loss=0.0291]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.18it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.09it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.86it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.38it/s]
02/23/2025 16:21:13 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12720/13000 [38:01<08:29,  1.82s/it, lr=1.14e-7, step_loss=0.0523]Steps:  98%|█████████▊| 12720/13000 [38:02<08:29,  1.82s/it, lr=1.14e-7, step_loss=0.00368]Steps:  98%|█████████▊| 12720/13000 [38:02<08:29,  1.82s/it, lr=1.14e-7, step_loss=0.00477]Steps:  98%|█████████▊| 12721/13000 [38:02<27:40,  5.95s/it, lr=1.14e-7, step_loss=0.00477]Steps:  98%|█████████▊| 12721/13000 [38:03<27:40,  5.95s/it, lr=1.14e-7, step_loss=0.0729] Steps:  98%|█████████▊| 12721/13000 [38:03<27:40,  5.95s/it, lr=1.14e-7, step_loss=0.0185]Steps:  98%|█████████▊| 12721/13000 [38:03<27:40,  5.95s/it, lr=1.14e-7, step_loss=0.0248]Steps:  98%|█████████▊| 12721/13000 [38:04<27:40,  5.95s/it, lr=1.14e-7, step_loss=0.214] Steps:  98%|█████████▊| 12722/13000 [38:04<21:20,  4.61s/it, lr=1.14e-7, step_loss=0.214]Steps:  98%|█████████▊| 12722/13000 [38:04<21:20,  4.61s/it, lr=1.13e-7, step_loss=0.0514]Steps:  98%|█████████▊| 12722/13000 [38:04<21:20,  4.61s/it, lr=1.13e-7, step_loss=0.271] Steps:  98%|█████████▊| 12722/13000 [38:05<21:20,  4.61s/it, lr=1.13e-7, step_loss=0.197]Steps:  98%|█████████▊| 12722/13000 [38:05<21:20,  4.61s/it, lr=1.13e-7, step_loss=0.00224]Steps:  98%|█████████▊| 12723/13000 [38:05<16:50,  3.65s/it, lr=1.13e-7, step_loss=0.00224]Steps:  98%|█████████▊| 12723/13000 [38:05<16:50,  3.65s/it, lr=1.12e-7, step_loss=0.442]  Steps:  98%|█████████▊| 12723/13000 [38:06<16:50,  3.65s/it, lr=1.12e-7, step_loss=0.0254]Steps:  98%|█████████▊| 12723/13000 [38:06<16:50,  3.65s/it, lr=1.12e-7, step_loss=0.243] Steps:  98%|█████████▊| 12723/13000 [38:06<16:50,  3.65s/it, lr=1.12e-7, step_loss=0.223]Steps:  98%|█████████▊| 12724/13000 [38:07<13:44,  2.99s/it, lr=1.12e-7, step_loss=0.223]Steps:  98%|█████████▊| 12724/13000 [38:07<13:44,  2.99s/it, lr=1.11e-7, step_loss=0.0193]Steps:  98%|█████████▊| 12724/13000 [38:07<13:44,  2.99s/it, lr=1.11e-7, step_loss=0.00579]Steps:  98%|█████████▊| 12724/13000 [38:08<13:44,  2.99s/it, lr=1.11e-7, step_loss=0.00563]Steps:  98%|█████████▊| 12724/13000 [38:08<13:44,  2.99s/it, lr=1.11e-7, step_loss=0.024]  Steps:  98%|█████████▊| 12725/13000 [38:08<11:39,  2.54s/it, lr=1.11e-7, step_loss=0.024]Steps:  98%|█████████▊| 12725/13000 [38:08<11:39,  2.54s/it, lr=1.1e-7, step_loss=0.0421]Steps:  98%|█████████▊| 12725/13000 [38:09<11:39,  2.54s/it, lr=1.1e-7, step_loss=0.0256]Steps:  98%|█████████▊| 12725/13000 [38:09<11:39,  2.54s/it, lr=1.1e-7, step_loss=0.0448]Steps:  98%|█████████▊| 12725/13000 [38:09<11:39,  2.54s/it, lr=1.1e-7, step_loss=0.0152]Steps:  98%|█████████▊| 12726/13000 [38:10<10:08,  2.22s/it, lr=1.1e-7, step_loss=0.0152]Steps:  98%|█████████▊| 12726/13000 [38:10<10:08,  2.22s/it, lr=1.1e-7, step_loss=0.0326]Steps:  98%|█████████▊| 12726/13000 [38:10<10:08,  2.22s/it, lr=1.1e-7, step_loss=0.0374]Steps:  98%|█████████▊| 12726/13000 [38:11<10:08,  2.22s/it, lr=1.1e-7, step_loss=0.47]  Steps:  98%|█████████▊| 12726/13000 [38:11<10:08,  2.22s/it, lr=1.1e-7, step_loss=0.496]Steps:  98%|█████████▊| 12727/13000 [38:11<09:04,  1.99s/it, lr=1.1e-7, step_loss=0.496]Steps:  98%|█████████▊| 12727/13000 [38:11<09:04,  1.99s/it, lr=1.09e-7, step_loss=0.148]Steps:  98%|█████████▊| 12727/13000 [38:12<09:04,  1.99s/it, lr=1.09e-7, step_loss=0.289]Steps:  98%|█████████▊| 12727/13000 [38:12<09:04,  1.99s/it, lr=1.09e-7, step_loss=0.0127]Steps:  98%|█████████▊| 12727/13000 [38:12<09:04,  1.99s/it, lr=1.09e-7, step_loss=0.0818]Steps:  98%|█████████▊| 12728/13000 [38:13<08:17,  1.83s/it, lr=1.09e-7, step_loss=0.0818]Steps:  98%|█████████▊| 12728/13000 [38:13<08:17,  1.83s/it, lr=1.08e-7, step_loss=0.00872]Steps:  98%|█████████▊| 12728/13000 [38:13<08:17,  1.83s/it, lr=1.08e-7, step_loss=0.102]  Steps:  98%|█████████▊| 12729/13000 [38:13<06:42,  1.49s/it, lr=1.08e-7, step_loss=0.102]Steps:  98%|█████████▊| 12729/13000 [38:13<06:42,  1.49s/it, lr=1.07e-7, step_loss=0.0687]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.82it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.26it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.71it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.31it/s]
02/23/2025 16:21:40 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12729/13000 [38:28<06:42,  1.49s/it, lr=1.07e-7, step_loss=0.00895]Steps:  98%|█████████▊| 12729/13000 [38:28<06:42,  1.49s/it, lr=1.07e-7, step_loss=0.212]  Steps:  98%|█████████▊| 12729/13000 [38:28<06:42,  1.49s/it, lr=1.07e-7, step_loss=0.295]Steps:  98%|█████████▊| 12730/13000 [38:29<25:28,  5.66s/it, lr=1.07e-7, step_loss=0.295]Steps:  98%|█████████▊| 12730/13000 [38:29<25:28,  5.66s/it, lr=1.06e-7, step_loss=0.0194]Steps:  98%|█████████▊| 12730/13000 [38:29<25:28,  5.66s/it, lr=1.06e-7, step_loss=0.0824]Steps:  98%|█████████▊| 12730/13000 [38:30<25:28,  5.66s/it, lr=1.06e-7, step_loss=0.0871]Steps:  98%|█████████▊| 12730/13000 [38:30<25:28,  5.66s/it, lr=1.06e-7, step_loss=0.00796]Steps:  98%|█████████▊| 12731/13000 [38:30<19:45,  4.41s/it, lr=1.06e-7, step_loss=0.00796]Steps:  98%|█████████▊| 12731/13000 [38:30<19:45,  4.41s/it, lr=1.06e-7, step_loss=0.123]  Steps:  98%|█████████▊| 12731/13000 [38:31<19:45,  4.41s/it, lr=1.06e-7, step_loss=0.00412]Steps:  98%|█████████▊| 12731/13000 [38:31<19:45,  4.41s/it, lr=1.06e-7, step_loss=0.00528]Steps:  98%|█████████▊| 12731/13000 [38:31<19:45,  4.41s/it, lr=1.06e-7, step_loss=0.0966] Steps:  98%|█████████▊| 12732/13000 [38:32<15:41,  3.51s/it, lr=1.06e-7, step_loss=0.0966]Steps:  98%|█████████▊| 12732/13000 [38:32<15:41,  3.51s/it, lr=1.05e-7, step_loss=0.0348]Steps:  98%|█████████▊| 12732/13000 [38:32<15:41,  3.51s/it, lr=1.05e-7, step_loss=0.0482]Steps:  98%|█████████▊| 12732/13000 [38:32<15:41,  3.51s/it, lr=1.05e-7, step_loss=0.014] Steps:  98%|█████████▊| 12732/13000 [38:33<15:41,  3.51s/it, lr=1.05e-7, step_loss=0.0368]Steps:  98%|█████████▊| 12733/13000 [38:33<12:53,  2.90s/it, lr=1.05e-7, step_loss=0.0368]Steps:  98%|█████████▊| 12733/13000 [38:33<12:53,  2.90s/it, lr=1.04e-7, step_loss=0.0374]Steps:  98%|█████████▊| 12733/13000 [38:34<12:53,  2.90s/it, lr=1.04e-7, step_loss=0.017] Steps:  98%|█████████▊| 12733/13000 [38:34<12:53,  2.90s/it, lr=1.04e-7, step_loss=0.257]Steps:  98%|█████████▊| 12733/13000 [38:34<12:53,  2.90s/it, lr=1.04e-7, step_loss=0.1]  Steps:  98%|█████████▊| 12734/13000 [38:35<10:55,  2.46s/it, lr=1.04e-7, step_loss=0.1]Steps:  98%|█████████▊| 12734/13000 [38:35<10:55,  2.46s/it, lr=1.03e-7, step_loss=0.0279]Steps:  98%|█████████▊| 12734/13000 [38:35<10:55,  2.46s/it, lr=1.03e-7, step_loss=0.0839]Steps:  98%|█████████▊| 12734/13000 [38:35<10:55,  2.46s/it, lr=1.03e-7, step_loss=0.0124]Steps:  98%|█████████▊| 12734/13000 [38:36<10:55,  2.46s/it, lr=1.03e-7, step_loss=0.0182]Steps:  98%|█████████▊| 12735/13000 [38:36<09:30,  2.15s/it, lr=1.03e-7, step_loss=0.0182]Steps:  98%|█████████▊| 12735/13000 [38:36<09:30,  2.15s/it, lr=1.02e-7, step_loss=0.0106]Steps:  98%|█████████▊| 12735/13000 [38:36<09:30,  2.15s/it, lr=1.02e-7, step_loss=0.131] Steps:  98%|█████████▊| 12735/13000 [38:37<09:30,  2.15s/it, lr=1.02e-7, step_loss=0.0373]Steps:  98%|█████████▊| 12735/13000 [38:37<09:30,  2.15s/it, lr=1.02e-7, step_loss=0.0225]Steps:  98%|█████████▊| 12736/13000 [38:37<08:32,  1.94s/it, lr=1.02e-7, step_loss=0.0225]Steps:  98%|█████████▊| 12736/13000 [38:38<08:32,  1.94s/it, lr=1.02e-7, step_loss=0.232] Steps:  98%|█████████▊| 12736/13000 [38:38<08:32,  1.94s/it, lr=1.02e-7, step_loss=0.181]Steps:  98%|█████████▊| 12736/13000 [38:38<08:32,  1.94s/it, lr=1.02e-7, step_loss=0.00743]Steps:  98%|█████████▊| 12736/13000 [38:39<08:32,  1.94s/it, lr=1.02e-7, step_loss=0.00521]Steps:  98%|█████████▊| 12737/13000 [38:39<07:52,  1.79s/it, lr=1.02e-7, step_loss=0.00521]Steps:  98%|█████████▊| 12737/13000 [38:39<07:52,  1.79s/it, lr=1.01e-7, step_loss=0.0726] Steps:  98%|█████████▊| 12737/13000 [38:39<07:52,  1.79s/it, lr=1.01e-7, step_loss=0.0744]Steps:  98%|█████████▊| 12738/13000 [38:40<06:22,  1.46s/it, lr=1.01e-7, step_loss=0.0744]Steps:  98%|█████████▊| 12738/13000 [38:40<06:22,  1.46s/it, lr=1e-7, step_loss=0.0166]   {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.44it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.58it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.42it/s]
02/23/2025 16:22:06 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12738/13000 [38:55<06:22,  1.46s/it, lr=1e-7, step_loss=0.243] Steps:  98%|█████████▊| 12738/13000 [38:55<06:22,  1.46s/it, lr=1e-7, step_loss=0.0292]Steps:  98%|█████████▊| 12738/13000 [38:56<06:22,  1.46s/it, lr=1e-7, step_loss=0.172] Steps:  98%|█████████▊| 12739/13000 [38:56<25:56,  5.96s/it, lr=1e-7, step_loss=0.172]Steps:  98%|█████████▊| 12739/13000 [38:56<25:56,  5.96s/it, lr=9.94e-8, step_loss=0.00385]Steps:  98%|█████████▊| 12739/13000 [38:56<25:56,  5.96s/it, lr=9.94e-8, step_loss=0.00545]Steps:  98%|█████████▊| 12739/13000 [38:57<25:56,  5.96s/it, lr=9.94e-8, step_loss=0.0947] Steps:  98%|█████████▊| 12739/13000 [38:57<25:56,  5.96s/it, lr=9.94e-8, step_loss=0.0594]Steps:  98%|█████████▊| 12740/13000 [38:58<20:01,  4.62s/it, lr=9.94e-8, step_loss=0.0594]Steps:  98%|█████████▊| 12740/13000 [38:59<20:01,  4.62s/it, lr=9.87e-8, step_loss=0.0476]Steps:  98%|█████████▊| 12740/13000 [39:00<20:01,  4.62s/it, lr=9.87e-8, step_loss=0.0131]Steps:  98%|█████████▊| 12740/13000 [39:00<20:01,  4.62s/it, lr=9.87e-8, step_loss=0.0944]Steps:  98%|█████████▊| 12740/13000 [39:00<20:01,  4.62s/it, lr=9.87e-8, step_loss=0.00448]Steps:  98%|█████████▊| 12741/13000 [39:01<18:10,  4.21s/it, lr=9.87e-8, step_loss=0.00448]Steps:  98%|█████████▊| 12741/13000 [39:01<18:10,  4.21s/it, lr=9.79e-8, step_loss=0.136]  Steps:  98%|█████████▊| 12741/13000 [39:01<18:10,  4.21s/it, lr=9.79e-8, step_loss=0.0186]Steps:  98%|█████████▊| 12741/13000 [39:02<18:10,  4.21s/it, lr=9.79e-8, step_loss=0.0317]Steps:  98%|█████████▊| 12741/13000 [39:02<18:10,  4.21s/it, lr=9.79e-8, step_loss=0.145] Steps:  98%|█████████▊| 12742/13000 [39:02<14:34,  3.39s/it, lr=9.79e-8, step_loss=0.145]Steps:  98%|█████████▊| 12742/13000 [39:02<14:34,  3.39s/it, lr=9.72e-8, step_loss=0.00967]Steps:  98%|█████████▊| 12742/13000 [39:03<14:34,  3.39s/it, lr=9.72e-8, step_loss=0.381]  Steps:  98%|█████████▊| 12742/13000 [39:03<14:34,  3.39s/it, lr=9.72e-8, step_loss=0.0364]Steps:  98%|█████████▊| 12742/13000 [39:03<14:34,  3.39s/it, lr=9.72e-8, step_loss=0.0942]Steps:  98%|█████████▊| 12743/13000 [39:04<11:59,  2.80s/it, lr=9.72e-8, step_loss=0.0942]Steps:  98%|█████████▊| 12743/13000 [39:04<11:59,  2.80s/it, lr=9.64e-8, step_loss=0.0032]Steps:  98%|█████████▊| 12743/13000 [39:04<11:59,  2.80s/it, lr=9.64e-8, step_loss=0.0853]Steps:  98%|█████████▊| 12743/13000 [39:04<11:59,  2.80s/it, lr=9.64e-8, step_loss=0.00643]Steps:  98%|█████████▊| 12743/13000 [39:05<11:59,  2.80s/it, lr=9.64e-8, step_loss=0.0055] Steps:  98%|█████████▊| 12744/13000 [39:06<10:44,  2.52s/it, lr=9.64e-8, step_loss=0.0055]Steps:  98%|█████████▊| 12744/13000 [39:06<10:44,  2.52s/it, lr=9.57e-8, step_loss=0.0166]Steps:  98%|█████████▊| 12744/13000 [39:06<10:44,  2.52s/it, lr=9.57e-8, step_loss=0.00436]Steps:  98%|█████████▊| 12744/13000 [39:06<10:44,  2.52s/it, lr=9.57e-8, step_loss=0.0471] Steps:  98%|█████████▊| 12744/13000 [39:07<10:44,  2.52s/it, lr=9.57e-8, step_loss=0.02]  Steps:  98%|█████████▊| 12745/13000 [39:07<09:18,  2.19s/it, lr=9.57e-8, step_loss=0.02]Steps:  98%|█████████▊| 12745/13000 [39:07<09:18,  2.19s/it, lr=9.49e-8, step_loss=0.0855]Steps:  98%|█████████▊| 12745/13000 [39:07<09:18,  2.19s/it, lr=9.49e-8, step_loss=0.0376]Steps:  98%|█████████▊| 12745/13000 [39:08<09:18,  2.19s/it, lr=9.49e-8, step_loss=0.11]  Steps:  98%|█████████▊| 12745/13000 [39:08<09:18,  2.19s/it, lr=9.49e-8, step_loss=0.0571]Steps:  98%|█████████▊| 12746/13000 [39:08<08:20,  1.97s/it, lr=9.49e-8, step_loss=0.0571]Steps:  98%|█████████▊| 12746/13000 [39:08<08:20,  1.97s/it, lr=9.42e-8, step_loss=0.0283]Steps:  98%|█████████▊| 12746/13000 [39:09<08:20,  1.97s/it, lr=9.42e-8, step_loss=0.0152]Steps:  98%|█████████▊| 12747/13000 [39:09<06:41,  1.59s/it, lr=9.42e-8, step_loss=0.0152]Steps:  98%|█████████▊| 12747/13000 [39:09<06:41,  1.59s/it, lr=9.34e-8, step_loss=0.00569]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.45it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.09it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.01it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.84it/s]
02/23/2025 16:22:36 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12747/13000 [39:24<06:41,  1.59s/it, lr=9.34e-8, step_loss=0.033]  Steps:  98%|█████████▊| 12747/13000 [39:25<06:41,  1.59s/it, lr=9.34e-8, step_loss=0.00461]Steps:  98%|█████████▊| 12747/13000 [39:25<06:41,  1.59s/it, lr=9.34e-8, step_loss=0.177]  Steps:  98%|█████████▊| 12748/13000 [39:25<25:03,  5.97s/it, lr=9.34e-8, step_loss=0.177]Steps:  98%|█████████▊| 12748/13000 [39:25<25:03,  5.97s/it, lr=9.27e-8, step_loss=0.00536]Steps:  98%|█████████▊| 12748/13000 [39:26<25:03,  5.97s/it, lr=9.27e-8, step_loss=0.0464] Steps:  98%|█████████▊| 12748/13000 [39:26<25:03,  5.97s/it, lr=9.27e-8, step_loss=0.0196]Steps:  98%|█████████▊| 12748/13000 [39:26<25:03,  5.97s/it, lr=9.27e-8, step_loss=0.153] Steps:  98%|█████████▊| 12749/13000 [39:27<19:15,  4.61s/it, lr=9.27e-8, step_loss=0.153]Steps:  98%|█████████▊| 12749/13000 [39:27<19:15,  4.61s/it, lr=9.2e-8, step_loss=0.134] Steps:  98%|█████████▊| 12749/13000 [39:27<19:15,  4.61s/it, lr=9.2e-8, step_loss=0.23] Steps:  98%|█████████▊| 12749/13000 [39:28<19:15,  4.61s/it, lr=9.2e-8, step_loss=0.0575]Steps:  98%|█████████▊| 12749/13000 [39:28<19:15,  4.61s/it, lr=9.2e-8, step_loss=0.204] Steps:  98%|█████████▊| 12750/13000 [39:28<15:16,  3.66s/it, lr=9.2e-8, step_loss=0.204]Steps:  98%|█████████▊| 12750/13000 [39:28<15:16,  3.66s/it, lr=9.12e-8, step_loss=0.38]Steps:  98%|█████████▊| 12750/13000 [39:29<15:16,  3.66s/it, lr=9.12e-8, step_loss=0.0215]Steps:  98%|█████████▊| 12750/13000 [39:29<15:16,  3.66s/it, lr=9.12e-8, step_loss=0.826] Steps:  98%|█████████▊| 12750/13000 [39:29<15:16,  3.66s/it, lr=9.12e-8, step_loss=0.0663]Steps:  98%|█████████▊| 12751/13000 [39:30<12:26,  3.00s/it, lr=9.12e-8, step_loss=0.0663]Steps:  98%|█████████▊| 12751/13000 [39:30<12:26,  3.00s/it, lr=9.05e-8, step_loss=0.0507]Steps:  98%|█████████▊| 12751/13000 [39:30<12:26,  3.00s/it, lr=9.05e-8, step_loss=0.132] Steps:  98%|█████████▊| 12751/13000 [39:30<12:26,  3.00s/it, lr=9.05e-8, step_loss=0.141]Steps:  98%|█████████▊| 12751/13000 [39:31<12:26,  3.00s/it, lr=9.05e-8, step_loss=0.116]Steps:  98%|█████████▊| 12752/13000 [39:31<10:32,  2.55s/it, lr=9.05e-8, step_loss=0.116]Steps:  98%|█████████▊| 12752/13000 [39:31<10:32,  2.55s/it, lr=8.98e-8, step_loss=0.148]Steps:  98%|█████████▊| 12752/13000 [39:32<10:32,  2.55s/it, lr=8.98e-8, step_loss=0.0365]Steps:  98%|█████████▊| 12752/13000 [39:32<10:32,  2.55s/it, lr=8.98e-8, step_loss=0.00393]Steps:  98%|█████████▊| 12752/13000 [39:32<10:32,  2.55s/it, lr=8.98e-8, step_loss=0.0562] Steps:  98%|█████████▊| 12753/13000 [39:33<09:06,  2.21s/it, lr=8.98e-8, step_loss=0.0562]Steps:  98%|█████████▊| 12753/13000 [39:33<09:06,  2.21s/it, lr=8.9e-8, step_loss=0.0431] Steps:  98%|█████████▊| 12753/13000 [39:33<09:06,  2.21s/it, lr=8.9e-8, step_loss=0.168] Steps:  98%|█████████▊| 12753/13000 [39:33<09:06,  2.21s/it, lr=8.9e-8, step_loss=0.435]Steps:  98%|█████████▊| 12753/13000 [39:34<09:06,  2.21s/it, lr=8.9e-8, step_loss=0.0339]Steps:  98%|█████████▊| 12754/13000 [39:34<08:10,  1.99s/it, lr=8.9e-8, step_loss=0.0339]Steps:  98%|█████████▊| 12754/13000 [39:34<08:10,  1.99s/it, lr=8.83e-8, step_loss=0.00464]Steps:  98%|█████████▊| 12754/13000 [39:35<08:10,  1.99s/it, lr=8.83e-8, step_loss=0.0177] Steps:  98%|█████████▊| 12754/13000 [39:35<08:10,  1.99s/it, lr=8.83e-8, step_loss=0.0163]Steps:  98%|█████████▊| 12754/13000 [39:35<08:10,  1.99s/it, lr=8.83e-8, step_loss=0.00879]Steps:  98%|█████████▊| 12755/13000 [39:36<07:28,  1.83s/it, lr=8.83e-8, step_loss=0.00879]Steps:  98%|█████████▊| 12755/13000 [39:36<07:28,  1.83s/it, lr=8.76e-8, step_loss=0.0477] Steps:  98%|█████████▊| 12755/13000 [39:36<07:28,  1.83s/it, lr=8.76e-8, step_loss=0.0754]Steps:  98%|█████████▊| 12756/13000 [39:36<06:03,  1.49s/it, lr=8.76e-8, step_loss=0.0754]Steps:  98%|█████████▊| 12756/13000 [39:36<06:03,  1.49s/it, lr=8.69e-8, step_loss=0.0538]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.11it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.89it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.66it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.18it/s]
02/23/2025 16:23:03 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12756/13000 [39:50<06:03,  1.49s/it, lr=8.69e-8, step_loss=0.247] Steps:  98%|█████████▊| 12756/13000 [39:51<06:03,  1.49s/it, lr=8.69e-8, step_loss=0.00648]Steps:  98%|█████████▊| 12756/13000 [39:51<06:03,  1.49s/it, lr=8.69e-8, step_loss=0.119]  Steps:  98%|█████████▊| 12757/13000 [39:52<22:47,  5.63s/it, lr=8.69e-8, step_loss=0.119]Steps:  98%|█████████▊| 12757/13000 [39:55<22:47,  5.63s/it, lr=8.62e-8, step_loss=0.113]Steps:  98%|█████████▊| 12757/13000 [39:55<22:47,  5.63s/it, lr=8.62e-8, step_loss=0.0121]Steps:  98%|█████████▊| 12757/13000 [39:55<22:47,  5.63s/it, lr=8.62e-8, step_loss=0.503] Steps:  98%|█████████▊| 12757/13000 [39:56<22:47,  5.63s/it, lr=8.62e-8, step_loss=0.0516]Steps:  98%|█████████▊| 12758/13000 [39:56<21:19,  5.29s/it, lr=8.62e-8, step_loss=0.0516]Steps:  98%|█████████▊| 12758/13000 [39:56<21:19,  5.29s/it, lr=8.55e-8, step_loss=0.19]  Steps:  98%|█████████▊| 12758/13000 [39:56<21:19,  5.29s/it, lr=8.55e-8, step_loss=0.287]Steps:  98%|█████████▊| 12758/13000 [39:57<21:19,  5.29s/it, lr=8.55e-8, step_loss=0.113]Steps:  98%|█████████▊| 12758/13000 [39:57<21:19,  5.29s/it, lr=8.55e-8, step_loss=0.0203]Steps:  98%|█████████▊| 12759/13000 [39:57<16:35,  4.13s/it, lr=8.55e-8, step_loss=0.0203]Steps:  98%|█████████▊| 12759/13000 [39:57<16:35,  4.13s/it, lr=8.48e-8, step_loss=0.0876]Steps:  98%|█████████▊| 12759/13000 [39:58<16:35,  4.13s/it, lr=8.48e-8, step_loss=0.0249]Steps:  98%|█████████▊| 12759/13000 [39:58<16:35,  4.13s/it, lr=8.48e-8, step_loss=0.388] Steps:  98%|█████████▊| 12759/13000 [39:59<16:35,  4.13s/it, lr=8.48e-8, step_loss=0.0285]Steps:  98%|█████████▊| 12760/13000 [39:59<13:19,  3.33s/it, lr=8.48e-8, step_loss=0.0285]Steps:  98%|█████████▊| 12760/13000 [39:59<13:19,  3.33s/it, lr=8.41e-8, step_loss=0.434] Steps:  98%|█████████▊| 12760/13000 [39:59<13:19,  3.33s/it, lr=8.41e-8, step_loss=0.0192]Steps:  98%|█████████▊| 12760/13000 [40:00<13:19,  3.33s/it, lr=8.41e-8, step_loss=0.122] Steps:  98%|█████████▊| 12760/13000 [40:00<13:19,  3.33s/it, lr=8.41e-8, step_loss=0.0425]Steps:  98%|█████████▊| 12761/13000 [40:00<11:01,  2.77s/it, lr=8.41e-8, step_loss=0.0425]Steps:  98%|█████████▊| 12761/13000 [40:00<11:01,  2.77s/it, lr=8.34e-8, step_loss=0.63]  Steps:  98%|█████████▊| 12761/13000 [40:01<11:01,  2.77s/it, lr=8.34e-8, step_loss=0.0542]Steps:  98%|█████████▊| 12761/13000 [40:01<11:01,  2.77s/it, lr=8.34e-8, step_loss=0.0279]Steps:  98%|█████████▊| 12761/13000 [40:01<11:01,  2.77s/it, lr=8.34e-8, step_loss=0.0699]Steps:  98%|█████████▊| 12762/13000 [40:02<09:24,  2.37s/it, lr=8.34e-8, step_loss=0.0699]Steps:  98%|█████████▊| 12762/13000 [40:02<09:24,  2.37s/it, lr=8.27e-8, step_loss=0.0334]Steps:  98%|█████████▊| 12762/13000 [40:02<09:24,  2.37s/it, lr=8.27e-8, step_loss=0.00397]Steps:  98%|█████████▊| 12762/13000 [40:03<09:24,  2.37s/it, lr=8.27e-8, step_loss=0.00449]Steps:  98%|█████████▊| 12762/13000 [40:03<09:24,  2.37s/it, lr=8.27e-8, step_loss=0.146]  Steps:  98%|█████████▊| 12763/13000 [40:03<08:16,  2.10s/it, lr=8.27e-8, step_loss=0.146]Steps:  98%|█████████▊| 12763/13000 [40:03<08:16,  2.10s/it, lr=8.2e-8, step_loss=0.00936]Steps:  98%|█████████▊| 12763/13000 [40:04<08:16,  2.10s/it, lr=8.2e-8, step_loss=0.113]  Steps:  98%|█████████▊| 12763/13000 [40:04<08:16,  2.10s/it, lr=8.2e-8, step_loss=0.156]Steps:  98%|█████████▊| 12763/13000 [40:04<08:16,  2.10s/it, lr=8.2e-8, step_loss=0.118]Steps:  98%|█████████▊| 12764/13000 [40:05<07:30,  1.91s/it, lr=8.2e-8, step_loss=0.118]Steps:  98%|█████████▊| 12764/13000 [40:05<07:30,  1.91s/it, lr=8.13e-8, step_loss=0.016]Steps:  98%|█████████▊| 12764/13000 [40:05<07:30,  1.91s/it, lr=8.13e-8, step_loss=0.254]Steps:  98%|█████████▊| 12765/13000 [40:05<06:01,  1.54s/it, lr=8.13e-8, step_loss=0.254]Steps:  98%|█████████▊| 12765/13000 [40:05<06:01,  1.54s/it, lr=8.06e-8, step_loss=0.127]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.04it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.30it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.79it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.34it/s]
02/23/2025 16:23:32 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12765/13000 [40:20<06:01,  1.54s/it, lr=8.06e-8, step_loss=0.097]Steps:  98%|█████████▊| 12765/13000 [40:20<06:01,  1.54s/it, lr=8.06e-8, step_loss=0.138]Steps:  98%|█████████▊| 12765/13000 [40:20<06:01,  1.54s/it, lr=8.06e-8, step_loss=0.335]Steps:  98%|█████████▊| 12766/13000 [40:21<22:04,  5.66s/it, lr=8.06e-8, step_loss=0.335]Steps:  98%|█████████▊| 12766/13000 [40:21<22:04,  5.66s/it, lr=7.99e-8, step_loss=0.0427]Steps:  98%|█████████▊| 12766/13000 [40:21<22:04,  5.66s/it, lr=7.99e-8, step_loss=0.0173]Steps:  98%|█████████▊| 12766/13000 [40:21<22:04,  5.66s/it, lr=7.99e-8, step_loss=0.0254]Steps:  98%|█████████▊| 12766/13000 [40:22<22:04,  5.66s/it, lr=7.99e-8, step_loss=0.143] Steps:  98%|█████████▊| 12767/13000 [40:22<17:02,  4.39s/it, lr=7.99e-8, step_loss=0.143]Steps:  98%|█████████▊| 12767/13000 [40:22<17:02,  4.39s/it, lr=7.92e-8, step_loss=0.181]Steps:  98%|█████████▊| 12767/13000 [40:23<17:02,  4.39s/it, lr=7.92e-8, step_loss=0.0973]Steps:  98%|█████████▊| 12767/13000 [40:23<17:02,  4.39s/it, lr=7.92e-8, step_loss=0.00845]Steps:  98%|█████████▊| 12767/13000 [40:23<17:02,  4.39s/it, lr=7.92e-8, step_loss=0.0121] Steps:  98%|█████████▊| 12768/13000 [40:24<13:33,  3.51s/it, lr=7.92e-8, step_loss=0.0121]Steps:  98%|█████████▊| 12768/13000 [40:24<13:33,  3.51s/it, lr=7.86e-8, step_loss=0.0111]Steps:  98%|█████████▊| 12768/13000 [40:24<13:33,  3.51s/it, lr=7.86e-8, step_loss=0.0628]Steps:  98%|█████████▊| 12768/13000 [40:24<13:33,  3.51s/it, lr=7.86e-8, step_loss=0.0442]Steps:  98%|█████████▊| 12768/13000 [40:25<13:33,  3.51s/it, lr=7.86e-8, step_loss=0.0276]Steps:  98%|█████████▊| 12769/13000 [40:25<11:07,  2.89s/it, lr=7.86e-8, step_loss=0.0276]Steps:  98%|█████████▊| 12769/13000 [40:25<11:07,  2.89s/it, lr=7.79e-8, step_loss=0.0393]Steps:  98%|█████████▊| 12769/13000 [40:25<11:07,  2.89s/it, lr=7.79e-8, step_loss=0.0727]Steps:  98%|█████████▊| 12769/13000 [40:26<11:07,  2.89s/it, lr=7.79e-8, step_loss=0.0233]Steps:  98%|█████████▊| 12769/13000 [40:26<11:07,  2.89s/it, lr=7.79e-8, step_loss=0.226] Steps:  98%|█████████▊| 12770/13000 [40:26<09:25,  2.46s/it, lr=7.79e-8, step_loss=0.226]Steps:  98%|█████████▊| 12770/13000 [40:26<09:25,  2.46s/it, lr=7.72e-8, step_loss=0.0127]Steps:  98%|█████████▊| 12770/13000 [40:27<09:25,  2.46s/it, lr=7.72e-8, step_loss=0.0262]Steps:  98%|█████████▊| 12770/13000 [40:27<09:25,  2.46s/it, lr=7.72e-8, step_loss=0.00341]Steps:  98%|█████████▊| 12770/13000 [40:28<09:25,  2.46s/it, lr=7.72e-8, step_loss=0.0271] Steps:  98%|█████████▊| 12771/13000 [40:28<08:12,  2.15s/it, lr=7.72e-8, step_loss=0.0271]Steps:  98%|█████████▊| 12771/13000 [40:28<08:12,  2.15s/it, lr=7.65e-8, step_loss=0.0192]Steps:  98%|█████████▊| 12771/13000 [40:28<08:12,  2.15s/it, lr=7.65e-8, step_loss=0.0249]Steps:  98%|█████████▊| 12771/13000 [40:29<08:12,  2.15s/it, lr=7.65e-8, step_loss=0.0149]Steps:  98%|█████████▊| 12771/13000 [40:29<08:12,  2.15s/it, lr=7.65e-8, step_loss=0.109] Steps:  98%|█████████▊| 12772/13000 [40:29<07:21,  1.94s/it, lr=7.65e-8, step_loss=0.109]Steps:  98%|█████████▊| 12772/13000 [40:29<07:21,  1.94s/it, lr=7.59e-8, step_loss=0.0829]Steps:  98%|█████████▊| 12772/13000 [40:30<07:21,  1.94s/it, lr=7.59e-8, step_loss=0.00713]Steps:  98%|█████████▊| 12772/13000 [40:30<07:21,  1.94s/it, lr=7.59e-8, step_loss=0.0256] Steps:  98%|█████████▊| 12772/13000 [40:30<07:21,  1.94s/it, lr=7.59e-8, step_loss=0.00444]Steps:  98%|█████████▊| 12773/13000 [40:31<06:47,  1.80s/it, lr=7.59e-8, step_loss=0.00444]Steps:  98%|█████████▊| 12773/13000 [40:31<06:47,  1.80s/it, lr=7.52e-8, step_loss=0.117]  Steps:  98%|█████████▊| 12773/13000 [40:31<06:47,  1.80s/it, lr=7.52e-8, step_loss=0.27] Steps:  98%|█████████▊| 12774/13000 [40:31<05:32,  1.47s/it, lr=7.52e-8, step_loss=0.27]Steps:  98%|█████████▊| 12774/13000 [40:32<05:32,  1.47s/it, lr=7.46e-8, step_loss=0.185]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.14it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.93it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.64it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.18it/s]
02/23/2025 16:23:58 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12774/13000 [40:46<05:32,  1.47s/it, lr=7.46e-8, step_loss=0.00924]Steps:  98%|█████████▊| 12774/13000 [40:46<05:32,  1.47s/it, lr=7.46e-8, step_loss=0.14]   Steps:  98%|█████████▊| 12774/13000 [40:47<05:32,  1.47s/it, lr=7.46e-8, step_loss=0.203]Steps:  98%|█████████▊| 12775/13000 [40:47<21:15,  5.67s/it, lr=7.46e-8, step_loss=0.203]Steps:  98%|█████████▊| 12775/13000 [40:47<21:15,  5.67s/it, lr=7.39e-8, step_loss=0.0157]Steps:  98%|█████████▊| 12775/13000 [40:47<21:15,  5.67s/it, lr=7.39e-8, step_loss=0.428] Steps:  98%|█████████▊| 12775/13000 [40:48<21:15,  5.67s/it, lr=7.39e-8, step_loss=0.016]Steps:  98%|█████████▊| 12775/13000 [40:48<21:15,  5.67s/it, lr=7.39e-8, step_loss=0.138]Steps:  98%|█████████▊| 12776/13000 [40:48<16:25,  4.40s/it, lr=7.39e-8, step_loss=0.138]Steps:  98%|█████████▊| 12776/13000 [40:48<16:25,  4.40s/it, lr=7.32e-8, step_loss=0.0153]Steps:  98%|█████████▊| 12776/13000 [40:49<16:25,  4.40s/it, lr=7.32e-8, step_loss=0.0217]Steps:  98%|█████████▊| 12776/13000 [40:49<16:25,  4.40s/it, lr=7.32e-8, step_loss=0.0159]Steps:  98%|█████████▊| 12776/13000 [40:50<16:25,  4.40s/it, lr=7.32e-8, step_loss=0.059] Steps:  98%|█████████▊| 12777/13000 [40:50<13:07,  3.53s/it, lr=7.32e-8, step_loss=0.059]Steps:  98%|█████████▊| 12777/13000 [40:50<13:07,  3.53s/it, lr=7.26e-8, step_loss=0.0362]Steps:  98%|█████████▊| 12777/13000 [40:50<13:07,  3.53s/it, lr=7.26e-8, step_loss=0.0846]Steps:  98%|█████████▊| 12777/13000 [40:51<13:07,  3.53s/it, lr=7.26e-8, step_loss=0.465] Steps:  98%|█████████▊| 12777/13000 [40:51<13:07,  3.53s/it, lr=7.26e-8, step_loss=0.258]Steps:  98%|█████████▊| 12778/13000 [40:51<10:46,  2.91s/it, lr=7.26e-8, step_loss=0.258]Steps:  98%|█████████▊| 12778/13000 [40:51<10:46,  2.91s/it, lr=7.19e-8, step_loss=0.0112]Steps:  98%|█████████▊| 12778/13000 [40:52<10:46,  2.91s/it, lr=7.19e-8, step_loss=0.0532]Steps:  98%|█████████▊| 12778/13000 [40:52<10:46,  2.91s/it, lr=7.19e-8, step_loss=0.00298]Steps:  98%|█████████▊| 12778/13000 [40:53<10:46,  2.91s/it, lr=7.19e-8, step_loss=0.0233] Steps:  98%|█████████▊| 12779/13000 [40:53<09:07,  2.48s/it, lr=7.19e-8, step_loss=0.0233]Steps:  98%|█████████▊| 12779/13000 [40:53<09:07,  2.48s/it, lr=7.13e-8, step_loss=0.00307]Steps:  98%|█████████▊| 12779/13000 [40:53<09:07,  2.48s/it, lr=7.13e-8, step_loss=0.00337]Steps:  98%|█████████▊| 12779/13000 [40:54<09:07,  2.48s/it, lr=7.13e-8, step_loss=0.143]  Steps:  98%|█████████▊| 12779/13000 [40:54<09:07,  2.48s/it, lr=7.13e-8, step_loss=0.00518]Steps:  98%|█████████▊| 12780/13000 [40:54<07:57,  2.17s/it, lr=7.13e-8, step_loss=0.00518]Steps:  98%|█████████▊| 12780/13000 [40:54<07:57,  2.17s/it, lr=7.06e-8, step_loss=0.0468] Steps:  98%|█████████▊| 12780/13000 [40:55<07:57,  2.17s/it, lr=7.06e-8, step_loss=0.0465]Steps:  98%|█████████▊| 12780/13000 [40:55<07:57,  2.17s/it, lr=7.06e-8, step_loss=0.0151]Steps:  98%|█████████▊| 12780/13000 [40:55<07:57,  2.17s/it, lr=7.06e-8, step_loss=0.0529]Steps:  98%|█████████▊| 12781/13000 [40:56<07:09,  1.96s/it, lr=7.06e-8, step_loss=0.0529]Steps:  98%|█████████▊| 12781/13000 [40:56<07:09,  1.96s/it, lr=7e-8, step_loss=0.142]    Steps:  98%|█████████▊| 12781/13000 [40:56<07:09,  1.96s/it, lr=7e-8, step_loss=0.0416]Steps:  98%|█████████▊| 12781/13000 [40:57<07:09,  1.96s/it, lr=7e-8, step_loss=0.0102]Steps:  98%|█████████▊| 12781/13000 [40:57<07:09,  1.96s/it, lr=7e-8, step_loss=0.053] Steps:  98%|█████████▊| 12782/13000 [40:57<06:31,  1.80s/it, lr=7e-8, step_loss=0.053]Steps:  98%|█████████▊| 12782/13000 [40:57<06:31,  1.80s/it, lr=6.94e-8, step_loss=0.0128]Steps:  98%|█████████▊| 12782/13000 [40:58<06:31,  1.80s/it, lr=6.94e-8, step_loss=0.76]  Steps:  98%|█████████▊| 12783/13000 [40:58<05:17,  1.46s/it, lr=6.94e-8, step_loss=0.76]Steps:  98%|█████████▊| 12783/13000 [40:58<05:17,  1.46s/it, lr=6.87e-8, step_loss=0.139]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.21it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.20it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.96it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.48it/s]
02/23/2025 16:24:24 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12783/13000 [41:12<05:17,  1.46s/it, lr=6.87e-8, step_loss=0.054]Steps:  98%|█████████▊| 12783/13000 [41:13<05:17,  1.46s/it, lr=6.87e-8, step_loss=0.0941]Steps:  98%|█████████▊| 12783/13000 [41:13<05:17,  1.46s/it, lr=6.87e-8, step_loss=0.00278]Steps:  98%|█████████▊| 12784/13000 [41:13<20:32,  5.71s/it, lr=6.87e-8, step_loss=0.00278]Steps:  98%|█████████▊| 12784/13000 [41:14<20:32,  5.71s/it, lr=6.81e-8, step_loss=0.146]  Steps:  98%|█████████▊| 12784/13000 [41:14<20:32,  5.71s/it, lr=6.81e-8, step_loss=0.0413]Steps:  98%|█████████▊| 12784/13000 [41:14<20:32,  5.71s/it, lr=6.81e-8, step_loss=0.087] Steps:  98%|█████████▊| 12784/13000 [41:15<20:32,  5.71s/it, lr=6.81e-8, step_loss=0.166]Steps:  98%|█████████▊| 12785/13000 [41:15<15:54,  4.44s/it, lr=6.81e-8, step_loss=0.166]Steps:  98%|█████████▊| 12785/13000 [41:15<15:54,  4.44s/it, lr=6.75e-8, step_loss=0.174]Steps:  98%|█████████▊| 12785/13000 [41:15<15:54,  4.44s/it, lr=6.75e-8, step_loss=0.271]Steps:  98%|█████████▊| 12785/13000 [41:16<15:54,  4.44s/it, lr=6.75e-8, step_loss=0.00923]Steps:  98%|█████████▊| 12785/13000 [41:16<15:54,  4.44s/it, lr=6.75e-8, step_loss=0.011]  Steps:  98%|█████████▊| 12786/13000 [41:16<12:38,  3.54s/it, lr=6.75e-8, step_loss=0.011]Steps:  98%|█████████▊| 12786/13000 [41:17<12:38,  3.54s/it, lr=6.68e-8, step_loss=0.126]Steps:  98%|█████████▊| 12786/13000 [41:17<12:38,  3.54s/it, lr=6.68e-8, step_loss=0.0907]Steps:  98%|█████████▊| 12786/13000 [41:17<12:38,  3.54s/it, lr=6.68e-8, step_loss=0.0221]Steps:  98%|█████████▊| 12786/13000 [41:18<12:38,  3.54s/it, lr=6.68e-8, step_loss=0.133] Steps:  98%|█████████▊| 12787/13000 [41:18<10:29,  2.95s/it, lr=6.68e-8, step_loss=0.133]Steps:  98%|█████████▊| 12787/13000 [41:18<10:29,  2.95s/it, lr=6.62e-8, step_loss=0.0155]Steps:  98%|█████████▊| 12787/13000 [41:18<10:29,  2.95s/it, lr=6.62e-8, step_loss=0.0326]Steps:  98%|█████████▊| 12787/13000 [41:19<10:29,  2.95s/it, lr=6.62e-8, step_loss=0.0222]Steps:  98%|█████████▊| 12787/13000 [41:19<10:29,  2.95s/it, lr=6.62e-8, step_loss=0.318] Steps:  98%|█████████▊| 12788/13000 [41:19<08:49,  2.50s/it, lr=6.62e-8, step_loss=0.318]Steps:  98%|█████████▊| 12788/13000 [41:19<08:49,  2.50s/it, lr=6.56e-8, step_loss=0.122]Steps:  98%|█████████▊| 12788/13000 [41:20<08:49,  2.50s/it, lr=6.56e-8, step_loss=0.0106]Steps:  98%|█████████▊| 12788/13000 [41:20<08:49,  2.50s/it, lr=6.56e-8, step_loss=0.0154]Steps:  98%|█████████▊| 12788/13000 [41:21<08:49,  2.50s/it, lr=6.56e-8, step_loss=0.00857]Steps:  98%|█████████▊| 12789/13000 [41:21<07:41,  2.19s/it, lr=6.56e-8, step_loss=0.00857]Steps:  98%|█████████▊| 12789/13000 [41:21<07:41,  2.19s/it, lr=6.5e-8, step_loss=0.127]   Steps:  98%|█████████▊| 12789/13000 [41:21<07:41,  2.19s/it, lr=6.5e-8, step_loss=0.0275]Steps:  98%|█████████▊| 12789/13000 [41:22<07:41,  2.19s/it, lr=6.5e-8, step_loss=0.0804]Steps:  98%|█████████▊| 12789/13000 [41:22<07:41,  2.19s/it, lr=6.5e-8, step_loss=0.00663]Steps:  98%|█████████▊| 12790/13000 [41:22<06:51,  1.96s/it, lr=6.5e-8, step_loss=0.00663]Steps:  98%|█████████▊| 12790/13000 [41:22<06:51,  1.96s/it, lr=6.44e-8, step_loss=0.0359]Steps:  98%|█████████▊| 12790/13000 [41:23<06:51,  1.96s/it, lr=6.44e-8, step_loss=0.0895]Steps:  98%|█████████▊| 12790/13000 [41:23<06:51,  1.96s/it, lr=6.44e-8, step_loss=0.211] Steps:  98%|█████████▊| 12790/13000 [41:23<06:51,  1.96s/it, lr=6.44e-8, step_loss=0.148]Steps:  98%|█████████▊| 12791/13000 [41:24<06:16,  1.80s/it, lr=6.44e-8, step_loss=0.148]Steps:  98%|█████████▊| 12791/13000 [41:24<06:16,  1.80s/it, lr=6.38e-8, step_loss=0.109]Steps:  98%|█████████▊| 12791/13000 [41:24<06:16,  1.80s/it, lr=6.38e-8, step_loss=0.0214]Steps:  98%|█████████▊| 12792/13000 [41:24<05:05,  1.47s/it, lr=6.38e-8, step_loss=0.0214]Steps:  98%|█████████▊| 12792/13000 [41:24<05:05,  1.47s/it, lr=6.32e-8, step_loss=0.0036]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.16it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.51it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.77it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.36it/s]
02/23/2025 16:24:51 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12792/13000 [41:39<05:05,  1.47s/it, lr=6.32e-8, step_loss=0.147] Steps:  98%|█████████▊| 12792/13000 [41:39<05:05,  1.47s/it, lr=6.32e-8, step_loss=0.012]Steps:  98%|█████████▊| 12792/13000 [41:40<05:05,  1.47s/it, lr=6.32e-8, step_loss=0.0159]Steps:  98%|█████████▊| 12793/13000 [41:40<19:35,  5.68s/it, lr=6.32e-8, step_loss=0.0159]Steps:  98%|█████████▊| 12793/13000 [41:40<19:35,  5.68s/it, lr=6.25e-8, step_loss=0.329] Steps:  98%|█████████▊| 12793/13000 [41:40<19:35,  5.68s/it, lr=6.25e-8, step_loss=0.221]Steps:  98%|█████████▊| 12793/13000 [41:41<19:35,  5.68s/it, lr=6.25e-8, step_loss=0.138]Steps:  98%|█████████▊| 12793/13000 [41:41<19:35,  5.68s/it, lr=6.25e-8, step_loss=0.0327]Steps:  98%|█████████▊| 12794/13000 [41:41<15:05,  4.39s/it, lr=6.25e-8, step_loss=0.0327]Steps:  98%|█████████▊| 12794/13000 [41:41<15:05,  4.39s/it, lr=6.19e-8, step_loss=0.026] Steps:  98%|█████████▊| 12794/13000 [41:42<15:05,  4.39s/it, lr=6.19e-8, step_loss=0.222]Steps:  98%|█████████▊| 12794/13000 [41:42<15:05,  4.39s/it, lr=6.19e-8, step_loss=0.0192]Steps:  98%|█████████▊| 12794/13000 [41:42<15:05,  4.39s/it, lr=6.19e-8, step_loss=0.00892]Steps:  98%|█████████▊| 12795/13000 [41:43<12:01,  3.52s/it, lr=6.19e-8, step_loss=0.00892]Steps:  98%|█████████▊| 12795/13000 [41:43<12:01,  3.52s/it, lr=6.13e-8, step_loss=0.00428]Steps:  98%|█████████▊| 12795/13000 [41:43<12:01,  3.52s/it, lr=6.13e-8, step_loss=0.0298] Steps:  98%|█████████▊| 12795/13000 [41:44<12:01,  3.52s/it, lr=6.13e-8, step_loss=0.0533]Steps:  98%|█████████▊| 12795/13000 [41:44<12:01,  3.52s/it, lr=6.13e-8, step_loss=0.027] Steps:  98%|█████████▊| 12796/13000 [41:44<09:56,  2.92s/it, lr=6.13e-8, step_loss=0.027]Steps:  98%|█████████▊| 12796/13000 [41:44<09:56,  2.92s/it, lr=6.07e-8, step_loss=0.0128]Steps:  98%|█████████▊| 12796/13000 [41:45<09:56,  2.92s/it, lr=6.07e-8, step_loss=0.0221]Steps:  98%|█████████▊| 12796/13000 [41:45<09:56,  2.92s/it, lr=6.07e-8, step_loss=0.0834]Steps:  98%|█████████▊| 12796/13000 [41:45<09:56,  2.92s/it, lr=6.07e-8, step_loss=0.0488]Steps:  98%|█████████▊| 12797/13000 [41:46<08:26,  2.49s/it, lr=6.07e-8, step_loss=0.0488]Steps:  98%|█████████▊| 12797/13000 [41:46<08:26,  2.49s/it, lr=6.02e-8, step_loss=0.225] Steps:  98%|█████████▊| 12797/13000 [41:46<08:26,  2.49s/it, lr=6.02e-8, step_loss=0.112]Steps:  98%|█████████▊| 12797/13000 [41:47<08:26,  2.49s/it, lr=6.02e-8, step_loss=0.0103]Steps:  98%|█████████▊| 12797/13000 [41:47<08:26,  2.49s/it, lr=6.02e-8, step_loss=0.00897]Steps:  98%|█████████▊| 12798/13000 [41:47<07:20,  2.18s/it, lr=6.02e-8, step_loss=0.00897]Steps:  98%|█████████▊| 12798/13000 [41:47<07:20,  2.18s/it, lr=5.96e-8, step_loss=0.143]  Steps:  98%|█████████▊| 12798/13000 [41:48<07:20,  2.18s/it, lr=5.96e-8, step_loss=0.00817]Steps:  98%|█████████▊| 12798/13000 [41:48<07:20,  2.18s/it, lr=5.96e-8, step_loss=0.00485]Steps:  98%|█████████▊| 12798/13000 [41:48<07:20,  2.18s/it, lr=5.96e-8, step_loss=0.151]  Steps:  98%|█████████▊| 12799/13000 [41:49<06:35,  1.97s/it, lr=5.96e-8, step_loss=0.151]Steps:  98%|█████████▊| 12799/13000 [41:49<06:35,  1.97s/it, lr=5.9e-8, step_loss=0.0565]Steps:  98%|█████████▊| 12799/13000 [41:49<06:35,  1.97s/it, lr=5.9e-8, step_loss=0.0601]Steps:  98%|█████████▊| 12799/13000 [41:50<06:35,  1.97s/it, lr=5.9e-8, step_loss=0.033] Steps:  98%|█████████▊| 12799/13000 [41:50<06:35,  1.97s/it, lr=5.9e-8, step_loss=0.0348]Steps:  98%|█████████▊| 12800/13000 [41:50<06:02,  1.81s/it, lr=5.9e-8, step_loss=0.0348]Steps:  98%|█████████▊| 12800/13000 [41:50<06:02,  1.81s/it, lr=5.84e-8, step_loss=0.195]Steps:  98%|█████████▊| 12800/13000 [41:51<06:02,  1.81s/it, lr=5.84e-8, step_loss=0.0204]Steps:  98%|█████████▊| 12801/13000 [41:51<04:53,  1.48s/it, lr=5.84e-8, step_loss=0.0204]Steps:  98%|█████████▊| 12801/13000 [41:51<04:53,  1.48s/it, lr=5.78e-8, step_loss=0.0463]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.91it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.58it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.88it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.44it/s]
02/23/2025 16:25:17 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  98%|█████████▊| 12801/13000 [42:05<04:53,  1.48s/it, lr=5.78e-8, step_loss=0.0505]Steps:  98%|█████████▊| 12801/13000 [42:06<04:53,  1.48s/it, lr=5.78e-8, step_loss=0.00538]Steps:  98%|█████████▊| 12801/13000 [42:06<04:53,  1.48s/it, lr=5.78e-8, step_loss=0.0775] Steps:  98%|█████████▊| 12802/13000 [42:06<18:45,  5.68s/it, lr=5.78e-8, step_loss=0.0775]Steps:  98%|█████████▊| 12802/13000 [42:06<18:45,  5.68s/it, lr=5.72e-8, step_loss=0.076] Steps:  98%|█████████▊| 12802/13000 [42:07<18:45,  5.68s/it, lr=5.72e-8, step_loss=0.339]Steps:  98%|█████████▊| 12802/13000 [42:07<18:45,  5.68s/it, lr=5.72e-8, step_loss=0.0257]Steps:  98%|█████████▊| 12802/13000 [42:08<18:45,  5.68s/it, lr=5.72e-8, step_loss=0.194] Steps:  98%|█████████▊| 12803/13000 [42:08<14:27,  4.40s/it, lr=5.72e-8, step_loss=0.194]Steps:  98%|█████████▊| 12803/13000 [42:08<14:27,  4.40s/it, lr=5.67e-8, step_loss=0.00975]Steps:  98%|█████████▊| 12803/13000 [42:08<14:27,  4.40s/it, lr=5.67e-8, step_loss=0.0333] Steps:  98%|█████████▊| 12803/13000 [42:09<14:27,  4.40s/it, lr=5.67e-8, step_loss=0.0475]Steps:  98%|█████████▊| 12803/13000 [42:09<14:27,  4.40s/it, lr=5.67e-8, step_loss=0.0348]Steps:  98%|█████████▊| 12804/13000 [42:09<11:31,  3.53s/it, lr=5.67e-8, step_loss=0.0348]Steps:  98%|█████████▊| 12804/13000 [42:09<11:31,  3.53s/it, lr=5.61e-8, step_loss=0.0188]Steps:  98%|█████████▊| 12804/13000 [42:10<11:31,  3.53s/it, lr=5.61e-8, step_loss=0.0598]Steps:  98%|█████████▊| 12804/13000 [42:10<11:31,  3.53s/it, lr=5.61e-8, step_loss=0.0366]Steps:  98%|█████████▊| 12804/13000 [42:10<11:31,  3.53s/it, lr=5.61e-8, step_loss=0.593] Steps:  98%|█████████▊| 12805/13000 [42:11<09:25,  2.90s/it, lr=5.61e-8, step_loss=0.593]Steps:  98%|█████████▊| 12805/13000 [42:11<09:25,  2.90s/it, lr=5.55e-8, step_loss=0.00809]Steps:  98%|█████████▊| 12805/13000 [42:11<09:25,  2.90s/it, lr=5.55e-8, step_loss=0.0123] Steps:  98%|█████████▊| 12805/13000 [42:12<09:25,  2.90s/it, lr=5.55e-8, step_loss=0.0101]Steps:  98%|█████████▊| 12805/13000 [42:12<09:25,  2.90s/it, lr=5.55e-8, step_loss=0.0505]Steps:  99%|█████████▊| 12806/13000 [42:12<07:57,  2.46s/it, lr=5.55e-8, step_loss=0.0505]Steps:  99%|█████████▊| 12806/13000 [42:12<07:57,  2.46s/it, lr=5.49e-8, step_loss=0.652] Steps:  99%|█████████▊| 12806/13000 [42:13<07:57,  2.46s/it, lr=5.49e-8, step_loss=0.393]Steps:  99%|█████████▊| 12806/13000 [42:13<07:57,  2.46s/it, lr=5.49e-8, step_loss=0.0808]Steps:  99%|█████████▊| 12806/13000 [42:13<07:57,  2.46s/it, lr=5.49e-8, step_loss=0.0794]Steps:  99%|█████████▊| 12807/13000 [42:14<06:57,  2.16s/it, lr=5.49e-8, step_loss=0.0794]Steps:  99%|█████████▊| 12807/13000 [42:14<06:57,  2.16s/it, lr=5.44e-8, step_loss=0.112] Steps:  99%|█████████▊| 12807/13000 [42:14<06:57,  2.16s/it, lr=5.44e-8, step_loss=0.0986]Steps:  99%|█████████▊| 12807/13000 [42:14<06:57,  2.16s/it, lr=5.44e-8, step_loss=0.0495]Steps:  99%|█████████▊| 12807/13000 [42:15<06:57,  2.16s/it, lr=5.44e-8, step_loss=0.0927]Steps:  99%|█████████▊| 12808/13000 [42:15<06:16,  1.96s/it, lr=5.44e-8, step_loss=0.0927]Steps:  99%|█████████▊| 12808/13000 [42:15<06:16,  1.96s/it, lr=5.38e-8, step_loss=0.0119]Steps:  99%|█████████▊| 12808/13000 [42:16<06:16,  1.96s/it, lr=5.38e-8, step_loss=0.106] Steps:  99%|█████████▊| 12808/13000 [42:16<06:16,  1.96s/it, lr=5.38e-8, step_loss=0.249]Steps:  99%|█████████▊| 12808/13000 [42:16<06:16,  1.96s/it, lr=5.38e-8, step_loss=0.0666]Steps:  99%|█████████▊| 12809/13000 [42:17<05:44,  1.81s/it, lr=5.38e-8, step_loss=0.0666]Steps:  99%|█████████▊| 12809/13000 [42:17<05:44,  1.81s/it, lr=5.33e-8, step_loss=0.0191]Steps:  99%|█████████▊| 12809/13000 [42:17<05:44,  1.81s/it, lr=5.33e-8, step_loss=0.171] Steps:  99%|█████████▊| 12810/13000 [42:17<04:39,  1.47s/it, lr=5.33e-8, step_loss=0.171]Steps:  99%|█████████▊| 12810/13000 [42:17<04:39,  1.47s/it, lr=5.27e-8, step_loss=0.363]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.55it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.53it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.42it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.96it/s]
02/23/2025 16:25:44 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▊| 12810/13000 [42:32<04:39,  1.47s/it, lr=5.27e-8, step_loss=0.0508]Steps:  99%|█████████▊| 12810/13000 [42:32<04:39,  1.47s/it, lr=5.27e-8, step_loss=0.103] Steps:  99%|█████████▊| 12810/13000 [42:33<04:39,  1.47s/it, lr=5.27e-8, step_loss=0.0412]Steps:  99%|█████████▊| 12811/13000 [42:33<18:00,  5.72s/it, lr=5.27e-8, step_loss=0.0412]Steps:  99%|█████████▊| 12811/13000 [42:33<18:00,  5.72s/it, lr=5.21e-8, step_loss=0.073] Steps:  99%|█████████▊| 12811/13000 [42:33<18:00,  5.72s/it, lr=5.21e-8, step_loss=0.0677]Steps:  99%|█████████▊| 12811/13000 [42:34<18:00,  5.72s/it, lr=5.21e-8, step_loss=0.0289]Steps:  99%|█████████▊| 12811/13000 [42:34<18:00,  5.72s/it, lr=5.21e-8, step_loss=0.0366]Steps:  99%|█████████▊| 12812/13000 [42:34<13:56,  4.45s/it, lr=5.21e-8, step_loss=0.0366]Steps:  99%|█████████▊| 12812/13000 [42:34<13:56,  4.45s/it, lr=5.16e-8, step_loss=0.0578]Steps:  99%|█████████▊| 12812/13000 [42:35<13:56,  4.45s/it, lr=5.16e-8, step_loss=0.158] Steps:  99%|█████████▊| 12812/13000 [42:35<13:56,  4.45s/it, lr=5.16e-8, step_loss=0.0404]Steps:  99%|█████████▊| 12812/13000 [42:35<13:56,  4.45s/it, lr=5.16e-8, step_loss=0.0795]Steps:  99%|█████████▊| 12813/13000 [42:36<11:04,  3.55s/it, lr=5.16e-8, step_loss=0.0795]Steps:  99%|█████████▊| 12813/13000 [42:36<11:04,  3.55s/it, lr=5.1e-8, step_loss=0.579]  Steps:  99%|█████████▊| 12813/13000 [42:36<11:04,  3.55s/it, lr=5.1e-8, step_loss=0.13] Steps:  99%|█████████▊| 12813/13000 [42:37<11:04,  3.55s/it, lr=5.1e-8, step_loss=0.149]Steps:  99%|█████████▊| 12813/13000 [42:37<11:04,  3.55s/it, lr=5.1e-8, step_loss=0.243]Steps:  99%|█████████▊| 12814/13000 [42:37<09:03,  2.92s/it, lr=5.1e-8, step_loss=0.243]Steps:  99%|█████████▊| 12814/13000 [42:37<09:03,  2.92s/it, lr=5.05e-8, step_loss=0.0413]Steps:  99%|█████████▊| 12814/13000 [42:38<09:03,  2.92s/it, lr=5.05e-8, step_loss=0.103] Steps:  99%|█████████▊| 12814/13000 [42:38<09:03,  2.92s/it, lr=5.05e-8, step_loss=0.218]Steps:  99%|█████████▊| 12814/13000 [42:38<09:03,  2.92s/it, lr=5.05e-8, step_loss=0.0148]Steps:  99%|█████████▊| 12815/13000 [42:39<07:38,  2.48s/it, lr=5.05e-8, step_loss=0.0148]Steps:  99%|█████████▊| 12815/13000 [42:39<07:38,  2.48s/it, lr=5e-8, step_loss=0.161]    Steps:  99%|█████████▊| 12815/13000 [42:39<07:38,  2.48s/it, lr=5e-8, step_loss=0.00609]Steps:  99%|█████████▊| 12815/13000 [42:39<07:38,  2.48s/it, lr=5e-8, step_loss=0.032]  Steps:  99%|█████████▊| 12815/13000 [42:40<07:38,  2.48s/it, lr=5e-8, step_loss=0.377]Steps:  99%|█████████▊| 12816/13000 [42:40<06:38,  2.16s/it, lr=5e-8, step_loss=0.377]Steps:  99%|█████████▊| 12816/13000 [42:40<06:38,  2.16s/it, lr=4.94e-8, step_loss=0.0203]Steps:  99%|█████████▊| 12816/13000 [42:41<06:38,  2.16s/it, lr=4.94e-8, step_loss=0.0115]Steps:  99%|█████████▊| 12816/13000 [42:41<06:38,  2.16s/it, lr=4.94e-8, step_loss=0.165] Steps:  99%|█████████▊| 12816/13000 [42:41<06:38,  2.16s/it, lr=4.94e-8, step_loss=0.0221]Steps:  99%|█████████▊| 12817/13000 [42:42<05:55,  1.94s/it, lr=4.94e-8, step_loss=0.0221]Steps:  99%|█████████▊| 12817/13000 [42:42<05:55,  1.94s/it, lr=4.89e-8, step_loss=0.0357]Steps:  99%|█████████▊| 12817/13000 [42:42<05:55,  1.94s/it, lr=4.89e-8, step_loss=0.469] Steps:  99%|█████████▊| 12817/13000 [42:42<05:55,  1.94s/it, lr=4.89e-8, step_loss=0.323]Steps:  99%|█████████▊| 12817/13000 [42:43<05:55,  1.94s/it, lr=4.89e-8, step_loss=0.255]Steps:  99%|█████████▊| 12818/13000 [42:43<05:26,  1.80s/it, lr=4.89e-8, step_loss=0.255]Steps:  99%|█████████▊| 12818/13000 [42:43<05:26,  1.80s/it, lr=4.84e-8, step_loss=0.0466]Steps:  99%|█████████▊| 12818/13000 [42:43<05:26,  1.80s/it, lr=4.84e-8, step_loss=0.238] Steps:  99%|█████████▊| 12819/13000 [42:44<04:25,  1.46s/it, lr=4.84e-8, step_loss=0.238]Steps:  99%|█████████▊| 12819/13000 [42:44<04:25,  1.46s/it, lr=4.78e-8, step_loss=0.11] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.04it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.37it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.75it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.32it/s]
02/23/2025 16:26:10 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▊| 12819/13000 [42:58<04:25,  1.46s/it, lr=4.78e-8, step_loss=0.0101]Steps:  99%|█████████▊| 12819/13000 [42:59<04:25,  1.46s/it, lr=4.78e-8, step_loss=0.413] Steps:  99%|█████████▊| 12819/13000 [42:59<04:25,  1.46s/it, lr=4.78e-8, step_loss=0.0211]Steps:  99%|█████████▊| 12820/13000 [42:59<17:02,  5.68s/it, lr=4.78e-8, step_loss=0.0211]Steps:  99%|█████████▊| 12820/13000 [42:59<17:02,  5.68s/it, lr=4.73e-8, step_loss=0.00996]Steps:  99%|█████████▊| 12820/13000 [43:00<17:02,  5.68s/it, lr=4.73e-8, step_loss=0.016]  Steps:  99%|█████████▊| 12820/13000 [43:00<17:02,  5.68s/it, lr=4.73e-8, step_loss=0.05] Steps:  99%|█████████▊| 12820/13000 [43:00<17:02,  5.68s/it, lr=4.73e-8, step_loss=0.302]Steps:  99%|█████████▊| 12821/13000 [43:01<13:09,  4.41s/it, lr=4.73e-8, step_loss=0.302]Steps:  99%|█████████▊| 12821/13000 [43:01<13:09,  4.41s/it, lr=4.68e-8, step_loss=0.0133]Steps:  99%|█████████▊| 12821/13000 [43:01<13:09,  4.41s/it, lr=4.68e-8, step_loss=0.0348]Steps:  99%|█████████▊| 12821/13000 [43:01<13:09,  4.41s/it, lr=4.68e-8, step_loss=0.501] Steps:  99%|█████████▊| 12821/13000 [43:02<13:09,  4.41s/it, lr=4.68e-8, step_loss=0.00612]Steps:  99%|█████████▊| 12822/13000 [43:02<10:26,  3.52s/it, lr=4.68e-8, step_loss=0.00612]Steps:  99%|█████████▊| 12822/13000 [43:02<10:26,  3.52s/it, lr=4.63e-8, step_loss=0.108]  Steps:  99%|█████████▊| 12822/13000 [43:03<10:26,  3.52s/it, lr=4.63e-8, step_loss=0.0182]Steps:  99%|█████████▊| 12822/13000 [43:03<10:26,  3.52s/it, lr=4.63e-8, step_loss=0.0554]Steps:  99%|█████████▊| 12822/13000 [43:03<10:26,  3.52s/it, lr=4.63e-8, step_loss=0.0852]Steps:  99%|█████████▊| 12823/13000 [43:04<08:34,  2.91s/it, lr=4.63e-8, step_loss=0.0852]Steps:  99%|█████████▊| 12823/13000 [43:04<08:34,  2.91s/it, lr=4.57e-8, step_loss=0.018] Steps:  99%|█████████▊| 12823/13000 [43:04<08:34,  2.91s/it, lr=4.57e-8, step_loss=0.0292]Steps:  99%|█████████▊| 12823/13000 [43:04<08:34,  2.91s/it, lr=4.57e-8, step_loss=0.0366]Steps:  99%|█████████▊| 12823/13000 [43:05<08:34,  2.91s/it, lr=4.57e-8, step_loss=0.00648]Steps:  99%|█████████▊| 12824/13000 [43:05<07:13,  2.46s/it, lr=4.57e-8, step_loss=0.00648]Steps:  99%|█████████▊| 12824/13000 [43:05<07:13,  2.46s/it, lr=4.52e-8, step_loss=0.0142] Steps:  99%|█████████▊| 12824/13000 [43:05<07:13,  2.46s/it, lr=4.52e-8, step_loss=0.0465]Steps:  99%|█████████▊| 12824/13000 [43:06<07:13,  2.46s/it, lr=4.52e-8, step_loss=0.0234]Steps:  99%|█████████▊| 12824/13000 [43:06<07:13,  2.46s/it, lr=4.52e-8, step_loss=0.606] Steps:  99%|█████████▊| 12825/13000 [43:07<06:19,  2.17s/it, lr=4.52e-8, step_loss=0.606]Steps:  99%|█████████▊| 12825/13000 [43:07<06:19,  2.17s/it, lr=4.47e-8, step_loss=0.0628]Steps:  99%|█████████▊| 12825/13000 [43:07<06:19,  2.17s/it, lr=4.47e-8, step_loss=0.367] Steps:  99%|█████████▊| 12825/13000 [43:07<06:19,  2.17s/it, lr=4.47e-8, step_loss=0.0624]Steps:  99%|█████████▊| 12825/13000 [43:08<06:19,  2.17s/it, lr=4.47e-8, step_loss=0.139] Steps:  99%|█████████▊| 12826/13000 [43:08<05:41,  1.96s/it, lr=4.47e-8, step_loss=0.139]Steps:  99%|█████████▊| 12826/13000 [43:08<05:41,  1.96s/it, lr=4.42e-8, step_loss=0.0207]Steps:  99%|█████████▊| 12826/13000 [43:08<05:41,  1.96s/it, lr=4.42e-8, step_loss=0.129] Steps:  99%|█████████▊| 12826/13000 [43:09<05:41,  1.96s/it, lr=4.42e-8, step_loss=0.0114]Steps:  99%|█████████▊| 12826/13000 [43:09<05:41,  1.96s/it, lr=4.42e-8, step_loss=0.0732]Steps:  99%|█████████▊| 12827/13000 [43:09<05:11,  1.80s/it, lr=4.42e-8, step_loss=0.0732]Steps:  99%|█████████▊| 12827/13000 [43:09<05:11,  1.80s/it, lr=4.37e-8, step_loss=0.0437]Steps:  99%|█████████▊| 12827/13000 [43:10<05:11,  1.80s/it, lr=4.37e-8, step_loss=0.217] Steps:  99%|█████████▊| 12828/13000 [43:10<04:12,  1.47s/it, lr=4.37e-8, step_loss=0.217]Steps:  99%|█████████▊| 12828/13000 [43:10<04:12,  1.47s/it, lr=4.32e-8, step_loss=0.252]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.63it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.39it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.84it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.37it/s]
02/23/2025 16:26:37 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  99%|█████████▊| 12828/13000 [43:25<04:12,  1.47s/it, lr=4.32e-8, step_loss=0.0646]Steps:  99%|█████████▊| 12828/13000 [43:25<04:12,  1.47s/it, lr=4.32e-8, step_loss=0.373] Steps:  99%|█████████▊| 12828/13000 [43:26<04:12,  1.47s/it, lr=4.32e-8, step_loss=0.0919]Steps:  99%|█████████▊| 12829/13000 [43:26<16:33,  5.81s/it, lr=4.32e-8, step_loss=0.0919]Steps:  99%|█████████▊| 12829/13000 [43:26<16:33,  5.81s/it, lr=4.27e-8, step_loss=0.121] Steps:  99%|█████████▊| 12829/13000 [43:26<16:33,  5.81s/it, lr=4.27e-8, step_loss=0.11] Steps:  99%|█████████▊| 12829/13000 [43:27<16:33,  5.81s/it, lr=4.27e-8, step_loss=0.00488]Steps:  99%|█████████▊| 12829/13000 [43:27<16:33,  5.81s/it, lr=4.27e-8, step_loss=0.0706] Steps:  99%|█████████▊| 12830/13000 [43:28<12:45,  4.50s/it, lr=4.27e-8, step_loss=0.0706]Steps:  99%|█████████▊| 12830/13000 [43:28<12:45,  4.50s/it, lr=4.22e-8, step_loss=0.0101]Steps:  99%|█████████▊| 12830/13000 [43:28<12:45,  4.50s/it, lr=4.22e-8, step_loss=0.0971]Steps:  99%|█████████▊| 12830/13000 [43:28<12:45,  4.50s/it, lr=4.22e-8, step_loss=0.5]   Steps:  99%|█████████▊| 12830/13000 [43:29<12:45,  4.50s/it, lr=4.22e-8, step_loss=0.0607]Steps:  99%|█████████▊| 12831/13000 [43:29<10:05,  3.58s/it, lr=4.22e-8, step_loss=0.0607]Steps:  99%|█████████▊| 12831/13000 [43:29<10:05,  3.58s/it, lr=4.17e-8, step_loss=0.034] Steps:  99%|█████████▊| 12831/13000 [43:29<10:05,  3.58s/it, lr=4.17e-8, step_loss=0.146]Steps:  99%|█████████▊| 12831/13000 [43:30<10:05,  3.58s/it, lr=4.17e-8, step_loss=0.0167]Steps:  99%|█████████▊| 12831/13000 [43:32<10:05,  3.58s/it, lr=4.17e-8, step_loss=0.0336]Steps:  99%|█████████▊| 12832/13000 [43:32<09:26,  3.37s/it, lr=4.17e-8, step_loss=0.0336]Steps:  99%|█████████▊| 12832/13000 [43:32<09:26,  3.37s/it, lr=4.12e-8, step_loss=0.071] Steps:  99%|█████████▊| 12832/13000 [43:32<09:26,  3.37s/it, lr=4.12e-8, step_loss=0.0325]Steps:  99%|█████████▊| 12832/13000 [43:33<09:26,  3.37s/it, lr=4.12e-8, step_loss=0.0846]Steps:  99%|█████████▊| 12832/13000 [43:33<09:26,  3.37s/it, lr=4.12e-8, step_loss=0.385] Steps:  99%|█████████▊| 12833/13000 [43:33<07:44,  2.78s/it, lr=4.12e-8, step_loss=0.385]Steps:  99%|█████████▊| 12833/13000 [43:33<07:44,  2.78s/it, lr=4.07e-8, step_loss=0.119]Steps:  99%|█████████▊| 12833/13000 [43:34<07:44,  2.78s/it, lr=4.07e-8, step_loss=0.047]Steps:  99%|█████████▊| 12833/13000 [43:34<07:44,  2.78s/it, lr=4.07e-8, step_loss=0.042]Steps:  99%|█████████▊| 12833/13000 [43:34<07:44,  2.78s/it, lr=4.07e-8, step_loss=0.00874]Steps:  99%|█████████▊| 12834/13000 [43:35<06:36,  2.39s/it, lr=4.07e-8, step_loss=0.00874]Steps:  99%|█████████▊| 12834/13000 [43:35<06:36,  2.39s/it, lr=4.02e-8, step_loss=0.00328]Steps:  99%|█████████▊| 12834/13000 [43:35<06:36,  2.39s/it, lr=4.02e-8, step_loss=0.404]  Steps:  99%|█████████▊| 12834/13000 [43:36<06:36,  2.39s/it, lr=4.02e-8, step_loss=0.155]Steps:  99%|█████████▊| 12834/13000 [43:36<06:36,  2.39s/it, lr=4.02e-8, step_loss=0.245]Steps:  99%|█████████▊| 12835/13000 [43:36<05:49,  2.12s/it, lr=4.02e-8, step_loss=0.245]Steps:  99%|█████████▊| 12835/13000 [43:36<05:49,  2.12s/it, lr=3.97e-8, step_loss=0.0138]Steps:  99%|█████████▊| 12835/13000 [43:37<05:49,  2.12s/it, lr=3.97e-8, step_loss=0.0542]Steps:  99%|█████████▊| 12835/13000 [43:37<05:49,  2.12s/it, lr=3.97e-8, step_loss=0.0233]Steps:  99%|█████████▊| 12835/13000 [43:37<05:49,  2.12s/it, lr=3.97e-8, step_loss=0.141] Steps:  99%|█████████▊| 12836/13000 [43:38<05:15,  1.93s/it, lr=3.97e-8, step_loss=0.141]Steps:  99%|█████████▊| 12836/13000 [43:38<05:15,  1.93s/it, lr=3.93e-8, step_loss=0.175]Steps:  99%|█████████▊| 12836/13000 [43:38<05:15,  1.93s/it, lr=3.93e-8, step_loss=0.0646]Steps:  99%|█████████▊| 12837/13000 [43:38<04:13,  1.56s/it, lr=3.93e-8, step_loss=0.0646]Steps:  99%|█████████▊| 12837/13000 [43:38<04:13,  1.56s/it, lr=3.88e-8, step_loss=0.0309]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.22it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.08it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.93it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.44it/s]
02/23/2025 16:27:05 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps:  99%|█████████▊| 12837/13000 [43:53<04:13,  1.56s/it, lr=3.88e-8, step_loss=0.00896]Steps:  99%|█████████▊| 12837/13000 [43:53<04:13,  1.56s/it, lr=3.88e-8, step_loss=0.182]  Steps:  99%|█████████▊| 12837/13000 [43:54<04:13,  1.56s/it, lr=3.88e-8, step_loss=0.0171]Steps:  99%|█████████▉| 12838/13000 [43:54<15:39,  5.80s/it, lr=3.88e-8, step_loss=0.0171]Steps:  99%|█████████▉| 12838/13000 [43:54<15:39,  5.80s/it, lr=3.83e-8, step_loss=0.0507]Steps:  99%|█████████▉| 12838/13000 [43:54<15:39,  5.80s/it, lr=3.83e-8, step_loss=0.0118]Steps:  99%|█████████▉| 12838/13000 [43:55<15:39,  5.80s/it, lr=3.83e-8, step_loss=0.64]  Steps:  99%|█████████▉| 12838/13000 [43:55<15:39,  5.80s/it, lr=3.83e-8, step_loss=0.0193]Steps:  99%|█████████▉| 12839/13000 [43:56<12:03,  4.50s/it, lr=3.83e-8, step_loss=0.0193]Steps:  99%|█████████▉| 12839/13000 [43:56<12:03,  4.50s/it, lr=3.78e-8, step_loss=0.00949]Steps:  99%|█████████▉| 12839/13000 [43:56<12:03,  4.50s/it, lr=3.78e-8, step_loss=0.0218] Steps:  99%|█████████▉| 12839/13000 [43:56<12:03,  4.50s/it, lr=3.78e-8, step_loss=0.215] Steps:  99%|█████████▉| 12839/13000 [43:57<12:03,  4.50s/it, lr=3.78e-8, step_loss=0.169]Steps:  99%|█████████▉| 12840/13000 [43:57<09:30,  3.57s/it, lr=3.78e-8, step_loss=0.169]Steps:  99%|█████████▉| 12840/13000 [43:57<09:30,  3.57s/it, lr=3.74e-8, step_loss=0.57] Steps:  99%|█████████▉| 12840/13000 [43:57<09:30,  3.57s/it, lr=3.74e-8, step_loss=0.0387]Steps:  99%|█████████▉| 12840/13000 [43:58<09:30,  3.57s/it, lr=3.74e-8, step_loss=0.00899]Steps:  99%|█████████▉| 12840/13000 [43:58<09:30,  3.57s/it, lr=3.74e-8, step_loss=0.102]  Steps:  99%|█████████▉| 12841/13000 [43:58<07:47,  2.94s/it, lr=3.74e-8, step_loss=0.102]Steps:  99%|█████████▉| 12841/13000 [43:58<07:47,  2.94s/it, lr=3.69e-8, step_loss=0.00497]Steps:  99%|█████████▉| 12841/13000 [43:59<07:47,  2.94s/it, lr=3.69e-8, step_loss=0.485]  Steps:  99%|█████████▉| 12841/13000 [43:59<07:47,  2.94s/it, lr=3.69e-8, step_loss=0.0562]Steps:  99%|█████████▉| 12841/13000 [44:00<07:47,  2.94s/it, lr=3.69e-8, step_loss=0.072] Steps:  99%|█████████▉| 12842/13000 [44:00<06:34,  2.50s/it, lr=3.69e-8, step_loss=0.072]Steps:  99%|█████████▉| 12842/13000 [44:00<06:34,  2.50s/it, lr=3.64e-8, step_loss=0.0347]Steps:  99%|█████████▉| 12842/13000 [44:00<06:34,  2.50s/it, lr=3.64e-8, step_loss=0.00745]Steps:  99%|█████████▉| 12842/13000 [44:01<06:34,  2.50s/it, lr=3.64e-8, step_loss=0.0181] Steps:  99%|█████████▉| 12842/13000 [44:01<06:34,  2.50s/it, lr=3.64e-8, step_loss=0.215] Steps:  99%|█████████▉| 12843/13000 [44:01<05:41,  2.18s/it, lr=3.64e-8, step_loss=0.215]Steps:  99%|█████████▉| 12843/13000 [44:01<05:41,  2.18s/it, lr=3.6e-8, step_loss=0.143] Steps:  99%|█████████▉| 12843/13000 [44:02<05:41,  2.18s/it, lr=3.6e-8, step_loss=0.0751]Steps:  99%|█████████▉| 12843/13000 [44:02<05:41,  2.18s/it, lr=3.6e-8, step_loss=0.0265]Steps:  99%|█████████▉| 12843/13000 [44:02<05:41,  2.18s/it, lr=3.6e-8, step_loss=0.0198]Steps:  99%|█████████▉| 12844/13000 [44:03<05:06,  1.96s/it, lr=3.6e-8, step_loss=0.0198]Steps:  99%|█████████▉| 12844/13000 [44:03<05:06,  1.96s/it, lr=3.55e-8, step_loss=0.00279]Steps:  99%|█████████▉| 12844/13000 [44:04<05:06,  1.96s/it, lr=3.55e-8, step_loss=0.161]  Steps:  99%|█████████▉| 12844/13000 [44:04<05:06,  1.96s/it, lr=3.55e-8, step_loss=0.01] Steps:  99%|█████████▉| 12844/13000 [44:04<05:06,  1.96s/it, lr=3.55e-8, step_loss=0.065]Steps:  99%|█████████▉| 12845/13000 [44:05<05:03,  1.96s/it, lr=3.55e-8, step_loss=0.065]Steps:  99%|█████████▉| 12845/13000 [44:05<05:03,  1.96s/it, lr=3.51e-8, step_loss=0.114]Steps:  99%|█████████▉| 12845/13000 [44:05<05:03,  1.96s/it, lr=3.51e-8, step_loss=0.0628]Steps:  99%|█████████▉| 12846/13000 [44:05<04:03,  1.58s/it, lr=3.51e-8, step_loss=0.0628]Steps:  99%|█████████▉| 12846/13000 [44:05<04:03,  1.58s/it, lr=3.46e-8, step_loss=0.161] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.10it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.16it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.68it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.23it/s]
02/23/2025 16:27:32 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12846/13000 [44:20<04:03,  1.58s/it, lr=3.46e-8, step_loss=0.0231]Steps:  99%|█████████▉| 12846/13000 [44:20<04:03,  1.58s/it, lr=3.46e-8, step_loss=0.572] Steps:  99%|█████████▉| 12846/13000 [44:21<04:03,  1.58s/it, lr=3.46e-8, step_loss=0.112]Steps:  99%|█████████▉| 12847/13000 [44:21<14:40,  5.75s/it, lr=3.46e-8, step_loss=0.112]Steps:  99%|█████████▉| 12847/13000 [44:21<14:40,  5.75s/it, lr=3.42e-8, step_loss=0.0539]Steps:  99%|█████████▉| 12847/13000 [44:21<14:40,  5.75s/it, lr=3.42e-8, step_loss=0.134] Steps:  99%|█████████▉| 12847/13000 [44:22<14:40,  5.75s/it, lr=3.42e-8, step_loss=0.0813]Steps:  99%|█████████▉| 12847/13000 [44:22<14:40,  5.75s/it, lr=3.42e-8, step_loss=0.00641]Steps:  99%|█████████▉| 12848/13000 [44:22<11:19,  4.47s/it, lr=3.42e-8, step_loss=0.00641]Steps:  99%|█████████▉| 12848/13000 [44:22<11:19,  4.47s/it, lr=3.37e-8, step_loss=0.0314] Steps:  99%|█████████▉| 12848/13000 [44:23<11:19,  4.47s/it, lr=3.37e-8, step_loss=0.0359]Steps:  99%|█████████▉| 12848/13000 [44:23<11:19,  4.47s/it, lr=3.37e-8, step_loss=0.0603]Steps:  99%|█████████▉| 12848/13000 [44:23<11:19,  4.47s/it, lr=3.37e-8, step_loss=0.462] Steps:  99%|█████████▉| 12849/13000 [44:24<08:57,  3.56s/it, lr=3.37e-8, step_loss=0.462]Steps:  99%|█████████▉| 12849/13000 [44:24<08:57,  3.56s/it, lr=3.33e-8, step_loss=0.0221]Steps:  99%|█████████▉| 12849/13000 [44:24<08:57,  3.56s/it, lr=3.33e-8, step_loss=0.37]  Steps:  99%|█████████▉| 12849/13000 [44:25<08:57,  3.56s/it, lr=3.33e-8, step_loss=0.0238]Steps:  99%|█████████▉| 12849/13000 [44:25<08:57,  3.56s/it, lr=3.33e-8, step_loss=0.206] Steps:  99%|█████████▉| 12850/13000 [44:25<07:19,  2.93s/it, lr=3.33e-8, step_loss=0.206]Steps:  99%|█████████▉| 12850/13000 [44:25<07:19,  2.93s/it, lr=3.28e-8, step_loss=0.128]Steps:  99%|█████████▉| 12850/13000 [44:26<07:19,  2.93s/it, lr=3.28e-8, step_loss=0.0634]Steps:  99%|█████████▉| 12850/13000 [44:26<07:19,  2.93s/it, lr=3.28e-8, step_loss=0.0114]Steps:  99%|█████████▉| 12850/13000 [44:26<07:19,  2.93s/it, lr=3.28e-8, step_loss=0.159] Steps:  99%|█████████▉| 12851/13000 [44:27<06:10,  2.49s/it, lr=3.28e-8, step_loss=0.159]Steps:  99%|█████████▉| 12851/13000 [44:28<06:10,  2.49s/it, lr=3.24e-8, step_loss=0.0706]Steps:  99%|█████████▉| 12851/13000 [44:28<06:10,  2.49s/it, lr=3.24e-8, step_loss=0.188] Steps:  99%|█████████▉| 12851/13000 [44:28<06:10,  2.49s/it, lr=3.24e-8, step_loss=0.201]Steps:  99%|█████████▉| 12851/13000 [44:29<06:10,  2.49s/it, lr=3.24e-8, step_loss=0.0221]Steps:  99%|█████████▉| 12852/13000 [44:29<06:03,  2.46s/it, lr=3.24e-8, step_loss=0.0221]Steps:  99%|█████████▉| 12852/13000 [44:29<06:03,  2.46s/it, lr=3.2e-8, step_loss=0.044]  Steps:  99%|█████████▉| 12852/13000 [44:30<06:03,  2.46s/it, lr=3.2e-8, step_loss=0.0636]Steps:  99%|█████████▉| 12852/13000 [44:30<06:03,  2.46s/it, lr=3.2e-8, step_loss=0.0134]Steps:  99%|█████████▉| 12852/13000 [44:30<06:03,  2.46s/it, lr=3.2e-8, step_loss=0.00393]Steps:  99%|█████████▉| 12853/13000 [44:31<05:27,  2.23s/it, lr=3.2e-8, step_loss=0.00393]Steps:  99%|█████████▉| 12853/13000 [44:31<05:27,  2.23s/it, lr=3.15e-8, step_loss=0.171] Steps:  99%|█████████▉| 12853/13000 [44:31<05:27,  2.23s/it, lr=3.15e-8, step_loss=0.381]Steps:  99%|█████████▉| 12853/13000 [44:32<05:27,  2.23s/it, lr=3.15e-8, step_loss=0.0838]Steps:  99%|█████████▉| 12853/13000 [44:32<05:27,  2.23s/it, lr=3.15e-8, step_loss=0.0722]Steps:  99%|█████████▉| 12854/13000 [44:32<04:50,  1.99s/it, lr=3.15e-8, step_loss=0.0722]Steps:  99%|█████████▉| 12854/13000 [44:32<04:50,  1.99s/it, lr=3.11e-8, step_loss=0.0177]Steps:  99%|█████████▉| 12854/13000 [44:33<04:50,  1.99s/it, lr=3.11e-8, step_loss=0.0309]Steps:  99%|█████████▉| 12855/13000 [44:33<03:53,  1.61s/it, lr=3.11e-8, step_loss=0.0309]Steps:  99%|█████████▉| 12855/13000 [44:33<03:53,  1.61s/it, lr=3.07e-8, step_loss=0.532] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.05it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.81it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.30it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.82it/s]
02/23/2025 16:28:00 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12855/13000 [44:48<03:53,  1.61s/it, lr=3.07e-8, step_loss=0.326]Steps:  99%|█████████▉| 12855/13000 [44:48<03:53,  1.61s/it, lr=3.07e-8, step_loss=0.0214]Steps:  99%|█████████▉| 12855/13000 [44:48<03:53,  1.61s/it, lr=3.07e-8, step_loss=0.178] Steps:  99%|█████████▉| 12856/13000 [44:49<14:05,  5.87s/it, lr=3.07e-8, step_loss=0.178]Steps:  99%|█████████▉| 12856/13000 [44:50<14:05,  5.87s/it, lr=3.03e-8, step_loss=0.0799]Steps:  99%|█████████▉| 12856/13000 [44:50<14:05,  5.87s/it, lr=3.03e-8, step_loss=0.0773]Steps:  99%|█████████▉| 12856/13000 [44:51<14:05,  5.87s/it, lr=3.03e-8, step_loss=0.0633]Steps:  99%|█████████▉| 12856/13000 [44:51<14:05,  5.87s/it, lr=3.03e-8, step_loss=0.031] Steps:  99%|█████████▉| 12857/13000 [44:51<11:43,  4.92s/it, lr=3.03e-8, step_loss=0.031]Steps:  99%|█████████▉| 12857/13000 [44:52<11:43,  4.92s/it, lr=2.99e-8, step_loss=0.0552]Steps:  99%|█████████▉| 12857/13000 [44:52<11:43,  4.92s/it, lr=2.99e-8, step_loss=0.0355]Steps:  99%|█████████▉| 12857/13000 [44:52<11:43,  4.92s/it, lr=2.99e-8, step_loss=0.00557]Steps:  99%|█████████▉| 12857/13000 [44:53<11:43,  4.92s/it, lr=2.99e-8, step_loss=0.031]  Steps:  99%|█████████▉| 12858/13000 [44:53<09:09,  3.87s/it, lr=2.99e-8, step_loss=0.031]Steps:  99%|█████████▉| 12858/13000 [44:53<09:09,  3.87s/it, lr=2.94e-8, step_loss=0.00922]Steps:  99%|█████████▉| 12858/13000 [44:53<09:09,  3.87s/it, lr=2.94e-8, step_loss=0.111]  Steps:  99%|█████████▉| 12858/13000 [44:54<09:09,  3.87s/it, lr=2.94e-8, step_loss=0.0132]Steps:  99%|█████████▉| 12858/13000 [44:54<09:09,  3.87s/it, lr=2.94e-8, step_loss=0.35]  Steps:  99%|█████████▉| 12859/13000 [44:54<07:24,  3.15s/it, lr=2.94e-8, step_loss=0.35]Steps:  99%|█████████▉| 12859/13000 [44:54<07:24,  3.15s/it, lr=2.9e-8, step_loss=0.034]Steps:  99%|█████████▉| 12859/13000 [44:55<07:24,  3.15s/it, lr=2.9e-8, step_loss=0.00598]Steps:  99%|█████████▉| 12859/13000 [44:55<07:24,  3.15s/it, lr=2.9e-8, step_loss=0.0919] Steps:  99%|█████████▉| 12859/13000 [44:56<07:24,  3.15s/it, lr=2.9e-8, step_loss=0.205] Steps:  99%|█████████▉| 12860/13000 [44:56<06:37,  2.84s/it, lr=2.9e-8, step_loss=0.205]Steps:  99%|█████████▉| 12860/13000 [44:57<06:37,  2.84s/it, lr=2.86e-8, step_loss=0.0082]Steps:  99%|█████████▉| 12860/13000 [44:57<06:37,  2.84s/it, lr=2.86e-8, step_loss=0.156] Steps:  99%|█████████▉| 12860/13000 [44:57<06:37,  2.84s/it, lr=2.86e-8, step_loss=0.0255]Steps:  99%|█████████▉| 12860/13000 [44:58<06:37,  2.84s/it, lr=2.86e-8, step_loss=0.00617]Steps:  99%|█████████▉| 12861/13000 [44:58<05:35,  2.42s/it, lr=2.86e-8, step_loss=0.00617]Steps:  99%|█████████▉| 12861/13000 [44:58<05:35,  2.42s/it, lr=2.82e-8, step_loss=0.00418]Steps:  99%|█████████▉| 12861/13000 [44:58<05:35,  2.42s/it, lr=2.82e-8, step_loss=0.0816] Steps:  99%|█████████▉| 12861/13000 [44:59<05:35,  2.42s/it, lr=2.82e-8, step_loss=0.00192]Steps:  99%|█████████▉| 12861/13000 [44:59<05:35,  2.42s/it, lr=2.82e-8, step_loss=0.12]   Steps:  99%|█████████▉| 12862/13000 [44:59<04:54,  2.13s/it, lr=2.82e-8, step_loss=0.12]Steps:  99%|█████████▉| 12862/13000 [44:59<04:54,  2.13s/it, lr=2.78e-8, step_loss=0.0823]Steps:  99%|█████████▉| 12862/13000 [45:00<04:54,  2.13s/it, lr=2.78e-8, step_loss=0.0157]Steps:  99%|█████████▉| 12862/13000 [45:00<04:54,  2.13s/it, lr=2.78e-8, step_loss=0.00532]Steps:  99%|█████████▉| 12862/13000 [45:01<04:54,  2.13s/it, lr=2.78e-8, step_loss=0.0898] Steps:  99%|█████████▉| 12863/13000 [45:01<04:24,  1.93s/it, lr=2.78e-8, step_loss=0.0898]Steps:  99%|█████████▉| 12863/13000 [45:01<04:24,  1.93s/it, lr=2.74e-8, step_loss=0.0149]Steps:  99%|█████████▉| 12863/13000 [45:02<04:24,  1.93s/it, lr=2.74e-8, step_loss=0.00449]Steps:  99%|█████████▉| 12864/13000 [45:02<03:56,  1.74s/it, lr=2.74e-8, step_loss=0.00449]Steps:  99%|█████████▉| 12864/13000 [45:02<03:56,  1.74s/it, lr=2.7e-8, step_loss=0.25]    {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.65it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.91it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.57it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.14it/s]
02/23/2025 16:28:29 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12864/13000 [45:16<03:56,  1.74s/it, lr=2.7e-8, step_loss=0.162]Steps:  99%|█████████▉| 12864/13000 [45:17<03:56,  1.74s/it, lr=2.7e-8, step_loss=0.0531]Steps:  99%|█████████▉| 12864/13000 [45:17<03:56,  1.74s/it, lr=2.7e-8, step_loss=0.0547]Steps:  99%|█████████▉| 12865/13000 [45:17<13:04,  5.81s/it, lr=2.7e-8, step_loss=0.0547]Steps:  99%|█████████▉| 12865/13000 [45:17<13:04,  5.81s/it, lr=2.66e-8, step_loss=0.0107]Steps:  99%|█████████▉| 12865/13000 [45:18<13:04,  5.81s/it, lr=2.66e-8, step_loss=0.0798]Steps:  99%|█████████▉| 12865/13000 [45:18<13:04,  5.81s/it, lr=2.66e-8, step_loss=0.0271]Steps:  99%|█████████▉| 12865/13000 [45:19<13:04,  5.81s/it, lr=2.66e-8, step_loss=0.274] Steps:  99%|█████████▉| 12866/13000 [45:19<10:05,  4.52s/it, lr=2.66e-8, step_loss=0.274]Steps:  99%|█████████▉| 12866/13000 [45:19<10:05,  4.52s/it, lr=2.62e-8, step_loss=0.155]Steps:  99%|█████████▉| 12866/13000 [45:19<10:05,  4.52s/it, lr=2.62e-8, step_loss=0.0776]Steps:  99%|█████████▉| 12866/13000 [45:20<10:05,  4.52s/it, lr=2.62e-8, step_loss=0.00929]Steps:  99%|█████████▉| 12866/13000 [45:20<10:05,  4.52s/it, lr=2.62e-8, step_loss=0.00539]Steps:  99%|█████████▉| 12867/13000 [45:20<07:59,  3.60s/it, lr=2.62e-8, step_loss=0.00539]Steps:  99%|█████████▉| 12867/13000 [45:20<07:59,  3.60s/it, lr=2.58e-8, step_loss=0.12]   Steps:  99%|█████████▉| 12867/13000 [45:21<07:59,  3.60s/it, lr=2.58e-8, step_loss=0.0549]Steps:  99%|█████████▉| 12867/13000 [45:21<07:59,  3.60s/it, lr=2.58e-8, step_loss=0.255] Steps:  99%|█████████▉| 12867/13000 [45:24<07:59,  3.60s/it, lr=2.58e-8, step_loss=0.0298]Steps:  99%|█████████▉| 12868/13000 [45:24<08:01,  3.65s/it, lr=2.58e-8, step_loss=0.0298]Steps:  99%|█████████▉| 12868/13000 [45:24<08:01,  3.65s/it, lr=2.54e-8, step_loss=0.281] Steps:  99%|█████████▉| 12868/13000 [45:25<08:01,  3.65s/it, lr=2.54e-8, step_loss=0.029]Steps:  99%|█████████▉| 12868/13000 [45:25<08:01,  3.65s/it, lr=2.54e-8, step_loss=0.245]Steps:  99%|█████████▉| 12868/13000 [45:25<08:01,  3.65s/it, lr=2.54e-8, step_loss=0.222]Steps:  99%|█████████▉| 12869/13000 [45:26<06:30,  2.98s/it, lr=2.54e-8, step_loss=0.222]Steps:  99%|█████████▉| 12869/13000 [45:26<06:30,  2.98s/it, lr=2.51e-8, step_loss=0.0112]Steps:  99%|█████████▉| 12869/13000 [45:26<06:30,  2.98s/it, lr=2.51e-8, step_loss=0.213] Steps:  99%|█████████▉| 12869/13000 [45:26<06:30,  2.98s/it, lr=2.51e-8, step_loss=0.0206]Steps:  99%|█████████▉| 12869/13000 [45:28<06:30,  2.98s/it, lr=2.51e-8, step_loss=0.368] Steps:  99%|█████████▉| 12870/13000 [45:28<06:03,  2.80s/it, lr=2.51e-8, step_loss=0.368]Steps:  99%|█████████▉| 12870/13000 [45:28<06:03,  2.80s/it, lr=2.47e-8, step_loss=0.115]Steps:  99%|█████████▉| 12870/13000 [45:28<06:03,  2.80s/it, lr=2.47e-8, step_loss=0.0423]Steps:  99%|█████████▉| 12870/13000 [45:29<06:03,  2.80s/it, lr=2.47e-8, step_loss=0.272] Steps:  99%|█████████▉| 12870/13000 [45:29<06:03,  2.80s/it, lr=2.47e-8, step_loss=0.129]Steps:  99%|█████████▉| 12871/13000 [45:29<05:08,  2.39s/it, lr=2.47e-8, step_loss=0.129]Steps:  99%|█████████▉| 12871/13000 [45:29<05:08,  2.39s/it, lr=2.43e-8, step_loss=0.175]Steps:  99%|█████████▉| 12871/13000 [45:30<05:08,  2.39s/it, lr=2.43e-8, step_loss=0.037]Steps:  99%|█████████▉| 12871/13000 [45:30<05:08,  2.39s/it, lr=2.43e-8, step_loss=0.0266]Steps:  99%|█████████▉| 12871/13000 [45:31<05:08,  2.39s/it, lr=2.43e-8, step_loss=0.43]  Steps:  99%|█████████▉| 12872/13000 [45:31<04:29,  2.10s/it, lr=2.43e-8, step_loss=0.43]Steps:  99%|█████████▉| 12872/13000 [45:31<04:29,  2.10s/it, lr=2.39e-8, step_loss=0.0263]Steps:  99%|█████████▉| 12872/13000 [45:31<04:29,  2.10s/it, lr=2.39e-8, step_loss=0.0158]Steps:  99%|█████████▉| 12873/13000 [45:32<03:34,  1.69s/it, lr=2.39e-8, step_loss=0.0158]Steps:  99%|█████████▉| 12873/13000 [45:34<03:34,  1.69s/it, lr=2.35e-8, step_loss=0.0478]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.22it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.14it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.68it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.24it/s]
02/23/2025 16:29:00 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12873/13000 [45:48<03:34,  1.69s/it, lr=2.35e-8, step_loss=0.00992]Steps:  99%|█████████▉| 12873/13000 [45:49<03:34,  1.69s/it, lr=2.35e-8, step_loss=0.115]  Steps:  99%|█████████▉| 12873/13000 [45:49<03:34,  1.69s/it, lr=2.35e-8, step_loss=0.0492]Steps:  99%|█████████▉| 12874/13000 [45:49<13:44,  6.54s/it, lr=2.35e-8, step_loss=0.0492]Steps:  99%|█████████▉| 12874/13000 [45:49<13:44,  6.54s/it, lr=2.32e-8, step_loss=0.0642]Steps:  99%|█████████▉| 12874/13000 [45:50<13:44,  6.54s/it, lr=2.32e-8, step_loss=0.48]  Steps:  99%|█████████▉| 12874/13000 [45:50<13:44,  6.54s/it, lr=2.32e-8, step_loss=0.0672]Steps:  99%|█████████▉| 12874/13000 [45:51<13:44,  6.54s/it, lr=2.32e-8, step_loss=0.163] Steps:  99%|█████████▉| 12875/13000 [45:51<10:26,  5.01s/it, lr=2.32e-8, step_loss=0.163]Steps:  99%|█████████▉| 12875/13000 [45:51<10:26,  5.01s/it, lr=2.28e-8, step_loss=0.144]Steps:  99%|█████████▉| 12875/13000 [45:51<10:26,  5.01s/it, lr=2.28e-8, step_loss=0.0782]Steps:  99%|█████████▉| 12875/13000 [45:52<10:26,  5.01s/it, lr=2.28e-8, step_loss=0.239] Steps:  99%|█████████▉| 12875/13000 [45:52<10:26,  5.01s/it, lr=2.28e-8, step_loss=0.154]Steps:  99%|█████████▉| 12876/13000 [45:52<08:10,  3.95s/it, lr=2.28e-8, step_loss=0.154]Steps:  99%|█████████▉| 12876/13000 [45:52<08:10,  3.95s/it, lr=2.24e-8, step_loss=0.305]Steps:  99%|█████████▉| 12876/13000 [45:53<08:10,  3.95s/it, lr=2.24e-8, step_loss=0.891]Steps:  99%|█████████▉| 12876/13000 [45:53<08:10,  3.95s/it, lr=2.24e-8, step_loss=0.182]Steps:  99%|█████████▉| 12876/13000 [45:54<08:10,  3.95s/it, lr=2.24e-8, step_loss=0.0857]Steps:  99%|█████████▉| 12877/13000 [45:54<06:34,  3.21s/it, lr=2.24e-8, step_loss=0.0857]Steps:  99%|█████████▉| 12877/13000 [45:54<06:34,  3.21s/it, lr=2.21e-8, step_loss=0.035] Steps:  99%|█████████▉| 12877/13000 [45:54<06:34,  3.21s/it, lr=2.21e-8, step_loss=0.0507]Steps:  99%|█████████▉| 12877/13000 [45:55<06:34,  3.21s/it, lr=2.21e-8, step_loss=0.348] Steps:  99%|█████████▉| 12877/13000 [45:55<06:34,  3.21s/it, lr=2.21e-8, step_loss=0.472]Steps:  99%|█████████▉| 12878/13000 [45:55<05:26,  2.68s/it, lr=2.21e-8, step_loss=0.472]Steps:  99%|█████████▉| 12878/13000 [45:55<05:26,  2.68s/it, lr=2.17e-8, step_loss=0.0229]Steps:  99%|█████████▉| 12878/13000 [45:56<05:26,  2.68s/it, lr=2.17e-8, step_loss=0.0189]Steps:  99%|█████████▉| 12878/13000 [45:56<05:26,  2.68s/it, lr=2.17e-8, step_loss=0.0207]Steps:  99%|█████████▉| 12878/13000 [45:56<05:26,  2.68s/it, lr=2.17e-8, step_loss=0.0365]Steps:  99%|█████████▉| 12879/13000 [45:57<04:40,  2.31s/it, lr=2.17e-8, step_loss=0.0365]Steps:  99%|█████████▉| 12879/13000 [45:57<04:40,  2.31s/it, lr=2.14e-8, step_loss=0.182] Steps:  99%|█████████▉| 12879/13000 [45:57<04:40,  2.31s/it, lr=2.14e-8, step_loss=0.0861]Steps:  99%|█████████▉| 12879/13000 [45:57<04:40,  2.31s/it, lr=2.14e-8, step_loss=0.162] Steps:  99%|█████████▉| 12879/13000 [45:58<04:40,  2.31s/it, lr=2.14e-8, step_loss=0.0443]Steps:  99%|█████████▉| 12880/13000 [45:58<04:06,  2.05s/it, lr=2.14e-8, step_loss=0.0443]Steps:  99%|█████████▉| 12880/13000 [45:58<04:06,  2.05s/it, lr=2.1e-8, step_loss=0.00767]Steps:  99%|█████████▉| 12880/13000 [45:59<04:06,  2.05s/it, lr=2.1e-8, step_loss=0.0664] Steps:  99%|█████████▉| 12880/13000 [45:59<04:06,  2.05s/it, lr=2.1e-8, step_loss=0.13]  Steps:  99%|█████████▉| 12880/13000 [45:59<04:06,  2.05s/it, lr=2.1e-8, step_loss=0.162]Steps:  99%|█████████▉| 12881/13000 [46:00<03:43,  1.88s/it, lr=2.1e-8, step_loss=0.162]Steps:  99%|█████████▉| 12881/13000 [46:00<03:43,  1.88s/it, lr=2.07e-8, step_loss=0.113]Steps:  99%|█████████▉| 12881/13000 [46:00<03:43,  1.88s/it, lr=2.07e-8, step_loss=0.035]Steps:  99%|█████████▉| 12882/13000 [46:00<02:59,  1.52s/it, lr=2.07e-8, step_loss=0.035]Steps:  99%|█████████▉| 12882/13000 [46:00<02:59,  1.52s/it, lr=2.03e-8, step_loss=0.131]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.06it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.44it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.79it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.36it/s]
02/23/2025 16:29:27 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12882/13000 [46:15<02:59,  1.52s/it, lr=2.03e-8, step_loss=0.0495]Steps:  99%|█████████▉| 12882/13000 [46:15<02:59,  1.52s/it, lr=2.03e-8, step_loss=0.0176]Steps:  99%|█████████▉| 12882/13000 [46:15<02:59,  1.52s/it, lr=2.03e-8, step_loss=0.184] Steps:  99%|█████████▉| 12883/13000 [46:16<11:08,  5.71s/it, lr=2.03e-8, step_loss=0.184]Steps:  99%|█████████▉| 12883/13000 [46:16<11:08,  5.71s/it, lr=2e-8, step_loss=0.011]   Steps:  99%|█████████▉| 12883/13000 [46:16<11:08,  5.71s/it, lr=2e-8, step_loss=0.368]Steps:  99%|█████████▉| 12883/13000 [46:17<11:08,  5.71s/it, lr=2e-8, step_loss=0.00324]Steps:  99%|█████████▉| 12883/13000 [46:17<11:08,  5.71s/it, lr=2e-8, step_loss=0.0861] Steps:  99%|█████████▉| 12884/13000 [46:17<08:33,  4.43s/it, lr=2e-8, step_loss=0.0861]Steps:  99%|█████████▉| 12884/13000 [46:17<08:33,  4.43s/it, lr=1.96e-8, step_loss=0.198]Steps:  99%|█████████▉| 12884/13000 [46:18<08:33,  4.43s/it, lr=1.96e-8, step_loss=0.00996]Steps:  99%|█████████▉| 12884/13000 [46:18<08:33,  4.43s/it, lr=1.96e-8, step_loss=0.063]  Steps:  99%|█████████▉| 12884/13000 [46:18<08:33,  4.43s/it, lr=1.96e-8, step_loss=0.157]Steps:  99%|█████████▉| 12885/13000 [46:19<06:46,  3.53s/it, lr=1.96e-8, step_loss=0.157]Steps:  99%|█████████▉| 12885/13000 [46:19<06:46,  3.53s/it, lr=1.93e-8, step_loss=0.319]Steps:  99%|█████████▉| 12885/13000 [46:20<06:46,  3.53s/it, lr=1.93e-8, step_loss=0.0987]Steps:  99%|█████████▉| 12885/13000 [46:20<06:46,  3.53s/it, lr=1.93e-8, step_loss=0.126] Steps:  99%|█████████▉| 12885/13000 [46:20<06:46,  3.53s/it, lr=1.93e-8, step_loss=0.105]Steps:  99%|█████████▉| 12886/13000 [46:21<05:49,  3.07s/it, lr=1.93e-8, step_loss=0.105]Steps:  99%|█████████▉| 12886/13000 [46:21<05:49,  3.07s/it, lr=1.9e-8, step_loss=0.0118]Steps:  99%|█████████▉| 12886/13000 [46:21<05:49,  3.07s/it, lr=1.9e-8, step_loss=0.185] Steps:  99%|█████████▉| 12886/13000 [46:21<05:49,  3.07s/it, lr=1.9e-8, step_loss=0.0916]Steps:  99%|█████████▉| 12886/13000 [46:22<05:49,  3.07s/it, lr=1.9e-8, step_loss=0.0405]Steps:  99%|█████████▉| 12887/13000 [46:22<04:52,  2.59s/it, lr=1.9e-8, step_loss=0.0405]Steps:  99%|█████████▉| 12887/13000 [46:22<04:52,  2.59s/it, lr=1.86e-8, step_loss=0.074]Steps:  99%|█████████▉| 12887/13000 [46:23<04:52,  2.59s/it, lr=1.86e-8, step_loss=0.0668]Steps:  99%|█████████▉| 12887/13000 [46:23<04:52,  2.59s/it, lr=1.86e-8, step_loss=0.0298]Steps:  99%|█████████▉| 12887/13000 [46:23<04:52,  2.59s/it, lr=1.86e-8, step_loss=0.0316]Steps:  99%|█████████▉| 12888/13000 [46:24<04:11,  2.25s/it, lr=1.86e-8, step_loss=0.0316]Steps:  99%|█████████▉| 12888/13000 [46:24<04:11,  2.25s/it, lr=1.83e-8, step_loss=0.0199]Steps:  99%|█████████▉| 12888/13000 [46:24<04:11,  2.25s/it, lr=1.83e-8, step_loss=0.00664]Steps:  99%|█████████▉| 12888/13000 [46:24<04:11,  2.25s/it, lr=1.83e-8, step_loss=0.00345]Steps:  99%|█████████▉| 12888/13000 [46:25<04:11,  2.25s/it, lr=1.83e-8, step_loss=0.0647] Steps:  99%|█████████▉| 12889/13000 [46:25<03:43,  2.01s/it, lr=1.83e-8, step_loss=0.0647]Steps:  99%|█████████▉| 12889/13000 [46:25<03:43,  2.01s/it, lr=1.8e-8, step_loss=0.0184] Steps:  99%|█████████▉| 12889/13000 [46:25<03:43,  2.01s/it, lr=1.8e-8, step_loss=0.116] Steps:  99%|█████████▉| 12889/13000 [46:26<03:43,  2.01s/it, lr=1.8e-8, step_loss=0.0474]Steps:  99%|█████████▉| 12889/13000 [46:26<03:43,  2.01s/it, lr=1.8e-8, step_loss=0.0272]Steps:  99%|█████████▉| 12890/13000 [46:27<03:22,  1.84s/it, lr=1.8e-8, step_loss=0.0272]Steps:  99%|█████████▉| 12890/13000 [46:27<03:22,  1.84s/it, lr=1.77e-8, step_loss=0.052]Steps:  99%|█████████▉| 12890/13000 [46:27<03:22,  1.84s/it, lr=1.77e-8, step_loss=0.254]Steps:  99%|█████████▉| 12891/13000 [46:27<02:43,  1.50s/it, lr=1.77e-8, step_loss=0.254]Steps:  99%|█████████▉| 12891/13000 [46:27<02:43,  1.50s/it, lr=1.73e-8, step_loss=0.147]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.34it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.03it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.56it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.14it/s]
02/23/2025 16:29:54 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12891/13000 [46:42<02:43,  1.50s/it, lr=1.73e-8, step_loss=0.00561]Steps:  99%|█████████▉| 12891/13000 [46:42<02:43,  1.50s/it, lr=1.73e-8, step_loss=0.0671] Steps:  99%|█████████▉| 12891/13000 [46:43<02:43,  1.50s/it, lr=1.73e-8, step_loss=0.00609]Steps:  99%|█████████▉| 12892/13000 [46:43<10:22,  5.77s/it, lr=1.73e-8, step_loss=0.00609]Steps:  99%|█████████▉| 12892/13000 [46:43<10:22,  5.77s/it, lr=1.7e-8, step_loss=0.0384]  Steps:  99%|█████████▉| 12892/13000 [46:43<10:22,  5.77s/it, lr=1.7e-8, step_loss=0.217] Steps:  99%|█████████▉| 12892/13000 [46:44<10:22,  5.77s/it, lr=1.7e-8, step_loss=0.0422]Steps:  99%|█████████▉| 12892/13000 [46:44<10:22,  5.77s/it, lr=1.7e-8, step_loss=0.00377]Steps:  99%|█████████▉| 12893/13000 [46:44<07:58,  4.47s/it, lr=1.7e-8, step_loss=0.00377]Steps:  99%|█████████▉| 12893/13000 [46:44<07:58,  4.47s/it, lr=1.67e-8, step_loss=0.0582]Steps:  99%|█████████▉| 12893/13000 [46:45<07:58,  4.47s/it, lr=1.67e-8, step_loss=0.206] Steps:  99%|█████████▉| 12893/13000 [46:45<07:58,  4.47s/it, lr=1.67e-8, step_loss=0.152]Steps:  99%|█████████▉| 12893/13000 [46:46<07:58,  4.47s/it, lr=1.67e-8, step_loss=0.289]Steps:  99%|█████████▉| 12894/13000 [46:46<06:18,  3.57s/it, lr=1.67e-8, step_loss=0.289]Steps:  99%|█████████▉| 12894/13000 [46:46<06:18,  3.57s/it, lr=1.64e-8, step_loss=0.242]Steps:  99%|█████████▉| 12894/13000 [46:46<06:18,  3.57s/it, lr=1.64e-8, step_loss=0.00562]Steps:  99%|█████████▉| 12894/13000 [46:47<06:18,  3.57s/it, lr=1.64e-8, step_loss=0.0215] Steps:  99%|█████████▉| 12894/13000 [46:48<06:18,  3.57s/it, lr=1.64e-8, step_loss=0.526] Steps:  99%|█████████▉| 12895/13000 [46:48<05:41,  3.25s/it, lr=1.64e-8, step_loss=0.526]Steps:  99%|█████████▉| 12895/13000 [46:48<05:41,  3.25s/it, lr=1.61e-8, step_loss=0.0142]Steps:  99%|█████████▉| 12895/13000 [46:49<05:41,  3.25s/it, lr=1.61e-8, step_loss=0.108] Steps:  99%|█████████▉| 12895/13000 [46:49<05:41,  3.25s/it, lr=1.61e-8, step_loss=0.221]Steps:  99%|█████████▉| 12895/13000 [46:50<05:41,  3.25s/it, lr=1.61e-8, step_loss=0.0135]Steps:  99%|█████████▉| 12896/13000 [46:50<04:42,  2.72s/it, lr=1.61e-8, step_loss=0.0135]Steps:  99%|█████████▉| 12896/13000 [46:50<04:42,  2.72s/it, lr=1.58e-8, step_loss=0.0619]Steps:  99%|█████████▉| 12896/13000 [46:50<04:42,  2.72s/it, lr=1.58e-8, step_loss=0.0133]Steps:  99%|█████████▉| 12896/13000 [46:51<04:42,  2.72s/it, lr=1.58e-8, step_loss=0.0988]Steps:  99%|█████████▉| 12896/13000 [46:51<04:42,  2.72s/it, lr=1.58e-8, step_loss=0.0202]Steps:  99%|█████████▉| 12897/13000 [46:51<04:00,  2.33s/it, lr=1.58e-8, step_loss=0.0202]Steps:  99%|█████████▉| 12897/13000 [46:53<04:00,  2.33s/it, lr=1.55e-8, step_loss=0.00951]Steps:  99%|█████████▉| 12897/13000 [46:53<04:00,  2.33s/it, lr=1.55e-8, step_loss=0.0366] Steps:  99%|█████████▉| 12897/13000 [46:53<04:00,  2.33s/it, lr=1.55e-8, step_loss=0.0881]Steps:  99%|█████████▉| 12897/13000 [46:54<04:00,  2.33s/it, lr=1.55e-8, step_loss=0.0557]Steps:  99%|█████████▉| 12898/13000 [46:54<04:11,  2.47s/it, lr=1.55e-8, step_loss=0.0557]Steps:  99%|█████████▉| 12898/13000 [46:54<04:11,  2.47s/it, lr=1.52e-8, step_loss=0.226] Steps:  99%|█████████▉| 12898/13000 [46:54<04:11,  2.47s/it, lr=1.52e-8, step_loss=0.0838]Steps:  99%|█████████▉| 12898/13000 [46:55<04:11,  2.47s/it, lr=1.52e-8, step_loss=0.138] Steps:  99%|█████████▉| 12898/13000 [46:55<04:11,  2.47s/it, lr=1.52e-8, step_loss=0.0993]Steps:  99%|█████████▉| 12899/13000 [46:56<03:38,  2.17s/it, lr=1.52e-8, step_loss=0.0993]Steps:  99%|█████████▉| 12899/13000 [46:56<03:38,  2.17s/it, lr=1.49e-8, step_loss=0.117] Steps:  99%|█████████▉| 12899/13000 [46:56<03:38,  2.17s/it, lr=1.49e-8, step_loss=0.0381]Steps:  99%|█████████▉| 12900/13000 [46:56<02:52,  1.73s/it, lr=1.49e-8, step_loss=0.0381]Steps:  99%|█████████▉| 12900/13000 [46:56<02:52,  1.73s/it, lr=1.46e-8, step_loss=0.00877]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.79it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.13it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.88it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.37it/s]
02/23/2025 16:30:23 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12900/13000 [47:11<02:52,  1.73s/it, lr=1.46e-8, step_loss=0.114]  Steps:  99%|█████████▉| 12900/13000 [47:11<02:52,  1.73s/it, lr=1.46e-8, step_loss=0.127]Steps:  99%|█████████▉| 12900/13000 [47:12<02:52,  1.73s/it, lr=1.46e-8, step_loss=0.454]Steps:  99%|█████████▉| 12901/13000 [47:12<09:47,  5.93s/it, lr=1.46e-8, step_loss=0.454]Steps:  99%|█████████▉| 12901/13000 [47:12<09:47,  5.93s/it, lr=1.43e-8, step_loss=0.077]Steps:  99%|█████████▉| 12901/13000 [47:12<09:47,  5.93s/it, lr=1.43e-8, step_loss=0.0286]Steps:  99%|█████████▉| 12901/13000 [47:13<09:47,  5.93s/it, lr=1.43e-8, step_loss=0.138] Steps:  99%|█████████▉| 12901/13000 [47:13<09:47,  5.93s/it, lr=1.43e-8, step_loss=0.0138]Steps:  99%|█████████▉| 12902/13000 [47:13<07:29,  4.59s/it, lr=1.43e-8, step_loss=0.0138]Steps:  99%|█████████▉| 12902/13000 [47:13<07:29,  4.59s/it, lr=1.4e-8, step_loss=0.0393] Steps:  99%|█████████▉| 12902/13000 [47:14<07:29,  4.59s/it, lr=1.4e-8, step_loss=0.16]  Steps:  99%|█████████▉| 12902/13000 [47:14<07:29,  4.59s/it, lr=1.4e-8, step_loss=0.00611]Steps:  99%|█████████▉| 12902/13000 [47:15<07:29,  4.59s/it, lr=1.4e-8, step_loss=0.178]  Steps:  99%|█████████▉| 12903/13000 [47:15<05:54,  3.65s/it, lr=1.4e-8, step_loss=0.178]Steps:  99%|█████████▉| 12903/13000 [47:15<05:54,  3.65s/it, lr=1.37e-8, step_loss=0.14]Steps:  99%|█████████▉| 12903/13000 [47:15<05:54,  3.65s/it, lr=1.37e-8, step_loss=0.0626]Steps:  99%|█████████▉| 12903/13000 [47:16<05:54,  3.65s/it, lr=1.37e-8, step_loss=0.00397]Steps:  99%|█████████▉| 12903/13000 [47:16<05:54,  3.65s/it, lr=1.37e-8, step_loss=0.00542]Steps:  99%|█████████▉| 12904/13000 [47:16<04:47,  2.99s/it, lr=1.37e-8, step_loss=0.00542]Steps:  99%|█████████▉| 12904/13000 [47:16<04:47,  2.99s/it, lr=1.35e-8, step_loss=0.0561] Steps:  99%|█████████▉| 12904/13000 [47:17<04:47,  2.99s/it, lr=1.35e-8, step_loss=0.0925]Steps:  99%|█████████▉| 12904/13000 [47:17<04:47,  2.99s/it, lr=1.35e-8, step_loss=0.15]  Steps:  99%|█████████▉| 12904/13000 [47:17<04:47,  2.99s/it, lr=1.35e-8, step_loss=0.0202]Steps:  99%|█████████▉| 12905/13000 [47:18<04:00,  2.53s/it, lr=1.35e-8, step_loss=0.0202]Steps:  99%|█████████▉| 12905/13000 [47:18<04:00,  2.53s/it, lr=1.32e-8, step_loss=0.0884]Steps:  99%|█████████▉| 12905/13000 [47:18<04:00,  2.53s/it, lr=1.32e-8, step_loss=0.00941]Steps:  99%|█████████▉| 12905/13000 [47:19<04:00,  2.53s/it, lr=1.32e-8, step_loss=0.108]  Steps:  99%|█████████▉| 12905/13000 [47:19<04:00,  2.53s/it, lr=1.32e-8, step_loss=0.00335]Steps:  99%|█████████▉| 12906/13000 [47:19<03:26,  2.20s/it, lr=1.32e-8, step_loss=0.00335]Steps:  99%|█████████▉| 12906/13000 [47:19<03:26,  2.20s/it, lr=1.29e-8, step_loss=0.171]  Steps:  99%|█████████▉| 12906/13000 [47:20<03:26,  2.20s/it, lr=1.29e-8, step_loss=0.0268]Steps:  99%|█████████▉| 12906/13000 [47:20<03:26,  2.20s/it, lr=1.29e-8, step_loss=0.0237]Steps:  99%|█████████▉| 12906/13000 [47:20<03:26,  2.20s/it, lr=1.29e-8, step_loss=0.0722]Steps:  99%|█████████▉| 12907/13000 [47:21<03:04,  1.98s/it, lr=1.29e-8, step_loss=0.0722]Steps:  99%|█████████▉| 12907/13000 [47:21<03:04,  1.98s/it, lr=1.26e-8, step_loss=0.0922]Steps:  99%|█████████▉| 12907/13000 [47:21<03:04,  1.98s/it, lr=1.26e-8, step_loss=0.00421]Steps:  99%|█████████▉| 12907/13000 [47:22<03:04,  1.98s/it, lr=1.26e-8, step_loss=0.0151] Steps:  99%|█████████▉| 12907/13000 [47:22<03:04,  1.98s/it, lr=1.26e-8, step_loss=0.00777]Steps:  99%|█████████▉| 12908/13000 [47:22<02:56,  1.92s/it, lr=1.26e-8, step_loss=0.00777]Steps:  99%|█████████▉| 12908/13000 [47:22<02:56,  1.92s/it, lr=1.24e-8, step_loss=0.719]  Steps:  99%|█████████▉| 12908/13000 [47:23<02:56,  1.92s/it, lr=1.24e-8, step_loss=0.00541]Steps:  99%|█████████▉| 12909/13000 [47:23<02:21,  1.55s/it, lr=1.24e-8, step_loss=0.00541]Steps:  99%|█████████▉| 12909/13000 [47:23<02:21,  1.55s/it, lr=1.21e-8, step_loss=0.196]  {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.16it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.38it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.76it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.34it/s]
02/23/2025 16:30:50 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12909/13000 [47:38<02:21,  1.55s/it, lr=1.21e-8, step_loss=0.147]Steps:  99%|█████████▉| 12909/13000 [47:38<02:21,  1.55s/it, lr=1.21e-8, step_loss=0.0656]Steps:  99%|█████████▉| 12909/13000 [47:38<02:21,  1.55s/it, lr=1.21e-8, step_loss=0.41]  Steps:  99%|█████████▉| 12910/13000 [47:39<08:38,  5.76s/it, lr=1.21e-8, step_loss=0.41]Steps:  99%|█████████▉| 12910/13000 [47:39<08:38,  5.76s/it, lr=1.18e-8, step_loss=0.16]Steps:  99%|█████████▉| 12910/13000 [47:39<08:38,  5.76s/it, lr=1.18e-8, step_loss=0.135]Steps:  99%|█████████▉| 12910/13000 [47:39<08:38,  5.76s/it, lr=1.18e-8, step_loss=0.149]Steps:  99%|█████████▉| 12910/13000 [47:40<08:38,  5.76s/it, lr=1.18e-8, step_loss=0.219]Steps:  99%|█████████▉| 12911/13000 [47:40<06:36,  4.46s/it, lr=1.18e-8, step_loss=0.219]Steps:  99%|█████████▉| 12911/13000 [47:40<06:36,  4.46s/it, lr=1.16e-8, step_loss=0.0052]Steps:  99%|█████████▉| 12911/13000 [47:41<06:36,  4.46s/it, lr=1.16e-8, step_loss=0.0339]Steps:  99%|█████████▉| 12911/13000 [47:41<06:36,  4.46s/it, lr=1.16e-8, step_loss=0.014] Steps:  99%|█████████▉| 12911/13000 [47:41<06:36,  4.46s/it, lr=1.16e-8, step_loss=0.0141]Steps:  99%|█████████▉| 12912/13000 [47:42<05:13,  3.56s/it, lr=1.16e-8, step_loss=0.0141]Steps:  99%|█████████▉| 12912/13000 [47:42<05:13,  3.56s/it, lr=1.13e-8, step_loss=0.102] Steps:  99%|█████████▉| 12912/13000 [47:42<05:13,  3.56s/it, lr=1.13e-8, step_loss=0.239]Steps:  99%|█████████▉| 12912/13000 [47:42<05:13,  3.56s/it, lr=1.13e-8, step_loss=0.0151]Steps:  99%|█████████▉| 12912/13000 [47:43<05:13,  3.56s/it, lr=1.13e-8, step_loss=0.312] Steps:  99%|█████████▉| 12913/13000 [47:43<04:13,  2.91s/it, lr=1.13e-8, step_loss=0.312]Steps:  99%|█████████▉| 12913/13000 [47:43<04:13,  2.91s/it, lr=1.11e-8, step_loss=0.059]Steps:  99%|█████████▉| 12913/13000 [47:43<04:13,  2.91s/it, lr=1.11e-8, step_loss=0.0986]Steps:  99%|█████████▉| 12913/13000 [47:44<04:13,  2.91s/it, lr=1.11e-8, step_loss=0.00262]Steps:  99%|█████████▉| 12913/13000 [47:44<04:13,  2.91s/it, lr=1.11e-8, step_loss=0.0759] Steps:  99%|█████████▉| 12914/13000 [47:44<03:32,  2.47s/it, lr=1.11e-8, step_loss=0.0759]Steps:  99%|█████████▉| 12914/13000 [47:44<03:32,  2.47s/it, lr=1.08e-8, step_loss=0.0897]Steps:  99%|█████████▉| 12914/13000 [47:45<03:32,  2.47s/it, lr=1.08e-8, step_loss=0.00384]Steps:  99%|█████████▉| 12914/13000 [47:45<03:32,  2.47s/it, lr=1.08e-8, step_loss=0.0384] Steps:  99%|█████████▉| 12914/13000 [47:46<03:32,  2.47s/it, lr=1.08e-8, step_loss=0.133] Steps:  99%|█████████▉| 12915/13000 [47:46<03:03,  2.15s/it, lr=1.08e-8, step_loss=0.133]Steps:  99%|█████████▉| 12915/13000 [47:46<03:03,  2.15s/it, lr=1.05e-8, step_loss=0.106]Steps:  99%|█████████▉| 12915/13000 [47:46<03:03,  2.15s/it, lr=1.05e-8, step_loss=0.0287]Steps:  99%|█████████▉| 12915/13000 [47:47<03:03,  2.15s/it, lr=1.05e-8, step_loss=0.00307]Steps:  99%|█████████▉| 12915/13000 [47:47<03:03,  2.15s/it, lr=1.05e-8, step_loss=0.223]  Steps:  99%|█████████▉| 12916/13000 [47:47<02:44,  1.95s/it, lr=1.05e-8, step_loss=0.223]Steps:  99%|█████████▉| 12916/13000 [47:47<02:44,  1.95s/it, lr=1.03e-8, step_loss=0.169]Steps:  99%|█████████▉| 12916/13000 [47:48<02:44,  1.95s/it, lr=1.03e-8, step_loss=0.109]Steps:  99%|█████████▉| 12916/13000 [47:48<02:44,  1.95s/it, lr=1.03e-8, step_loss=0.0624]Steps:  99%|█████████▉| 12916/13000 [47:49<02:44,  1.95s/it, lr=1.03e-8, step_loss=0.337] Steps:  99%|█████████▉| 12917/13000 [47:49<02:30,  1.81s/it, lr=1.03e-8, step_loss=0.337]Steps:  99%|█████████▉| 12917/13000 [47:49<02:30,  1.81s/it, lr=1.01e-8, step_loss=0.541]Steps:  99%|█████████▉| 12917/13000 [47:49<02:30,  1.81s/it, lr=1.01e-8, step_loss=0.00314]Steps:  99%|█████████▉| 12918/13000 [47:50<02:01,  1.48s/it, lr=1.01e-8, step_loss=0.00314]Steps:  99%|█████████▉| 12918/13000 [47:50<02:01,  1.48s/it, lr=9.82e-9, step_loss=0.0624] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.57it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.11it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.73it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.29it/s]
02/23/2025 16:31:16 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12918/13000 [48:04<02:01,  1.48s/it, lr=9.82e-9, step_loss=0.0147]Steps:  99%|█████████▉| 12918/13000 [48:05<02:01,  1.48s/it, lr=9.82e-9, step_loss=0.00717]Steps:  99%|█████████▉| 12918/13000 [48:05<02:01,  1.48s/it, lr=9.82e-9, step_loss=0.151]  Steps:  99%|█████████▉| 12919/13000 [48:05<07:44,  5.73s/it, lr=9.82e-9, step_loss=0.151]Steps:  99%|█████████▉| 12919/13000 [48:05<07:44,  5.73s/it, lr=9.58e-9, step_loss=0.0111]Steps:  99%|█████████▉| 12919/13000 [48:06<07:44,  5.73s/it, lr=9.58e-9, step_loss=0.342] Steps:  99%|█████████▉| 12919/13000 [48:06<07:44,  5.73s/it, lr=9.58e-9, step_loss=0.893]Steps:  99%|█████████▉| 12919/13000 [48:06<07:44,  5.73s/it, lr=9.58e-9, step_loss=0.0139]Steps:  99%|█████████▉| 12920/13000 [48:07<05:56,  4.46s/it, lr=9.58e-9, step_loss=0.0139]Steps:  99%|█████████▉| 12920/13000 [48:07<05:56,  4.46s/it, lr=9.34e-9, step_loss=0.0952]Steps:  99%|█████████▉| 12920/13000 [48:07<05:56,  4.46s/it, lr=9.34e-9, step_loss=0.0239]Steps:  99%|█████████▉| 12920/13000 [48:07<05:56,  4.46s/it, lr=9.34e-9, step_loss=0.00858]Steps:  99%|█████████▉| 12920/13000 [48:08<05:56,  4.46s/it, lr=9.34e-9, step_loss=0.00781]Steps:  99%|█████████▉| 12921/13000 [48:08<04:40,  3.56s/it, lr=9.34e-9, step_loss=0.00781]Steps:  99%|█████████▉| 12921/13000 [48:08<04:40,  3.56s/it, lr=9.11e-9, step_loss=0.0603] Steps:  99%|█████████▉| 12921/13000 [48:09<04:40,  3.56s/it, lr=9.11e-9, step_loss=0.579] Steps:  99%|█████████▉| 12921/13000 [48:09<04:40,  3.56s/it, lr=9.11e-9, step_loss=0.15] Steps:  99%|█████████▉| 12921/13000 [48:09<04:40,  3.56s/it, lr=9.11e-9, step_loss=0.117]Steps:  99%|█████████▉| 12922/13000 [48:10<03:47,  2.91s/it, lr=9.11e-9, step_loss=0.117]Steps:  99%|█████████▉| 12922/13000 [48:10<03:47,  2.91s/it, lr=8.88e-9, step_loss=0.0407]Steps:  99%|█████████▉| 12922/13000 [48:10<03:47,  2.91s/it, lr=8.88e-9, step_loss=0.0718]Steps:  99%|█████████▉| 12922/13000 [48:10<03:47,  2.91s/it, lr=8.88e-9, step_loss=0.0857]Steps:  99%|█████████▉| 12922/13000 [48:11<03:47,  2.91s/it, lr=8.88e-9, step_loss=0.0748]Steps:  99%|█████████▉| 12923/13000 [48:11<03:11,  2.48s/it, lr=8.88e-9, step_loss=0.0748]Steps:  99%|█████████▉| 12923/13000 [48:11<03:11,  2.48s/it, lr=8.66e-9, step_loss=0.0695]Steps:  99%|█████████▉| 12923/13000 [48:11<03:11,  2.48s/it, lr=8.66e-9, step_loss=0.0166]Steps:  99%|█████████▉| 12923/13000 [48:12<03:11,  2.48s/it, lr=8.66e-9, step_loss=0.0257]Steps:  99%|█████████▉| 12923/13000 [48:12<03:11,  2.48s/it, lr=8.66e-9, step_loss=0.0729]Steps:  99%|█████████▉| 12924/13000 [48:12<02:45,  2.18s/it, lr=8.66e-9, step_loss=0.0729]Steps:  99%|█████████▉| 12924/13000 [48:13<02:45,  2.18s/it, lr=8.43e-9, step_loss=0.117] Steps:  99%|█████████▉| 12924/13000 [48:13<02:45,  2.18s/it, lr=8.43e-9, step_loss=0.00468]Steps:  99%|█████████▉| 12924/13000 [48:13<02:45,  2.18s/it, lr=8.43e-9, step_loss=0.232]  Steps:  99%|█████████▉| 12924/13000 [48:14<02:45,  2.18s/it, lr=8.43e-9, step_loss=0.103]Steps:  99%|█████████▉| 12925/13000 [48:14<02:27,  1.97s/it, lr=8.43e-9, step_loss=0.103]Steps:  99%|█████████▉| 12925/13000 [48:14<02:27,  1.97s/it, lr=8.21e-9, step_loss=0.06] Steps:  99%|█████████▉| 12925/13000 [48:14<02:27,  1.97s/it, lr=8.21e-9, step_loss=0.119]Steps:  99%|█████████▉| 12925/13000 [48:15<02:27,  1.97s/it, lr=8.21e-9, step_loss=0.17] Steps:  99%|█████████▉| 12925/13000 [48:15<02:27,  1.97s/it, lr=8.21e-9, step_loss=0.038]Steps:  99%|█████████▉| 12926/13000 [48:15<02:13,  1.80s/it, lr=8.21e-9, step_loss=0.038]Steps:  99%|█████████▉| 12926/13000 [48:15<02:13,  1.80s/it, lr=7.99e-9, step_loss=0.00588]Steps:  99%|█████████▉| 12926/13000 [48:16<02:13,  1.80s/it, lr=7.99e-9, step_loss=0.568]  Steps:  99%|█████████▉| 12927/13000 [48:16<01:47,  1.47s/it, lr=7.99e-9, step_loss=0.568]Steps:  99%|█████████▉| 12927/13000 [48:16<01:47,  1.47s/it, lr=7.78e-9, step_loss=0.00399]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.20it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.31it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.99it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.51it/s]
02/23/2025 16:31:43 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps:  99%|█████████▉| 12927/13000 [48:31<01:47,  1.47s/it, lr=7.78e-9, step_loss=0.0179] Steps:  99%|█████████▉| 12927/13000 [48:31<01:47,  1.47s/it, lr=7.78e-9, step_loss=0.0304]Steps:  99%|█████████▉| 12927/13000 [48:31<01:47,  1.47s/it, lr=7.78e-9, step_loss=0.00355]Steps:  99%|█████████▉| 12928/13000 [48:32<06:52,  5.73s/it, lr=7.78e-9, step_loss=0.00355]Steps:  99%|█████████▉| 12928/13000 [48:32<06:52,  5.73s/it, lr=7.57e-9, step_loss=0.0887] Steps:  99%|█████████▉| 12928/13000 [48:32<06:52,  5.73s/it, lr=7.57e-9, step_loss=0.149] Steps:  99%|█████████▉| 12928/13000 [48:33<06:52,  5.73s/it, lr=7.57e-9, step_loss=0.0201]Steps:  99%|█████████▉| 12928/13000 [48:33<06:52,  5.73s/it, lr=7.57e-9, step_loss=0.196] Steps:  99%|█████████▉| 12929/13000 [48:33<05:15,  4.44s/it, lr=7.57e-9, step_loss=0.196]Steps:  99%|█████████▉| 12929/13000 [48:33<05:15,  4.44s/it, lr=7.36e-9, step_loss=0.0212]Steps:  99%|█████████▉| 12929/13000 [48:34<05:15,  4.44s/it, lr=7.36e-9, step_loss=0.0423]Steps:  99%|█████████▉| 12929/13000 [48:34<05:15,  4.44s/it, lr=7.36e-9, step_loss=0.0644]Steps:  99%|█████████▉| 12929/13000 [48:34<05:15,  4.44s/it, lr=7.36e-9, step_loss=0.0675]Steps:  99%|█████████▉| 12930/13000 [48:35<04:07,  3.54s/it, lr=7.36e-9, step_loss=0.0675]Steps:  99%|█████████▉| 12930/13000 [48:35<04:07,  3.54s/it, lr=7.15e-9, step_loss=0.119] Steps:  99%|█████████▉| 12930/13000 [48:35<04:07,  3.54s/it, lr=7.15e-9, step_loss=0.0696]Steps:  99%|█████████▉| 12930/13000 [48:35<04:07,  3.54s/it, lr=7.15e-9, step_loss=0.00625]Steps:  99%|█████████▉| 12930/13000 [48:36<04:07,  3.54s/it, lr=7.15e-9, step_loss=0.219]  Steps:  99%|█████████▉| 12931/13000 [48:36<03:20,  2.90s/it, lr=7.15e-9, step_loss=0.219]Steps:  99%|█████████▉| 12931/13000 [48:36<03:20,  2.90s/it, lr=6.95e-9, step_loss=0.0627]Steps:  99%|█████████▉| 12931/13000 [48:36<03:20,  2.90s/it, lr=6.95e-9, step_loss=0.109] Steps:  99%|█████████▉| 12931/13000 [48:37<03:20,  2.90s/it, lr=6.95e-9, step_loss=0.0645]Steps:  99%|█████████▉| 12931/13000 [48:37<03:20,  2.90s/it, lr=6.95e-9, step_loss=0.0719]Steps:  99%|█████████▉| 12932/13000 [48:37<02:47,  2.47s/it, lr=6.95e-9, step_loss=0.0719]Steps:  99%|█████████▉| 12932/13000 [48:38<02:47,  2.47s/it, lr=6.75e-9, step_loss=0.102] Steps:  99%|█████████▉| 12932/13000 [48:38<02:47,  2.47s/it, lr=6.75e-9, step_loss=0.00968]Steps:  99%|█████████▉| 12932/13000 [48:38<02:47,  2.47s/it, lr=6.75e-9, step_loss=0.0259] Steps:  99%|█████████▉| 12932/13000 [48:39<02:47,  2.47s/it, lr=6.75e-9, step_loss=0.0112]Steps:  99%|█████████▉| 12933/13000 [48:39<02:24,  2.16s/it, lr=6.75e-9, step_loss=0.0112]Steps:  99%|█████████▉| 12933/13000 [48:39<02:24,  2.16s/it, lr=6.55e-9, step_loss=0.00476]Steps:  99%|█████████▉| 12933/13000 [48:39<02:24,  2.16s/it, lr=6.55e-9, step_loss=0.0219] Steps:  99%|█████████▉| 12933/13000 [48:40<02:24,  2.16s/it, lr=6.55e-9, step_loss=0.104] Steps:  99%|█████████▉| 12933/13000 [48:40<02:24,  2.16s/it, lr=6.55e-9, step_loss=0.148]Steps:  99%|█████████▉| 12934/13000 [48:40<02:09,  1.96s/it, lr=6.55e-9, step_loss=0.148]Steps:  99%|█████████▉| 12934/13000 [48:41<02:09,  1.96s/it, lr=6.36e-9, step_loss=0.076]Steps:  99%|█████████▉| 12934/13000 [48:41<02:09,  1.96s/it, lr=6.36e-9, step_loss=0.00262]Steps:  99%|█████████▉| 12934/13000 [48:42<02:09,  1.96s/it, lr=6.36e-9, step_loss=0.0736] Steps:  99%|█████████▉| 12934/13000 [48:42<02:09,  1.96s/it, lr=6.36e-9, step_loss=0.0836]Steps: 100%|█████████▉| 12935/13000 [48:42<02:05,  1.93s/it, lr=6.36e-9, step_loss=0.0836]Steps: 100%|█████████▉| 12935/13000 [48:42<02:05,  1.93s/it, lr=6.17e-9, step_loss=0.0323]Steps: 100%|█████████▉| 12935/13000 [48:43<02:05,  1.93s/it, lr=6.17e-9, step_loss=0.318] Steps: 100%|█████████▉| 12936/13000 [48:43<01:39,  1.56s/it, lr=6.17e-9, step_loss=0.318]Steps: 100%|█████████▉| 12936/13000 [48:43<01:39,  1.56s/it, lr=5.98e-9, step_loss=0.0349]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 10.98it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.38it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.81it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.37it/s]
02/23/2025 16:32:09 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Steps: 100%|█████████▉| 12936/13000 [48:58<01:39,  1.56s/it, lr=5.98e-9, step_loss=0.424] Steps: 100%|█████████▉| 12936/13000 [48:58<01:39,  1.56s/it, lr=5.98e-9, step_loss=0.0641]Steps: 100%|█████████▉| 12936/13000 [48:58<01:39,  1.56s/it, lr=5.98e-9, step_loss=0.45]  Steps: 100%|█████████▉| 12937/13000 [48:59<06:03,  5.76s/it, lr=5.98e-9, step_loss=0.45]Steps: 100%|█████████▉| 12937/13000 [48:59<06:03,  5.76s/it, lr=5.79e-9, step_loss=0.598]Steps: 100%|█████████▉| 12937/13000 [48:59<06:03,  5.76s/it, lr=5.79e-9, step_loss=0.0176]Steps: 100%|█████████▉| 12937/13000 [48:59<06:03,  5.76s/it, lr=5.79e-9, step_loss=0.0641]Steps: 100%|█████████▉| 12937/13000 [49:00<06:03,  5.76s/it, lr=5.79e-9, step_loss=0.144] Steps: 100%|█████████▉| 12938/13000 [49:00<04:37,  4.48s/it, lr=5.79e-9, step_loss=0.144]Steps: 100%|█████████▉| 12938/13000 [49:00<04:37,  4.48s/it, lr=5.61e-9, step_loss=0.053]Steps: 100%|█████████▉| 12938/13000 [49:00<04:37,  4.48s/it, lr=5.61e-9, step_loss=0.0272]Steps: 100%|█████████▉| 12938/13000 [49:01<04:37,  4.48s/it, lr=5.61e-9, step_loss=0.439] Steps: 100%|█████████▉| 12938/13000 [49:01<04:37,  4.48s/it, lr=5.61e-9, step_loss=0.129]Steps: 100%|█████████▉| 12939/13000 [49:01<03:37,  3.57s/it, lr=5.61e-9, step_loss=0.129]Steps: 100%|█████████▉| 12939/13000 [49:03<03:37,  3.57s/it, lr=5.43e-9, step_loss=0.102]Steps: 100%|█████████▉| 12939/13000 [49:03<03:37,  3.57s/it, lr=5.43e-9, step_loss=0.624]Steps: 100%|█████████▉| 12939/13000 [49:03<03:37,  3.57s/it, lr=5.43e-9, step_loss=0.0121]Steps: 100%|█████████▉| 12939/13000 [49:04<03:37,  3.57s/it, lr=5.43e-9, step_loss=0.029] Steps: 100%|█████████▉| 12940/13000 [49:04<03:17,  3.28s/it, lr=5.43e-9, step_loss=0.029]Steps: 100%|█████████▉| 12940/13000 [49:04<03:17,  3.28s/it, lr=5.26e-9, step_loss=0.908]Steps: 100%|█████████▉| 12940/13000 [49:05<03:17,  3.28s/it, lr=5.26e-9, step_loss=0.0307]Steps: 100%|█████████▉| 12940/13000 [49:05<03:17,  3.28s/it, lr=5.26e-9, step_loss=0.0328]Steps: 100%|█████████▉| 12940/13000 [49:05<03:17,  3.28s/it, lr=5.26e-9, step_loss=0.146] Steps: 100%|█████████▉| 12941/13000 [49:06<02:41,  2.73s/it, lr=5.26e-9, step_loss=0.146]Steps: 100%|█████████▉| 12941/13000 [49:06<02:41,  2.73s/it, lr=5.08e-9, step_loss=0.0039]Steps: 100%|█████████▉| 12941/13000 [49:06<02:41,  2.73s/it, lr=5.08e-9, step_loss=0.0336]Steps: 100%|█████████▉| 12941/13000 [49:06<02:41,  2.73s/it, lr=5.08e-9, step_loss=0.00828]Steps: 100%|█████████▉| 12941/13000 [49:07<02:41,  2.73s/it, lr=5.08e-9, step_loss=0.0234] Steps: 100%|█████████▉| 12942/13000 [49:07<02:15,  2.34s/it, lr=5.08e-9, step_loss=0.0234]Steps: 100%|█████████▉| 12942/13000 [49:07<02:15,  2.34s/it, lr=4.91e-9, step_loss=0.13]  Steps: 100%|█████████▉| 12942/13000 [49:07<02:15,  2.34s/it, lr=4.91e-9, step_loss=0.0332]Steps: 100%|█████████▉| 12942/13000 [49:08<02:15,  2.34s/it, lr=4.91e-9, step_loss=0.0524]Steps: 100%|█████████▉| 12942/13000 [49:08<02:15,  2.34s/it, lr=4.91e-9, step_loss=0.0565]Steps: 100%|█████████▉| 12943/13000 [49:09<02:00,  2.12s/it, lr=4.91e-9, step_loss=0.0565]Steps: 100%|█████████▉| 12943/13000 [49:09<02:00,  2.12s/it, lr=4.74e-9, step_loss=0.00299]Steps: 100%|█████████▉| 12943/13000 [49:09<02:00,  2.12s/it, lr=4.74e-9, step_loss=0.095]  Steps: 100%|█████████▉| 12943/13000 [49:09<02:00,  2.12s/it, lr=4.74e-9, step_loss=0.558]Steps: 100%|█████████▉| 12943/13000 [49:10<02:00,  2.12s/it, lr=4.74e-9, step_loss=0.066]Steps: 100%|█████████▉| 12944/13000 [49:10<01:47,  1.92s/it, lr=4.74e-9, step_loss=0.066]Steps: 100%|█████████▉| 12944/13000 [49:10<01:47,  1.92s/it, lr=4.58e-9, step_loss=0.0777]Steps: 100%|█████████▉| 12944/13000 [49:10<01:47,  1.92s/it, lr=4.58e-9, step_loss=0.0108]Steps: 100%|█████████▉| 12945/13000 [49:11<01:25,  1.56s/it, lr=4.58e-9, step_loss=0.0108]Steps: 100%|█████████▉| 12945/13000 [49:11<01:25,  1.56s/it, lr=4.42e-9, step_loss=0.0196]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.62it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.11it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.66it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.24it/s]
02/23/2025 16:32:37 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12945/13000 [49:25<01:25,  1.56s/it, lr=4.42e-9, step_loss=0.142] Steps: 100%|█████████▉| 12945/13000 [49:25<01:25,  1.56s/it, lr=4.42e-9, step_loss=0.203]Steps: 100%|█████████▉| 12945/13000 [49:26<01:25,  1.56s/it, lr=4.42e-9, step_loss=0.0589]Steps: 100%|█████████▉| 12946/13000 [49:26<05:09,  5.72s/it, lr=4.42e-9, step_loss=0.0589]Steps: 100%|█████████▉| 12946/13000 [49:26<05:09,  5.72s/it, lr=4.26e-9, step_loss=0.00403]Steps: 100%|█████████▉| 12946/13000 [49:27<05:09,  5.72s/it, lr=4.26e-9, step_loss=0.0362] Steps: 100%|█████████▉| 12946/13000 [49:27<05:09,  5.72s/it, lr=4.26e-9, step_loss=0.0305]Steps: 100%|█████████▉| 12946/13000 [49:27<05:09,  5.72s/it, lr=4.26e-9, step_loss=0.0371]Steps: 100%|█████████▉| 12947/13000 [49:28<03:55,  4.43s/it, lr=4.26e-9, step_loss=0.0371]Steps: 100%|█████████▉| 12947/13000 [49:28<03:55,  4.43s/it, lr=4.1e-9, step_loss=0.00757]Steps: 100%|█████████▉| 12947/13000 [49:28<03:55,  4.43s/it, lr=4.1e-9, step_loss=0.27]   Steps: 100%|█████████▉| 12947/13000 [49:28<03:55,  4.43s/it, lr=4.1e-9, step_loss=0.282]Steps: 100%|█████████▉| 12947/13000 [49:29<03:55,  4.43s/it, lr=4.1e-9, step_loss=0.0448]Steps: 100%|█████████▉| 12948/13000 [49:29<03:04,  3.54s/it, lr=4.1e-9, step_loss=0.0448]Steps: 100%|█████████▉| 12948/13000 [49:29<03:04,  3.54s/it, lr=3.95e-9, step_loss=0.0213]Steps: 100%|█████████▉| 12948/13000 [49:29<03:04,  3.54s/it, lr=3.95e-9, step_loss=0.0178]Steps: 100%|█████████▉| 12948/13000 [49:30<03:04,  3.54s/it, lr=3.95e-9, step_loss=0.126] Steps: 100%|█████████▉| 12948/13000 [49:30<03:04,  3.54s/it, lr=3.95e-9, step_loss=0.491]Steps: 100%|█████████▉| 12949/13000 [49:30<02:28,  2.91s/it, lr=3.95e-9, step_loss=0.491]Steps: 100%|█████████▉| 12949/13000 [49:31<02:28,  2.91s/it, lr=3.8e-9, step_loss=0.0929]Steps: 100%|█████████▉| 12949/13000 [49:31<02:28,  2.91s/it, lr=3.8e-9, step_loss=0.17]  Steps: 100%|█████████▉| 12949/13000 [49:31<02:28,  2.91s/it, lr=3.8e-9, step_loss=0.0196]Steps: 100%|█████████▉| 12949/13000 [49:32<02:28,  2.91s/it, lr=3.8e-9, step_loss=0.0122]Steps: 100%|█████████▉| 12950/13000 [49:32<02:04,  2.48s/it, lr=3.8e-9, step_loss=0.0122]Steps: 100%|█████████▉| 12950/13000 [49:32<02:04,  2.48s/it, lr=3.65e-9, step_loss=0.133]Steps: 100%|█████████▉| 12950/13000 [49:32<02:04,  2.48s/it, lr=3.65e-9, step_loss=0.00532]Steps: 100%|█████████▉| 12950/13000 [49:33<02:04,  2.48s/it, lr=3.65e-9, step_loss=0.0111] Steps: 100%|█████████▉| 12950/13000 [49:33<02:04,  2.48s/it, lr=3.65e-9, step_loss=0.0532]Steps: 100%|█████████▉| 12951/13000 [49:33<01:46,  2.18s/it, lr=3.65e-9, step_loss=0.0532]Steps: 100%|█████████▉| 12951/13000 [49:34<01:46,  2.18s/it, lr=3.51e-9, step_loss=0.129] Steps: 100%|█████████▉| 12951/13000 [49:34<01:46,  2.18s/it, lr=3.51e-9, step_loss=0.152]Steps: 100%|█████████▉| 12951/13000 [49:35<01:46,  2.18s/it, lr=3.51e-9, step_loss=0.0471]Steps: 100%|█████████▉| 12951/13000 [49:35<01:46,  2.18s/it, lr=3.51e-9, step_loss=0.00717]Steps: 100%|█████████▉| 12952/13000 [49:35<01:38,  2.05s/it, lr=3.51e-9, step_loss=0.00717]Steps: 100%|█████████▉| 12952/13000 [49:35<01:38,  2.05s/it, lr=3.36e-9, step_loss=0.141]  Steps: 100%|█████████▉| 12952/13000 [49:36<01:38,  2.05s/it, lr=3.36e-9, step_loss=0.215]Steps: 100%|█████████▉| 12952/13000 [49:36<01:38,  2.05s/it, lr=3.36e-9, step_loss=0.0415]Steps: 100%|█████████▉| 12952/13000 [49:36<01:38,  2.05s/it, lr=3.36e-9, step_loss=0.0191]Steps: 100%|█████████▉| 12953/13000 [49:37<01:27,  1.87s/it, lr=3.36e-9, step_loss=0.0191]Steps: 100%|█████████▉| 12953/13000 [49:37<01:27,  1.87s/it, lr=3.23e-9, step_loss=0.00568]Steps: 100%|█████████▉| 12953/13000 [49:37<01:27,  1.87s/it, lr=3.23e-9, step_loss=0.0054] Steps: 100%|█████████▉| 12954/13000 [49:37<01:09,  1.52s/it, lr=3.23e-9, step_loss=0.0054]Steps: 100%|█████████▉| 12954/13000 [49:37<01:09,  1.52s/it, lr=3.09e-9, step_loss=0.0146]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.15it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.13it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.74it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.29it/s]
02/23/2025 16:33:04 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12954/13000 [49:52<01:09,  1.52s/it, lr=3.09e-9, step_loss=0.00512]Steps: 100%|█████████▉| 12954/13000 [49:52<01:09,  1.52s/it, lr=3.09e-9, step_loss=0.0232] Steps: 100%|█████████▉| 12954/13000 [49:52<01:09,  1.52s/it, lr=3.09e-9, step_loss=0.0104]Steps: 100%|█████████▉| 12955/13000 [49:53<04:16,  5.70s/it, lr=3.09e-9, step_loss=0.0104]Steps: 100%|█████████▉| 12955/13000 [49:53<04:16,  5.70s/it, lr=2.96e-9, step_loss=0.0364]Steps: 100%|█████████▉| 12955/13000 [49:53<04:16,  5.70s/it, lr=2.96e-9, step_loss=0.155] Steps: 100%|█████████▉| 12955/13000 [49:54<04:16,  5.70s/it, lr=2.96e-9, step_loss=0.0334]Steps: 100%|█████████▉| 12955/13000 [49:54<04:16,  5.70s/it, lr=2.96e-9, step_loss=0.0495]Steps: 100%|█████████▉| 12956/13000 [49:54<03:14,  4.43s/it, lr=2.96e-9, step_loss=0.0495]Steps: 100%|█████████▉| 12956/13000 [49:54<03:14,  4.43s/it, lr=2.83e-9, step_loss=0.00656]Steps: 100%|█████████▉| 12956/13000 [49:55<03:14,  4.43s/it, lr=2.83e-9, step_loss=0.0105] Steps: 100%|█████████▉| 12956/13000 [49:55<03:14,  4.43s/it, lr=2.83e-9, step_loss=0.234] Steps: 100%|█████████▉| 12956/13000 [49:55<03:14,  4.43s/it, lr=2.83e-9, step_loss=0.129]Steps: 100%|█████████▉| 12957/13000 [49:56<02:32,  3.54s/it, lr=2.83e-9, step_loss=0.129]Steps: 100%|█████████▉| 12957/13000 [49:56<02:32,  3.54s/it, lr=2.7e-9, step_loss=0.0159]Steps: 100%|█████████▉| 12957/13000 [49:56<02:32,  3.54s/it, lr=2.7e-9, step_loss=0.12]  Steps: 100%|█████████▉| 12957/13000 [49:57<02:32,  3.54s/it, lr=2.7e-9, step_loss=0.0926]Steps: 100%|█████████▉| 12957/13000 [49:57<02:32,  3.54s/it, lr=2.7e-9, step_loss=0.141] Steps: 100%|█████████▉| 12958/13000 [49:58<02:09,  3.08s/it, lr=2.7e-9, step_loss=0.141]Steps: 100%|█████████▉| 12958/13000 [49:58<02:09,  3.08s/it, lr=2.58e-9, step_loss=0.132]Steps: 100%|█████████▉| 12958/13000 [49:58<02:09,  3.08s/it, lr=2.58e-9, step_loss=0.0113]Steps: 100%|█████████▉| 12958/13000 [49:59<02:09,  3.08s/it, lr=2.58e-9, step_loss=0.0322]Steps: 100%|█████████▉| 12958/13000 [49:59<02:09,  3.08s/it, lr=2.58e-9, step_loss=0.0913]Steps: 100%|█████████▉| 12959/13000 [49:59<01:46,  2.59s/it, lr=2.58e-9, step_loss=0.0913]Steps: 100%|█████████▉| 12959/13000 [50:00<01:46,  2.59s/it, lr=2.45e-9, step_loss=0.251] Steps: 100%|█████████▉| 12959/13000 [50:00<01:46,  2.59s/it, lr=2.45e-9, step_loss=0.0626]Steps: 100%|█████████▉| 12959/13000 [50:01<01:46,  2.59s/it, lr=2.45e-9, step_loss=0.00309]Steps: 100%|█████████▉| 12959/13000 [50:01<01:46,  2.59s/it, lr=2.45e-9, step_loss=0.017]  Steps: 100%|█████████▉| 12960/13000 [50:01<01:37,  2.45s/it, lr=2.45e-9, step_loss=0.017]Steps: 100%|█████████▉| 12960/13000 [50:01<01:37,  2.45s/it, lr=2.34e-9, step_loss=0.377]Steps: 100%|█████████▉| 12960/13000 [50:02<01:37,  2.45s/it, lr=2.34e-9, step_loss=0.285]Steps: 100%|█████████▉| 12960/13000 [50:02<01:37,  2.45s/it, lr=2.34e-9, step_loss=0.132]Steps: 100%|█████████▉| 12960/13000 [50:04<01:37,  2.45s/it, lr=2.34e-9, step_loss=0.05] Steps: 100%|█████████▉| 12961/13000 [50:04<01:37,  2.50s/it, lr=2.34e-9, step_loss=0.05]Steps: 100%|█████████▉| 12961/13000 [50:04<01:37,  2.50s/it, lr=2.22e-9, step_loss=0.0932]Steps: 100%|█████████▉| 12961/13000 [50:04<01:37,  2.50s/it, lr=2.22e-9, step_loss=0.037] Steps: 100%|█████████▉| 12961/13000 [50:05<01:37,  2.50s/it, lr=2.22e-9, step_loss=0.0356]Steps: 100%|█████████▉| 12961/13000 [50:05<01:37,  2.50s/it, lr=2.22e-9, step_loss=0.209] Steps: 100%|█████████▉| 12962/13000 [50:05<01:22,  2.18s/it, lr=2.22e-9, step_loss=0.209]Steps: 100%|█████████▉| 12962/13000 [50:06<01:22,  2.18s/it, lr=2.11e-9, step_loss=0.16] Steps: 100%|█████████▉| 12962/13000 [50:06<01:22,  2.18s/it, lr=2.11e-9, step_loss=0.017]Steps: 100%|█████████▉| 12963/13000 [50:06<01:06,  1.79s/it, lr=2.11e-9, step_loss=0.017]Steps: 100%|█████████▉| 12963/13000 [50:06<01:06,  1.79s/it, lr=2e-9, step_loss=0.0412]  {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.45it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.83it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.01it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.62it/s]
02/23/2025 16:33:33 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12963/13000 [50:21<01:06,  1.79s/it, lr=2e-9, step_loss=0.0988]Steps: 100%|█████████▉| 12963/13000 [50:21<01:06,  1.79s/it, lr=2e-9, step_loss=0.00767]Steps: 100%|█████████▉| 12963/13000 [50:22<01:06,  1.79s/it, lr=2e-9, step_loss=0.0218] Steps: 100%|█████████▉| 12964/13000 [50:22<03:33,  5.93s/it, lr=2e-9, step_loss=0.0218]Steps: 100%|█████████▉| 12964/13000 [50:22<03:33,  5.93s/it, lr=1.89e-9, step_loss=0.0695]Steps: 100%|█████████▉| 12964/13000 [50:22<03:33,  5.93s/it, lr=1.89e-9, step_loss=0.00491]Steps: 100%|█████████▉| 12964/13000 [50:23<03:33,  5.93s/it, lr=1.89e-9, step_loss=0.031]  Steps: 100%|█████████▉| 12964/13000 [50:23<03:33,  5.93s/it, lr=1.89e-9, step_loss=0.0138]Steps: 100%|█████████▉| 12965/13000 [50:23<02:40,  4.58s/it, lr=1.89e-9, step_loss=0.0138]Steps: 100%|█████████▉| 12965/13000 [50:23<02:40,  4.58s/it, lr=1.79e-9, step_loss=0.024] Steps: 100%|█████████▉| 12965/13000 [50:24<02:40,  4.58s/it, lr=1.79e-9, step_loss=0.11] Steps: 100%|█████████▉| 12965/13000 [50:24<02:40,  4.58s/it, lr=1.79e-9, step_loss=0.0582]Steps: 100%|█████████▉| 12965/13000 [50:24<02:40,  4.58s/it, lr=1.79e-9, step_loss=0.0634]Steps: 100%|█████████▉| 12966/13000 [50:25<02:04,  3.65s/it, lr=1.79e-9, step_loss=0.0634]Steps: 100%|█████████▉| 12966/13000 [50:25<02:04,  3.65s/it, lr=1.69e-9, step_loss=0.613] Steps: 100%|█████████▉| 12966/13000 [50:25<02:04,  3.65s/it, lr=1.69e-9, step_loss=0.0591]Steps: 100%|█████████▉| 12966/13000 [50:26<02:04,  3.65s/it, lr=1.69e-9, step_loss=0.669] Steps: 100%|█████████▉| 12966/13000 [50:26<02:04,  3.65s/it, lr=1.69e-9, step_loss=0.0385]Steps: 100%|█████████▉| 12967/13000 [50:26<01:38,  2.99s/it, lr=1.69e-9, step_loss=0.0385]Steps: 100%|█████████▉| 12967/13000 [50:26<01:38,  2.99s/it, lr=1.59e-9, step_loss=0.0245]Steps: 100%|█████████▉| 12967/13000 [50:27<01:38,  2.99s/it, lr=1.59e-9, step_loss=0.061] Steps: 100%|█████████▉| 12967/13000 [50:27<01:38,  2.99s/it, lr=1.59e-9, step_loss=0.117]Steps: 100%|█████████▉| 12967/13000 [50:27<01:38,  2.99s/it, lr=1.59e-9, step_loss=0.106]Steps: 100%|█████████▉| 12968/13000 [50:28<01:20,  2.53s/it, lr=1.59e-9, step_loss=0.106]Steps: 100%|█████████▉| 12968/13000 [50:28<01:20,  2.53s/it, lr=1.5e-9, step_loss=0.0163]Steps: 100%|█████████▉| 12968/13000 [50:28<01:20,  2.53s/it, lr=1.5e-9, step_loss=0.00729]Steps: 100%|█████████▉| 12968/13000 [50:28<01:20,  2.53s/it, lr=1.5e-9, step_loss=0.0156] Steps: 100%|█████████▉| 12968/13000 [50:29<01:20,  2.53s/it, lr=1.5e-9, step_loss=0.102] Steps: 100%|█████████▉| 12969/13000 [50:29<01:07,  2.19s/it, lr=1.5e-9, step_loss=0.102]Steps: 100%|█████████▉| 12969/13000 [50:29<01:07,  2.19s/it, lr=1.4e-9, step_loss=0.194]Steps: 100%|█████████▉| 12969/13000 [50:29<01:07,  2.19s/it, lr=1.4e-9, step_loss=0.0529]Steps: 100%|█████████▉| 12969/13000 [50:30<01:07,  2.19s/it, lr=1.4e-9, step_loss=0.033] Steps: 100%|█████████▉| 12969/13000 [50:30<01:07,  2.19s/it, lr=1.4e-9, step_loss=0.215]Steps: 100%|█████████▉| 12970/13000 [50:31<00:59,  1.98s/it, lr=1.4e-9, step_loss=0.215]Steps: 100%|█████████▉| 12970/13000 [50:31<00:59,  1.98s/it, lr=1.31e-9, step_loss=0.0179]Steps: 100%|█████████▉| 12970/13000 [50:31<00:59,  1.98s/it, lr=1.31e-9, step_loss=0.0611]Steps: 100%|█████████▉| 12970/13000 [50:31<00:59,  1.98s/it, lr=1.31e-9, step_loss=0.086] Steps: 100%|█████████▉| 12970/13000 [50:32<00:59,  1.98s/it, lr=1.31e-9, step_loss=0.0899]Steps: 100%|█████████▉| 12971/13000 [50:32<00:52,  1.82s/it, lr=1.31e-9, step_loss=0.0899]Steps: 100%|█████████▉| 12971/13000 [50:32<00:52,  1.82s/it, lr=1.23e-9, step_loss=0.29]  Steps: 100%|█████████▉| 12971/13000 [50:32<00:52,  1.82s/it, lr=1.23e-9, step_loss=0.0137]Steps: 100%|█████████▉| 12972/13000 [50:33<00:41,  1.48s/it, lr=1.23e-9, step_loss=0.0137]Steps: 100%|█████████▉| 12972/13000 [50:33<00:41,  1.48s/it, lr=1.14e-9, step_loss=0.222] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.12it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.47it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.80it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.38it/s]
02/23/2025 16:33:59 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12972/13000 [50:47<00:41,  1.48s/it, lr=1.14e-9, step_loss=0.389]Steps: 100%|█████████▉| 12972/13000 [50:47<00:41,  1.48s/it, lr=1.14e-9, step_loss=0.0356]Steps: 100%|█████████▉| 12972/13000 [50:48<00:41,  1.48s/it, lr=1.14e-9, step_loss=0.311] Steps: 100%|█████████▉| 12973/13000 [50:48<02:32,  5.65s/it, lr=1.14e-9, step_loss=0.311]Steps: 100%|█████████▉| 12973/13000 [50:48<02:32,  5.65s/it, lr=1.06e-9, step_loss=0.0366]Steps: 100%|█████████▉| 12973/13000 [50:48<02:32,  5.65s/it, lr=1.06e-9, step_loss=0.00487]Steps: 100%|█████████▉| 12973/13000 [50:49<02:32,  5.65s/it, lr=1.06e-9, step_loss=0.111]  Steps: 100%|█████████▉| 12973/13000 [50:49<02:32,  5.65s/it, lr=1.06e-9, step_loss=0.273]Steps: 100%|█████████▉| 12974/13000 [50:50<01:54,  4.39s/it, lr=1.06e-9, step_loss=0.273]Steps: 100%|█████████▉| 12974/13000 [50:50<01:54,  4.39s/it, lr=9.87e-10, step_loss=0.114]Steps: 100%|█████████▉| 12974/13000 [50:50<01:54,  4.39s/it, lr=9.87e-10, step_loss=0.0508]Steps: 100%|█████████▉| 12974/13000 [50:50<01:54,  4.39s/it, lr=9.87e-10, step_loss=0.0527]Steps: 100%|█████████▉| 12974/13000 [50:51<01:54,  4.39s/it, lr=9.87e-10, step_loss=0.206] Steps: 100%|█████████▉| 12975/13000 [50:51<01:27,  3.52s/it, lr=9.87e-10, step_loss=0.206]Steps: 100%|█████████▉| 12975/13000 [50:51<01:27,  3.52s/it, lr=9.12e-10, step_loss=0.07] Steps: 100%|█████████▉| 12975/13000 [50:51<01:27,  3.52s/it, lr=9.12e-10, step_loss=0.0809]Steps: 100%|█████████▉| 12975/13000 [50:52<01:27,  3.52s/it, lr=9.12e-10, step_loss=0.0847]Steps: 100%|█████████▉| 12975/13000 [50:52<01:27,  3.52s/it, lr=9.12e-10, step_loss=0.154] Steps: 100%|█████████▉| 12976/13000 [50:52<01:09,  2.90s/it, lr=9.12e-10, step_loss=0.154]Steps: 100%|█████████▉| 12976/13000 [50:53<01:09,  2.90s/it, lr=8.41e-10, step_loss=0.213]Steps: 100%|█████████▉| 12976/13000 [50:53<01:09,  2.90s/it, lr=8.41e-10, step_loss=0.0757]Steps: 100%|█████████▉| 12976/13000 [50:53<01:09,  2.90s/it, lr=8.41e-10, step_loss=0.167] Steps: 100%|█████████▉| 12976/13000 [50:54<01:09,  2.90s/it, lr=8.41e-10, step_loss=0.0415]Steps: 100%|█████████▉| 12977/13000 [50:54<00:56,  2.47s/it, lr=8.41e-10, step_loss=0.0415]Steps: 100%|█████████▉| 12977/13000 [50:54<00:56,  2.47s/it, lr=7.72e-10, step_loss=0.177] Steps: 100%|█████████▉| 12977/13000 [50:54<00:56,  2.47s/it, lr=7.72e-10, step_loss=0.0608]Steps: 100%|█████████▉| 12977/13000 [50:55<00:56,  2.47s/it, lr=7.72e-10, step_loss=0.342] Steps: 100%|█████████▉| 12977/13000 [50:55<00:56,  2.47s/it, lr=7.72e-10, step_loss=0.268]Steps: 100%|█████████▉| 12978/13000 [50:55<00:47,  2.16s/it, lr=7.72e-10, step_loss=0.268]Steps: 100%|█████████▉| 12978/13000 [50:55<00:47,  2.16s/it, lr=7.07e-10, step_loss=0.0791]Steps: 100%|█████████▉| 12978/13000 [50:56<00:47,  2.16s/it, lr=7.07e-10, step_loss=0.185] Steps: 100%|█████████▉| 12978/13000 [50:56<00:47,  2.16s/it, lr=7.07e-10, step_loss=0.216]Steps: 100%|█████████▉| 12978/13000 [50:57<00:47,  2.16s/it, lr=7.07e-10, step_loss=0.0689]Steps: 100%|█████████▉| 12979/13000 [50:57<00:40,  1.95s/it, lr=7.07e-10, step_loss=0.0689]Steps: 100%|█████████▉| 12979/13000 [50:57<00:40,  1.95s/it, lr=6.44e-10, step_loss=0.0275]Steps: 100%|█████████▉| 12979/13000 [50:57<00:40,  1.95s/it, lr=6.44e-10, step_loss=0.163] Steps: 100%|█████████▉| 12979/13000 [50:58<00:40,  1.95s/it, lr=6.44e-10, step_loss=0.649]Steps: 100%|█████████▉| 12979/13000 [50:58<00:40,  1.95s/it, lr=6.44e-10, step_loss=0.24] Steps: 100%|█████████▉| 12980/13000 [50:58<00:35,  1.80s/it, lr=6.44e-10, step_loss=0.24]Steps: 100%|█████████▉| 12980/13000 [50:58<00:35,  1.80s/it, lr=5.84e-10, step_loss=0.12]Steps: 100%|█████████▉| 12980/13000 [50:59<00:35,  1.80s/it, lr=5.84e-10, step_loss=0.0442]Steps: 100%|█████████▉| 12981/13000 [50:59<00:28,  1.47s/it, lr=5.84e-10, step_loss=0.0442]Steps: 100%|█████████▉| 12981/13000 [50:59<00:28,  1.47s/it, lr=5.27e-10, step_loss=0.202] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.04it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.40it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.42it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.92it/s]
02/23/2025 16:34:26 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12981/13000 [51:13<00:28,  1.47s/it, lr=5.27e-10, step_loss=0.00612]Steps: 100%|█████████▉| 12981/13000 [51:14<00:28,  1.47s/it, lr=5.27e-10, step_loss=0.0298] Steps: 100%|█████████▉| 12981/13000 [51:14<00:28,  1.47s/it, lr=5.27e-10, step_loss=0.0363]Steps: 100%|█████████▉| 12982/13000 [51:15<01:42,  5.70s/it, lr=5.27e-10, step_loss=0.0363]Steps: 100%|█████████▉| 12982/13000 [51:15<01:42,  5.70s/it, lr=4.73e-10, step_loss=0.174] Steps: 100%|█████████▉| 12982/13000 [51:15<01:42,  5.70s/it, lr=4.73e-10, step_loss=0.198]Steps: 100%|█████████▉| 12982/13000 [51:17<01:42,  5.70s/it, lr=4.73e-10, step_loss=0.0215]Steps: 100%|█████████▉| 12982/13000 [51:18<01:42,  5.70s/it, lr=4.73e-10, step_loss=0.131] Steps: 100%|█████████▉| 12983/13000 [51:18<01:24,  4.99s/it, lr=4.73e-10, step_loss=0.131]Steps: 100%|█████████▉| 12983/13000 [51:18<01:24,  4.99s/it, lr=4.22e-10, step_loss=0.0184]Steps: 100%|█████████▉| 12983/13000 [51:18<01:24,  4.99s/it, lr=4.22e-10, step_loss=0.074] Steps: 100%|█████████▉| 12983/13000 [51:19<01:24,  4.99s/it, lr=4.22e-10, step_loss=0.0286]Steps: 100%|█████████▉| 12983/13000 [51:19<01:24,  4.99s/it, lr=4.22e-10, step_loss=0.329] Steps: 100%|█████████▉| 12984/13000 [51:19<01:02,  3.92s/it, lr=4.22e-10, step_loss=0.329]Steps: 100%|█████████▉| 12984/13000 [51:19<01:02,  3.92s/it, lr=3.74e-10, step_loss=0.253]Steps: 100%|█████████▉| 12984/13000 [51:20<01:02,  3.92s/it, lr=3.74e-10, step_loss=0.146]Steps: 100%|█████████▉| 12984/13000 [51:20<01:02,  3.92s/it, lr=3.74e-10, step_loss=0.0498]Steps: 100%|█████████▉| 12984/13000 [51:20<01:02,  3.92s/it, lr=3.74e-10, step_loss=0.0117]Steps: 100%|█████████▉| 12985/13000 [51:21<00:47,  3.19s/it, lr=3.74e-10, step_loss=0.0117]Steps: 100%|█████████▉| 12985/13000 [51:21<00:47,  3.19s/it, lr=3.28e-10, step_loss=0.0273]Steps: 100%|█████████▉| 12985/13000 [51:21<00:47,  3.19s/it, lr=3.28e-10, step_loss=0.0314]Steps: 100%|█████████▉| 12985/13000 [51:22<00:47,  3.19s/it, lr=3.28e-10, step_loss=0.0999]Steps: 100%|█████████▉| 12985/13000 [51:22<00:47,  3.19s/it, lr=3.28e-10, step_loss=0.0774]Steps: 100%|█████████▉| 12986/13000 [51:22<00:37,  2.67s/it, lr=3.28e-10, step_loss=0.0774]Steps: 100%|█████████▉| 12986/13000 [51:23<00:37,  2.67s/it, lr=2.86e-10, step_loss=0.0288]Steps: 100%|█████████▉| 12986/13000 [51:23<00:37,  2.67s/it, lr=2.86e-10, step_loss=0.0101]Steps: 100%|█████████▉| 12986/13000 [51:24<00:37,  2.67s/it, lr=2.86e-10, step_loss=0.0254]Steps: 100%|█████████▉| 12986/13000 [51:24<00:37,  2.67s/it, lr=2.86e-10, step_loss=0.109] Steps: 100%|█████████▉| 12987/13000 [51:24<00:32,  2.48s/it, lr=2.86e-10, step_loss=0.109]Steps: 100%|█████████▉| 12987/13000 [51:24<00:32,  2.48s/it, lr=2.47e-10, step_loss=0.0188]Steps: 100%|█████████▉| 12987/13000 [51:25<00:32,  2.48s/it, lr=2.47e-10, step_loss=0.247] Steps: 100%|█████████▉| 12987/13000 [51:25<00:32,  2.48s/it, lr=2.47e-10, step_loss=0.0915]Steps: 100%|█████████▉| 12987/13000 [51:25<00:32,  2.48s/it, lr=2.47e-10, step_loss=0.625] Steps: 100%|█████████▉| 12988/13000 [51:26<00:26,  2.17s/it, lr=2.47e-10, step_loss=0.625]Steps: 100%|█████████▉| 12988/13000 [51:26<00:26,  2.17s/it, lr=2.1e-10, step_loss=0.146] Steps: 100%|█████████▉| 12988/13000 [51:26<00:26,  2.17s/it, lr=2.1e-10, step_loss=0.00941]Steps: 100%|█████████▉| 12988/13000 [51:27<00:26,  2.17s/it, lr=2.1e-10, step_loss=0.0137] Steps: 100%|█████████▉| 12988/13000 [51:27<00:26,  2.17s/it, lr=2.1e-10, step_loss=0.00493]Steps: 100%|█████████▉| 12989/13000 [51:27<00:21,  1.96s/it, lr=2.1e-10, step_loss=0.00493]Steps: 100%|█████████▉| 12989/13000 [51:28<00:21,  1.96s/it, lr=1.77e-10, step_loss=0.0214]Steps: 100%|█████████▉| 12989/13000 [51:28<00:21,  1.96s/it, lr=1.77e-10, step_loss=0.0105]Steps: 100%|█████████▉| 12990/13000 [51:28<00:16,  1.69s/it, lr=1.77e-10, step_loss=0.0105]Steps: 100%|█████████▉| 12990/13000 [51:28<00:16,  1.69s/it, lr=1.46e-10, step_loss=0.308] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.13it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.75it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.05it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.61it/s]
02/23/2025 16:34:55 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12990/13000 [51:43<00:16,  1.69s/it, lr=1.46e-10, step_loss=0.0235]Steps: 100%|█████████▉| 12990/13000 [51:43<00:16,  1.69s/it, lr=1.46e-10, step_loss=0.034] Steps: 100%|█████████▉| 12990/13000 [51:44<00:16,  1.69s/it, lr=1.46e-10, step_loss=0.0514]Steps: 100%|█████████▉| 12991/13000 [51:44<00:53,  5.90s/it, lr=1.46e-10, step_loss=0.0514]Steps: 100%|█████████▉| 12991/13000 [51:44<00:53,  5.90s/it, lr=1.18e-10, step_loss=0.0333]Steps: 100%|█████████▉| 12991/13000 [51:44<00:53,  5.90s/it, lr=1.18e-10, step_loss=0.411] Steps: 100%|█████████▉| 12991/13000 [51:45<00:53,  5.90s/it, lr=1.18e-10, step_loss=0.0219]Steps: 100%|█████████▉| 12991/13000 [51:45<00:53,  5.90s/it, lr=1.18e-10, step_loss=0.0495]Steps: 100%|█████████▉| 12992/13000 [51:45<00:36,  4.57s/it, lr=1.18e-10, step_loss=0.0495]Steps: 100%|█████████▉| 12992/13000 [51:45<00:36,  4.57s/it, lr=9.34e-11, step_loss=0.111] Steps: 100%|█████████▉| 12992/13000 [51:46<00:36,  4.57s/it, lr=9.34e-11, step_loss=0.101]Steps: 100%|█████████▉| 12992/13000 [51:46<00:36,  4.57s/it, lr=9.34e-11, step_loss=0.0126]Steps: 100%|█████████▉| 12992/13000 [51:47<00:36,  4.57s/it, lr=9.34e-11, step_loss=0.173] Steps: 100%|█████████▉| 12993/13000 [51:47<00:25,  3.62s/it, lr=9.34e-11, step_loss=0.173]Steps: 100%|█████████▉| 12993/13000 [51:47<00:25,  3.62s/it, lr=7.15e-11, step_loss=0.0259]Steps: 100%|█████████▉| 12993/13000 [51:47<00:25,  3.62s/it, lr=7.15e-11, step_loss=0.342] Steps: 100%|█████████▉| 12993/13000 [51:48<00:25,  3.62s/it, lr=7.15e-11, step_loss=0.00963]Steps: 100%|█████████▉| 12993/13000 [51:48<00:25,  3.62s/it, lr=7.15e-11, step_loss=0.0111] Steps: 100%|█████████▉| 12994/13000 [51:48<00:17,  2.97s/it, lr=7.15e-11, step_loss=0.0111]Steps: 100%|█████████▉| 12994/13000 [51:48<00:17,  2.97s/it, lr=5.26e-11, step_loss=0.0733]Steps: 100%|█████████▉| 12994/13000 [51:49<00:17,  2.97s/it, lr=5.26e-11, step_loss=0.0333]Steps: 100%|█████████▉| 12994/13000 [51:49<00:17,  2.97s/it, lr=5.26e-11, step_loss=0.0267]Steps: 100%|█████████▉| 12994/13000 [51:49<00:17,  2.97s/it, lr=5.26e-11, step_loss=0.0152]Steps: 100%|█████████▉| 12995/13000 [51:50<00:12,  2.53s/it, lr=5.26e-11, step_loss=0.0152]Steps: 100%|█████████▉| 12995/13000 [51:50<00:12,  2.53s/it, lr=3.65e-11, step_loss=0.0615]Steps: 100%|█████████▉| 12995/13000 [51:50<00:12,  2.53s/it, lr=3.65e-11, step_loss=0.307] Steps: 100%|█████████▉| 12995/13000 [51:51<00:12,  2.53s/it, lr=3.65e-11, step_loss=0.107]Steps: 100%|█████████▉| 12995/13000 [51:51<00:12,  2.53s/it, lr=3.65e-11, step_loss=0.0364]Steps: 100%|█████████▉| 12996/13000 [51:51<00:08,  2.20s/it, lr=3.65e-11, step_loss=0.0364]Steps: 100%|█████████▉| 12996/13000 [51:51<00:08,  2.20s/it, lr=2.34e-11, step_loss=0.0451]Steps: 100%|█████████▉| 12996/13000 [51:52<00:08,  2.20s/it, lr=2.34e-11, step_loss=0.00968]Steps: 100%|█████████▉| 12996/13000 [51:52<00:08,  2.20s/it, lr=2.34e-11, step_loss=0.0306] Steps: 100%|█████████▉| 12996/13000 [51:52<00:08,  2.20s/it, lr=2.34e-11, step_loss=0.088] Steps: 100%|█████████▉| 12997/13000 [51:53<00:05,  1.98s/it, lr=2.34e-11, step_loss=0.088]Steps: 100%|█████████▉| 12997/13000 [51:53<00:05,  1.98s/it, lr=1.31e-11, step_loss=0.332]Steps: 100%|█████████▉| 12997/13000 [51:53<00:05,  1.98s/it, lr=1.31e-11, step_loss=0.276]Steps: 100%|█████████▉| 12997/13000 [51:54<00:05,  1.98s/it, lr=1.31e-11, step_loss=0.0262]Steps: 100%|█████████▉| 12997/13000 [51:54<00:05,  1.98s/it, lr=1.31e-11, step_loss=0.106] Steps: 100%|█████████▉| 12998/13000 [51:54<00:03,  1.90s/it, lr=1.31e-11, step_loss=0.106]Steps: 100%|█████████▉| 12998/13000 [51:54<00:03,  1.90s/it, lr=5.84e-12, step_loss=0.0572]Steps: 100%|█████████▉| 12998/13000 [51:55<00:03,  1.90s/it, lr=5.84e-12, step_loss=0.00639]Steps: 100%|█████████▉| 12999/13000 [51:55<00:01,  1.54s/it, lr=5.84e-12, step_loss=0.00639]Steps: 100%|█████████▉| 12999/13000 [51:55<00:01,  1.54s/it, lr=1.46e-12, step_loss=0.0319] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.26it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.52it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.86it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  9.44it/s]
02/23/2025 16:35:22 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|█████████▉| 12999/13000 [52:10<00:01,  1.54s/it, lr=1.46e-12, step_loss=0.0303]Steps: 100%|█████████▉| 12999/13000 [52:10<00:01,  1.54s/it, lr=1.46e-12, step_loss=0.034] Steps: 100%|█████████▉| 12999/13000 [52:10<00:01,  1.54s/it, lr=1.46e-12, step_loss=0.176]Steps: 100%|██████████| 13000/13000 [52:11<00:00,  5.74s/it, lr=1.46e-12, step_loss=0.176]02/23/2025 16:35:36 - INFO - accelerate.accelerator - Saving current state to train/checkpoint-13000
02/23/2025 16:35:51 - INFO - accelerate.checkpointing - Model weights saved in train/checkpoint-13000/model.safetensors
02/23/2025 16:35:52 - INFO - accelerate.checkpointing - Optimizer state saved in train/checkpoint-13000/optimizer.bin
02/23/2025 16:35:52 - INFO - accelerate.checkpointing - Scheduler state saved in train/checkpoint-13000/scheduler.bin
02/23/2025 16:35:52 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in train/checkpoint-13000/sampler.bin
02/23/2025 16:35:52 - INFO - accelerate.checkpointing - Random states saved in train/checkpoint-13000/random_states_0.pkl
Model weights saved in train/checkpoint-13000/pytorch_lora_weights.safetensors
02/23/2025 16:35:52 - INFO - __main__ - Saved state to train/checkpoint-13000
Steps: 100%|██████████| 13000/13000 [52:26<00:00,  5.74s/it, lr=0, step_loss=0.396]       {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.10it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 10.77it/s][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.04it/s][ALoading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.63it/s]
02/23/2025 16:35:55 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Model weights saved in train/pytorch_lora_weights.safetensors
{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][AInstantiating AutoencoderKL model under default dtype torch.float32.
{'use_quant_conv', 'scaling_factor', 'mid_block_add_attention', 'latents_std', 'latents_mean', 'use_post_quant_conv', 'force_upcast', 'shift_factor'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/vae.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  29%|██▊       | 2/7 [00:00<00:00, 11.52it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.
{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:00<00:00, 11.17it/s][AInstantiating UNet2DConditionModel model under default dtype torch.float32.
{'use_linear_projection', 'mid_block_type', 'upcast_attention', 'resnet_skip_time_act', 'conv_in_kernel', 'class_embeddings_concat', 'dual_cross_attention', 'encoder_hid_dim_type', 'timestep_post_act', 'reverse_transformer_layers_per_block', 'addition_embed_type_num_heads', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'class_embed_type', 'transformer_layers_per_block', 'only_cross_attention', 'time_embedding_dim', 'num_attention_heads', 'addition_embed_type', 'addition_time_embed_dim', 'projection_class_embeddings_input_dim', 'mid_block_only_cross_attention', 'resnet_out_scale_factor', 'time_embedding_type', 'num_class_embeds', 'cross_attention_norm', 'encoder_hid_dim', 'time_embedding_act_fn', 'conv_out_kernel', 'dropout', 'attention_type'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:  71%|███████▏  | 5/7 [00:11<00:00, 11.17it/s][AAll model checkpoint weights were used when initializing UNet2DConditionModel.

All the weights of UNet2DConditionModel were initialized from the model checkpoint at /home/users/yeevelyn/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14/unet.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.
Loaded unet as UNet2DConditionModel from `unet` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...:  86%|████████▌ | 6/7 [00:18<00:04,  4.45s/it][ALoaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.

Loading pipeline components...: 100%|██████████| 7/7 [00:18<00:00,  3.38s/it][ALoading pipeline components...: 100%|██████████| 7/7 [00:18<00:00,  2.66s/it]
Loading unet.
02/23/2025 16:36:29 - INFO - __main__ - Running validation... 
 Generating 4 images with prompt: Kei plays a soccer ball in a park. She has a determined expression and is running after the ball. The background is colorful and fully rendered..
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.
Steps: 100%|██████████| 13000/13000 [53:27<00:00,  3.21s/it, lr=0, step_loss=0.396]
